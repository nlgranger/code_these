{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from lproc import subset, rmap\n",
    "from datasets import ch14dataset as dataset\n",
    "from sltools.utils import gloss2seq, seq2gloss\n",
    "from sltools.nn_utils import onehot, jaccard, compute_scores\n",
    "from sltools.postproc import optimize_boundaries, filter_longshort\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.hmmvsrnn_reco.a_data import durations, gloss_seqs, tmpdir, \\\n",
    "   train_subset, val_subset, test_subset, vocabulary\n",
    "from experiments.hmmvsrnn_reco.b_preprocess import skel_feat_seqs, bgr_feat_seqs\n",
    "\n",
    "model = \"rnn\"\n",
    "modality = \"skel\"\n",
    "variant = \"tc3\"\n",
    "date = \"180213\"\n",
    "\n",
    "experiment_name = model + \"_\" + modality + \"_\" + (variant + \"_\" if variant != \"\" else \"\") + date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality == \"skel\":  # Skeleton end-to-end\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import skel_feat_seqs\n",
    "    feats_seqs_train = [subset(skel_feat_seqs, train_subset)]\n",
    "    feats_seqs_val = [subset(skel_feat_seqs, val_subset)]\n",
    "    feats_seqs_test = [subset(skel_feat_seqs, test_subset)]\n",
    "\n",
    "elif modality == \"bgr\":  # BGR end-to-end\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import bgr_feat_seqs\n",
    "    feats_seqs_train = [subset(bgr_feat_seqs, train_subset)]\n",
    "    feats_seqs_val = [subset(bgr_feat_seqs, val_subset)]\n",
    "\n",
    "elif modality == \"fusion\":  # Fusion end-to-end\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import skel_feat_seqs\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import bgr_feat_seqs\n",
    "    feats_seqs_train = [\n",
    "        subset(skel_feat_seqs, train_subset),\n",
    "        subset(bgr_feat_seqs, train_subset)\n",
    "        ]\n",
    "    feats_seqs_val = [\n",
    "        subset(skel_feat_seqs, val_subset),\n",
    "        subset(bgr_feat_seqs, val_subset)\n",
    "        ]\n",
    "\n",
    "elif modality == \"transfer\":  # Transfer\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess_transfer import transfer_features\n",
    "    transfered_feats_seqs = transfer_features(\n",
    "        \"hmm_skel_180122\", \"hmm_skel\",\n",
    "        max_time=128, batch_size=16,\n",
    "        encoder_kwargs={'tconv_sz': 17, 'filter_dilation': 1})\n",
    "    feats_seqs_train = [subset(transfered_feats_seqs, train_subset)]\n",
    "    feats_seqs_val = [subset(transfered_feats_seqs, val_subset)]\n",
    "\n",
    "# Annotations\n",
    "gloss_seqs_train = subset(gloss_seqs, train_subset)\n",
    "durations_train = subset(durations, train_subset)\n",
    "targets_train = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                     gloss_seqs_train, durations_train)\n",
    "\n",
    "gloss_seqs_val = subset(gloss_seqs, val_subset)\n",
    "durations_val = subset(durations, val_subset)\n",
    "targets_val = rmap(lambda g, d: gloss2seq(g, d, 0), \n",
    "                   gloss_seqs_val, durations_val)\n",
    "\n",
    "gloss_seqs_test = subset(gloss_seqs, test_subset)\n",
    "durations_test = subset(durations, test_subset)\n",
    "targets_test = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                    gloss_seqs_test, durations_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = shelve.open(os.path.join(tmpdir, experiment_name))\n",
    "all_batch_losses = []\n",
    "all_epoch_losses = []\n",
    "for i in sorted([e for e in report.keys() if e.startswith(\"epoch\")]):\n",
    "    r = report[i]\n",
    "    all_batch_losses += r['batch_losses']\n",
    "    all_epoch_losses.append(r['epoch_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(np.arange(len(all_epoch_losses)), all_epoch_losses, c='red')\n",
    "n_batches = len(all_batch_losses) // len(all_epoch_losses)\n",
    "error = np.array([np.std(all_batch_losses[i:i+n_batches]) \n",
    "                  for i in range(0, len(all_batch_losses), n_batches)])\n",
    "# plt.fill_between(np.arange(len(all_epoch_losses)), \n",
    "#                  np.maximum(0.00001, all_epoch_losses - error), \n",
    "#                  all_epoch_losses + error)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "# plt.semilogy([10 ** (i - 5) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"fine-tuning started from {}\".format(\n",
    "    sorted([(r['val_scores']['jaccard'], e)\n",
    "                     for e, r in report.items()\n",
    "                     if e.startswith(\"epoch\")\n",
    "                     and \"params\" in r.keys()])[-1][1]))\n",
    "\n",
    "# Find best epoch for early stopping\n",
    "best_epoch = sorted([(r['val_scores']['jaccard'], e)\n",
    "                     for e, r in report.items()\n",
    "                     if e.startswith(\"epoch\")\n",
    "                     and \"params\" in r.keys()])[-1][1]\n",
    "\n",
    "print(\"best epoch: {}\".format(best_epoch))\n",
    "\n",
    "epoch_report = report[best_epoch]\n",
    "print(epoch_report['train_scores']['jaccard'])\n",
    "print(epoch_report['train_scores']['framewise'])\n",
    "print(epoch_report['val_scores']['jaccard'])\n",
    "print(epoch_report['train_scores']['framewise'] - epoch_report['val_scores']['framewise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality == \"skel\": # Skeleton end-to-end\n",
    "    from experiments.hmmvsrnn_reco.c_models import skel_lstm\n",
    "    model_dict = skel_lstm(feats_shape=skel_feat_seqs[0][0].shape,\n",
    "                           **report['model_args'])\n",
    "\n",
    "elif modality == \"bgr\":  # BGR end-to-end\n",
    "    from experiments.hmmvsrnn_reco.c_models import bgr_lstm\n",
    "    model_dict = bgr_lstm(feats_shape=feats_seqs_train[0][1][0].shape,\n",
    "                          **report['model_args'])\n",
    "\n",
    "elif modality == \"fusion\":  # Fusion end-to-end\n",
    "    from experiments.hmmvsrnn_reco.c_models import fusion_lstm\n",
    "    model_dict = fusion_lstm(skel_feats_shape=skel_feat_seqs[0][0].shape,\n",
    "                             bgr_feats_shape=bgr_feat_seqs[0][0].shape,\n",
    "                             **report['model_args'])\n",
    "\n",
    "# Reload parameters\n",
    "params = epoch_report['params']\n",
    "all_layers = lasagne.layers.get_all_layers(model_dict['l_linout'])\n",
    "lasagne.layers.set_all_param_values(all_layers, params)\n",
    "\n",
    "# Compile\n",
    "from sltools.models.rnn import build_predict_fn\n",
    "predict_fn = build_predict_fn(model_dict, batch_size, max_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sltools.models.rnn import seqs2batches\n",
    "# from sltools.nn_utils import seq_hinge_loss, log_softmax\n",
    "\n",
    "# x, y, d = next(seqs2batches(feats_seqs_train, targets_train, \n",
    "#                             batch_size=batch_size, max_time=max_time, warmup=model_dict['warmup']))\n",
    "\n",
    "# linout, masks, feats = lasagne.layers.get_output(\n",
    "#     [model_dict['l_linout'], model_dict['l_mask'], model_dict[\"l_feats\"]])\n",
    "# targets = T.imatrix()\n",
    "# loss = seq_hinge_loss(linout, targets, masks=masks, delta=.3)\n",
    "# g = theano.grad(loss.sum(), wrt=linout)\n",
    "# print(g.eval({\n",
    "#     model_dict['l_in'][0].input_var: x,\n",
    "#     targets: y,\n",
    "#     model_dict['l_duration'].input_var: d\n",
    "# }))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = [np.argmax(p, axis=1) for p in predict_fn(feats_seqs_train)]\n",
    "ji_train, framewise_train, confusion_train = compute_scores(predictions_train, targets_train, vocabulary)\n",
    "\n",
    "predictions_val = [np.argmax(p, axis=1) for p in predict_fn(feats_seqs_val)]\n",
    "ji_val, framewise_val, confusion_val = compute_scores(predictions_val, targets_val, vocabulary)\n",
    "\n",
    "print(\"JI: {:.4f} / {:.4f}\".format(ji_train, ji_val))\n",
    "print(\"Accuracy: {:.4f} / {:.4f}\".format(framewise_train, framewise_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = [\n",
    "    'âˆ…','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo']\n",
    "\n",
    "cmap = matplotlib.cm.viridis\n",
    "cmap.set_bad(cmap(0.001))\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(6, 4))\n",
    "im = ax1.matshow(confusion_train / np.sum(confusion_train, axis=1, keepdims=True), \n",
    "                 interpolation='none', cmap=cmap,\n",
    "                 clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "ax1.set_yticks(np.arange(0, 22, 1))\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticklabels(cnames)\n",
    "\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "fig, ax2 = plt.subplots(1, 1, figsize=(6, 4))\n",
    "im = ax2.matshow(confusion_val / np.sum(confusion_val, axis=1, keepdims=True), \n",
    "                 interpolation='none', cmap='viridis',\n",
    "                 clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "ax2.set_yticks(np.arange(0, 22, 1))\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticklabels(cnames)\n",
    "\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_seq(proba, ax=None):\n",
    "    # 21 distinct colors\n",
    "    \n",
    "    cmap = np.array([[113,204,0], [209,73,251], [243,255,52], [223,119,255], \n",
    "         [139,255,150], [255,66,189], [1,222,201], [255,77,30], \n",
    "         [0,149,225], [137,106,0], [0,43,105], [255,230,180], \n",
    "         [111,0,66], [0,113,63], [251,177,255], [56,96,0], \n",
    "         [160,218,255], [74,0,6], [255,170,172], [0,62,95], \n",
    "         [93,43,0]]) / 255\n",
    "    \n",
    "    ax = ax or plt.gca()\n",
    "    l = np.argmax(proba, axis=1)\n",
    "    for g, start, stop in seq2gloss(l):\n",
    "        start = max(0, start - 1)\n",
    "        stop = min(len(proba), stop + 1)\n",
    "        if g == 0:\n",
    "            ax.plot(np.arange(start, stop), proba[start:stop, 0], ls=':', c=cmap[0])\n",
    "        else:\n",
    "            ax.plot(np.arange(start, stop), proba[start:stop, g], c=cmap[g])\n",
    "            ax.fill_between(np.arange(start, stop),\n",
    "                            0, proba[start:stop, g],\n",
    "                            facecolor=cmap[g],\n",
    "                            alpha=0.3)\n",
    "    ax.set_ylim((0.1, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 62\n",
    "\n",
    "proba = predict_fn([[fseq[s]] for fseq in feats_seqs_val])[0]\n",
    "labels = onehot(gloss2seq(gloss_seqs_val[s], durations_val[s], 0), \n",
    "                np.arange(0, 21))\n",
    "\n",
    "f = plt.figure(figsize=(13, 2))\n",
    "ax = f.add_subplot(111)\n",
    "preview_seq(proba[:], ax)\n",
    "plt.title(\"model predictions\")\n",
    "plt.show()\n",
    "f = plt.figure(figsize=(13, .7))\n",
    "ax = f.add_subplot(111)\n",
    "preview_seq(labels[:] * 1.0,  ax)\n",
    "plt.title(\"targets\")\n",
    "plt.show()\n",
    "\n",
    "# print(transformations[val_subset_augmented[s]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of errors\n",
    "\n",
    "scores = [jaccard(onehot(l, vocabulary), onehot(p, vocabulary))\n",
    "         for l, p in zip(targets_val, predictions_val)]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(scores, np.linspace(0.0, 1, 40))\n",
    "plt.title(\"Histogram of sequence-wise JI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of false positives out of sequence vocabulary\n",
    "np.mean([len(set(p_) - set(l_)) for p_, l_ in zip(predictions_val, targets_val)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion types\n",
    "cum_err = np.sum(confusion_val, axis=1) - np.diag(confusion_val)\n",
    "print(\"false pos: {}  false neg: {}, mis-class: {}\".format(\n",
    "    cum_err[0], np.sum(confusion_val[1:, 0]), np.sum(cum_err[1:]) - np.sum(confusion_val[1:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate error with predicted gloss duration\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "prediction_accuracy = [np.sum(l[start:stop] == g) \n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "none_accuracy = [np.sum(l[start:stop] == 0)\n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "gloss_d = [stop - start\n",
    "           for p in predictions_val \n",
    "           for (g, start, stop) in seq2gloss(p)\n",
    "           if g != 0]\n",
    "\n",
    "scores_pred = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "scores_none = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "total_d = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "for vp, vn, d in zip(prediction_accuracy, none_accuracy, gloss_d):\n",
    "    idx = int(d / 5)\n",
    "    scores_pred[idx] += vp\n",
    "    scores_none[idx] += vn\n",
    "    total_d[idx] += d\n",
    "\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5), \n",
    "              scores_pred / total_d,\n",
    "              width=5,\n",
    "              alpha=.5)\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5), \n",
    "              scores_none / total_d,\n",
    "              width=5,\n",
    "              alpha=.5)\n",
    "\n",
    "plt.legend([\"predicted class\", \"non-gesture class\"])\n",
    "plt.xlabel(\"subsequence duration (based on model prediction)\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize duration filter\n",
    "\n",
    "boundaries = optimize_boundaries(targets_val, predictions_val, vocabulary, (30, 100, 301))\n",
    "print(\"Optimal range: \", boundaries)\n",
    "print(\"FYI the score without is: {:.4f}\".format(ji_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation score\n",
    "\n",
    "ji_after, _, _ = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_val], \n",
    "    targets_val, vocabulary)\n",
    "print(\"validation score: {:.4f}\".format(ji_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "\n",
    "targets_test = [gloss2seq(g_, d_, 0) for g_, d_ in zip(gloss_seqs_test, durations_test)]\n",
    "predictions_test = [np.argmax(p, axis=1) for p in predict_fn(feats_seqs_test)]\n",
    "\n",
    "ji_test, _, _ = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_test], \n",
    "    targets_test, vocabulary)\n",
    "print(\"testing score: {:.4f}\".format(ji_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sltools.tconv import TemporalConv\n",
    "\n",
    "tc_l = None\n",
    "layers = lasagne.layers.get_all_layers(model_dict['l_linout'])\n",
    "\n",
    "for l in layers:\n",
    "    if isinstance(l, TemporalConv):\n",
    "        tc_l = l\n",
    "        break\n",
    "\n",
    "W = np.asarray(tc_l.W.eval())\n",
    "tsne = TSNE(n_components=1, n_iter=5000, n_iter_without_progress=100, verbose=True)\n",
    "filter_order = np.argsort(tsne.fit_transform(W)[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = None\n",
    "n = int(np.ceil(len(filter_order) / 200))\n",
    "for i in range(0, n):\n",
    "    if i % 4 == 0:\n",
    "        f = plt.figure(figsize=(15, 8))\n",
    "    ax = plt.subplot(1, 4, i % 4 + 1, sharey=ax)\n",
    "    ax.pcolor(W[filter_order[i * 200:(i + 1) * 200], ::-1], \n",
    "              clim=(-np.abs(W).max(), np.abs(W).max()), \n",
    "              cmap='RdBu')\n",
    "    \n",
    "    if ((i + 1) % 4 == 0) or i + 1 == n:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show activated filters for a category\n",
    "\n",
    "act_l = layers[layers.index(tc_l) + 2]\n",
    "X = feat_seqs_val\n",
    "X = rmap(lambda x_: (x_,), X)\n",
    "y = [gloss2seq(g_, len(r_), 0)\n",
    "     for g_, r_ in zip(gloss_seqs_val, feat_seqs_val)]\n",
    "\n",
    "# Chunking\n",
    "step = recognizer.max_len - 2 * recognizer.warmup\n",
    "durations = [len(seq[0]) for seq in X]\n",
    "chunks = [(i, k, min(k + recognizer.max_len, d))\n",
    "          for i, d in enumerate(durations)\n",
    "          for k in range(0, d - recognizer.warmup, step)]\n",
    "grads = [np.zeros((d, tc_l.output_shape[2]), dtype=theano.config.floatX)\n",
    "         for d in durations]\n",
    "\n",
    "# Functions\n",
    "X_buffers = [np.zeros(shape=(recognizer.batch_size, recognizer.max_len) + shape,\n",
    "                      dtype=theano.config.floatX)\n",
    "             for shape in recognizer.input_shapes]\n",
    "y_buffer = np.zeros(shape=(recognizer.batch_size, recognizer.max_len), dtype=np.int32)\n",
    "d_buffer = np.zeros((recognizer.batch_size,), dtype=np.int32)\n",
    "c_buffer = np.zeros((recognizer.batch_size, 3), dtype=np.int32)\n",
    "tgt_var = T.imatrix()\n",
    "  \n",
    "activations, predictions = lasagne.layers.get_output(\n",
    "    [act_l, recognizer.l_raw], deterministic=True)\n",
    "g = theano.grad(predictions[T.arange(recognizer.batch_size)[:, None], :, tgt_var].sum(), \n",
    "                wrt=activations)\n",
    "g_fn = theano.function([recognizer.l_in[0].input_var, recognizer.durations_var, tgt_var], g)\n",
    "\n",
    "j = 0\n",
    "for i, (seq, start, stop) in enumerate(chunks):\n",
    "    for b, x in zip(X_buffers, X[seq]):\n",
    "        b[j][:stop - start] = x[start:stop]\n",
    "    y_buffer[j][:stop - start] = y[seq][start:stop]\n",
    "    d_buffer[j] = stop - start\n",
    "    c_buffer[j] = (seq, start, stop)\n",
    "\n",
    "    if j + 1 == recognizer.batch_size or i == len(chunks) - 1:\n",
    "        batch_predictions = g_fn(*X_buffers, d_buffer, y_buffer)[:j + 1]\n",
    "        for (seq_, start_, stop_), grad in zip(c_buffer, batch_predictions):\n",
    "            warmup = recognizer.warmup if start_ > 0 else 0\n",
    "            grads[seq_][start_ + warmup:stop_] = \\\n",
    "                grad[warmup:stop_ - start_]\n",
    "\n",
    "    j = (j + 1) % recognizer.batch_size\n",
    "    \n",
    "all_grads = np.concatenate(grads)\n",
    "all_labels = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = .5 # max(-X.min(), X.max())\n",
    "\n",
    "ashes = []\n",
    "for l in range(recognizer.nlabels):\n",
    "    where = (all_labels == l)\n",
    "    h = np.stack([np.histogram(X[where, i], bins=np.linspace(-rng, rng, 16))[0] / where.sum()\n",
    "                  for i in range(X.shape[1])])\n",
    "    ashes.append(h)\n",
    "\n",
    "meanh = np.mean(ashes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 50))\n",
    "\n",
    "ax = plt.subplot2grid((1, 6), (0, 0), colspan=2)\n",
    "ax.pcolormesh(W[filter_order, :], clim=(-np.abs(W).max(), np.abs(W).max()), cmap='bwr')\n",
    "ax.set_yticks(np.arange(0, W.shape[0], 5))\n",
    "# ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "ax.grid(True)\n",
    "\n",
    "for p, i in enumerate([0, 1, 2, -1]):\n",
    "    h = ashes[i] - meanh\n",
    "#     h = meanh\n",
    "    ax = plt.subplot2grid((1, 6), (0, 2 + p), colspan=1)\n",
    "    ax.pcolormesh(h, clim=(-1, 1), cmap='bwr')\n",
    "    ax.set_yticks(np.arange(0, W.shape[0], 5))\n",
    "    ax.set_xticks(np.arange(0, 16, 3))\n",
    "    ax.set_xticklabels(np.linspace(-rng, rng, 6))\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim((0, W.shape[0]))\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.imshow(np.concatenate(feat_seqs[0][1280], axis=1), clim=(0, 1), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max([stop - start for gseq in gloss_seqs_val for g, start, stop in gseq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
