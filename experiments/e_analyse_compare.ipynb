{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.normpath(os.path.join(os.getcwd(), '..')))\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import pickle as pkl\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import lasagne\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import SymLogNorm\n",
    "from matplotlib.mlab import bivariate_normal\n",
    "import matplotlib.cm\n",
    "from lproc import subset, rmap\n",
    "from datasets.utils import gloss2seq, seq2gloss\n",
    "from sltools.nn_utils import compute_scores, jaccard, onehot\n",
    "from sltools.models.rnn import build_predict_fn\n",
    "from sltools.postproc import optimize_boundaries, filter_longshort"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlabels = 21\n",
    "\n",
    "from experiments.ch14_skel.a_data import durations, gloss_seqs, tmpdir, \\\n",
    "    train_subset, val_subset, test_subset, vocabulary\n",
    "from experiments.ch14_skel.b_preprocess import feat_seqs\n",
    "from experiments.ch14_skel.c_models import build_lstm\n",
    "feat_seqs = rmap(lambda x: (x,), feat_seqs)\n",
    "\n",
    "# from experiments.ch14_bgr.a_data import durations, gloss_seqs, tmpdir, \\\n",
    "#     train_subset, val_subset, test_subset, vocabulary\n",
    "# from experiments.ch14_bgr.b_preprocess import feat_seqs\n",
    "# feat_seqs = rmap(lambda x: (x,), feat_seqs)\n",
    "\n",
    "# from experiments.ch14_fusion.a_data import durations, gloss_seqs, tmpdir, \\\n",
    "#     train_subset, val_subset, test_subset, vocabulary\n",
    "# from experiments.ch14_fusion.b_preprocess import feat_seqs\n",
    "\n",
    "feats_seqs_train = subset(feat_seqs, train_subset)\n",
    "gloss_seqs_train = subset(gloss_seqs, train_subset)\n",
    "durations_train = subset(durations, train_subset)\n",
    "\n",
    "feats_seqs_val = subset(feat_seqs, val_subset)\n",
    "gloss_seqs_val = subset(gloss_seqs, val_subset)\n",
    "durations_val = subset(durations, val_subset)\n",
    "\n",
    "feats_seqs_test = subset(feat_seqs, test_subset)\n",
    "gloss_seqs_test = subset(gloss_seqs, test_subset)\n",
    "durations_test = subset(durations, test_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HMM\n",
    "# hmm_report = shelve.open(os.path.join(tmpdir, \"..\", \"..\", \"ch14_skel_hmm_alpha07\", \"cache\", \"hmm_report\"))\n",
    "hmm_report = shelve.open(os.path.join(tmpdir, \"hmm_report\"))\n",
    "\n",
    "all_batch_losses = []\n",
    "all_epoch_losses = []\n",
    "n_epochs = []\n",
    "best_phase = 0\n",
    "best_score = 0\n",
    "for i in sorted(map(int, hmm_report.keys())):\n",
    "    r = hmm_report[str(i)]\n",
    "    all_batch_losses += r['batch_losses']\n",
    "    all_epoch_losses += r['epoch_losses']\n",
    "    if r['val_report']['jaccard'] > best_score:\n",
    "        best_phase = i\n",
    "        best_score = r['val_report']['jaccard']\n",
    "\n",
    "hmm_phase_report = hmm_report[str(best_phase)]\n",
    "hmm_recognizer = hmm_phase_report['model']\n",
    "\n",
    "labels = [gloss2seq(g_, d_, 0) for g_, d_ in zip(gloss_seqs_val, durations_val)]\n",
    "preds = hmm_recognizer.predict(feats_seqs_val)\n",
    "hmm_boundaries = optimize_boundaries(labels, preds, vocabulary, (30, 150, 300))\n",
    "print(\"Optimal range: \", hmm_boundaries)\n",
    "ji_before = np.mean([jaccard(onehot(l, vocabulary), onehot(p, vocabulary))\n",
    "                     for l, p in zip(labels, preds)])\n",
    "ji_after = np.mean([jaccard(onehot(l, vocabulary), \n",
    "                            onehot(filter_longshort(p, hmm_boundaries, 0), vocabulary))\n",
    "                    for l, p in zip(labels, preds)])\n",
    "print(\"JI: {:.4f} -> {:.4f}\".format(ji_before, ji_after))\n",
    "print(hmm_phase_report['val_report']['jaccard'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN\n",
    "max_time = 128\n",
    "batch_size = 16\n",
    "rnn_report = shelve.open(os.path.join(tmpdir, \"rnn_report\"))\n",
    "best_epoch = sorted([(float(rnn_report[str(e)]['val_scores']['jaccard']), int(e))\n",
    "                     for e in rnn_report.keys() if 'val_scores' in rnn_report[str(e)].keys()])[-1][1]\n",
    "\n",
    "rnn_epoch_report = rnn_report[str(best_epoch)]\n",
    "\n",
    "input_shape = tuple([x.shape[1:] for x in feat_seqs[0]])\n",
    "\n",
    "model = build_lstm(*input_shape,\n",
    "                   batch_size=batch_size, max_time=max_time)\n",
    "\n",
    "all_layers = lasagne.layers.get_all_layers(model['l_linout'])\n",
    "with open(os.path.join(tmpdir, \"rnn_it{:04d}.pkl\".format(best_epoch)), 'rb') as f:\n",
    "    params = pkl.load(f)\n",
    "    lasagne.layers.set_all_param_values(all_layers, params)\n",
    "\n",
    "rnn_predict_fn = build_predict_fn(model, batch_size, max_time, nlabels, model['warmup'])\n",
    "\n",
    "labels = [gloss2seq(g_, d_, 0) for g_, d_ in zip(gloss_seqs_val, durations_val)]\n",
    "preds = rmap(lambda x: np.argmax(x, axis=1),\n",
    "             rnn_predict_fn(rmap(lambda x: x[0], feats_seqs_val)))\n",
    "rnn_boundaries = optimize_boundaries(labels, preds, vocabulary, (30, 150, 300))\n",
    "print(\"Optimal range: \", rnn_boundaries)\n",
    "ji_before = np.mean([jaccard(onehot(l, vocabulary), onehot(p, vocabulary))\n",
    "                     for l, p in zip(labels, preds)])\n",
    "ji_after = np.mean([jaccard(onehot(l, vocabulary), \n",
    "                            onehot(filter_longshort(p, rnn_boundaries, 0), vocabulary))\n",
    "                    for l, p in zip(labels, preds)])\n",
    "print(\"JI: {:.4f} -> {:.4f}\".format(ji_before, ji_after))\n",
    "print(rnn_epoch_report['val_scores']['jaccard'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmm_preds = hmm_recognizer.predict(feats_seqs_val)\n",
    "hmm_preds = [filter_longshort(p, hmm_boundaries, 0) for p in hmm_preds]\n",
    "rnn_preds = rmap(lambda x: np.argmax(x, axis=1),\n",
    "                 rnn_predict_fn(rmap(lambda x: x[0], feats_seqs_val)))\n",
    "rnn_preds = [filter_longshort(p, rnn_boundaries, 0) for p in rnn_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_val = [gloss2seq(gseq, d, 0) for gseq, d in zip(gloss_seqs_val, durations_val)]\n",
    "\n",
    "hj, hf, hc = compute_scores(hmm_preds, targets_val, vocabulary)\n",
    "rj, rf, rc = compute_scores(rnn_preds, targets_val, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = hc / hc.sum(axis=1, keepdims=True) - rc / hc.sum(axis=1, keepdims=True)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(diff, cmap='RdYlBu', clim=(-.07, .07))\n",
    "\n",
    "plt.colorbar()\n",
    "plt.title(r\"$\\dfrac{C_{ij}^{hmm} - C_{ij}^{rnn}}{C_{i}} \\quad where \\quad C_{ij} = \\#\\left(ŷ=j \\, | \\, y=i\\right)$\",\n",
    "          y=-.3)\n",
    "plt.xlabel(\"predictions\")\n",
    "plt.ylabel(\"targets\")\n",
    "plt.yticks(np.arange(21))\n",
    "plt.xticks(np.arange(0, 21, 1))\n",
    "plt.gca().set_yticklabels([\n",
    "    '∅','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo'])\n",
    "plt.gca().set_xticklabels([])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.diag(hc - rc)) / hc.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = hc - np.diag(np.diag(hc))\n",
    "np.sum(x[1:, 1:]) / np.sum(hc[1:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rc - np.diag(np.diag(rc))\n",
    "np.sum(x[1:, 1:]) / np.sum(rc[1:, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error types:\n",
    "# too soon: 1\n",
    "# too late: 2\n",
    "# misclassification: 3\n",
    "# false negative: 4\n",
    "# false positive (if not too soon or too late): 5\n",
    "# other: 6\n",
    "#\n",
    "# Error descriptor: (rec, time, type, quantity)\n",
    "\n",
    "acceptance_ratio = .5  # matching ratio over the target subsequence to accept detection\n",
    "\n",
    "def triage_errors(preds, gloss_seqs, durations):\n",
    "    errors = []\n",
    "    \n",
    "    for i, (pseq, gseq, d) in enumerate(zip(preds, gloss_seqs, durations)):\n",
    "        l = gloss2seq(gseq, d, 0)\n",
    "        tgseq = seq2gloss(l)  # reintroduces segments for blanks\n",
    "        pgseq = seq2gloss(pseq)\n",
    "        for pg, pstart, pstop in pgseq:\n",
    "            for tg, start, stop in tgseq:\n",
    "                overlaps = min(stop, pstop) - max(start, pstart) > (stop - start) * acceptance_ratio\n",
    "                \n",
    "                # detected, but too soon\n",
    "                if overlaps and pg == tg and pg != 0 and pstart <= start:\n",
    "                    errors.append((1, start - pstart, tg, start, stop, pg, pstart, pstop, i))\n",
    "            \n",
    "                # detected, but too late\n",
    "                if overlaps and pg == tg and pg != 0 and pstop >= stop:\n",
    "                    errors.append((2, pstop - stop, tg, start, stop, pg, pstart, pstop, i))\n",
    "\n",
    "                # misclassification\n",
    "                if overlaps and pg != tg and pg != 0 and tg != 0:\n",
    "                    errors.append((3, min(stop, pstop) - max(start, pstart), tg, start, stop, pg, pstart, pstop, i))\n",
    "                \n",
    "                # false positive\n",
    "                overlaps = min(stop, pstop) - max(start, pstart) > (pstop - pstart) * acceptance_ratio\n",
    "                if tg == 0 and pg != 0 and overlaps:\n",
    "                    errors.append((5, min(stop, pstop) - max(start, pstart), 0, start, stop, pg, pstart, pstop, i))\n",
    "                    \n",
    "        for tg, start, stop in tgseq:\n",
    "            # false negative\n",
    "            if tg != 0 and np.mean(pseq[start:stop] == 0) > acceptance_ratio:\n",
    "                errors.append((4, np.sum(pseq[start:stop] == 0), tg, start, stop, 0, -1, -1, i))\n",
    "    \n",
    "    return np.array(errors)\n",
    "                \n",
    "hmm_errors = triage_errors(hmm_preds, gloss_seqs_val, durations_val)\n",
    "\n",
    "rnn_errors = triage_errors(rnn_preds, gloss_seqs_val, durations_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(2, 3, 1)\n",
    "hmm_too_soon = hmm_errors[hmm_errors[:, 0] == 1, 1]\n",
    "rnn_too_soon = rnn_errors[rnn_errors[:, 0] == 1, 1]\n",
    "bins = np.linspace(0, 10, 10)\n",
    "# plt.gca().set_yscale('log')\n",
    "\n",
    "plt.bar(bins[:-1], np.histogram(hmm_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.bar(bins[:-1], np.histogram(rnn_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.legend([\"hmm\", \"rnn\"])\n",
    "plt.title(\"too soon\")\n",
    "\n",
    "plt.subplot(2, 3, 2)\n",
    "hmm_too_soon = hmm_errors[hmm_errors[:, 0] == 2, 1]\n",
    "rnn_too_soon = rnn_errors[rnn_errors[:, 0] == 2, 1]\n",
    "bins = np.linspace(0, 10, 10)\n",
    "\n",
    "plt.bar(bins[:-1], np.histogram(hmm_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.bar(bins[:-1], np.histogram(rnn_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.legend([\"hmm\", \"rnn\"])\n",
    "plt.title(\"too late\")\n",
    "\n",
    "plt.subplot(2, 3, 3)\n",
    "hmm_too_soon = hmm_errors[hmm_errors[:, 0] == 3, 1]\n",
    "rnn_too_soon = rnn_errors[rnn_errors[:, 0] == 3, 1]\n",
    "bins = np.linspace(0, max(hmm_too_soon.max(), rnn_too_soon.max()), 20)\n",
    "\n",
    "plt.bar(bins[:-1], np.histogram(hmm_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.bar(bins[:-1], np.histogram(rnn_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.legend([\"hmm\", \"rnn\"])\n",
    "plt.title(\"mislassification\")\n",
    "\n",
    "plt.subplot(2, 3, 4)\n",
    "hmm_too_soon = hmm_errors[hmm_errors[:, 0] == 4, 1]\n",
    "rnn_too_soon = rnn_errors[rnn_errors[:, 0] == 4, 1]\n",
    "bins = np.linspace(0, max(hmm_too_soon.max(), rnn_too_soon.max()), 20)\n",
    "\n",
    "plt.bar(bins[:-1], np.histogram(hmm_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.bar(bins[:-1], np.histogram(rnn_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.legend([\"hmm\", \"rnn\"])\n",
    "plt.title(\"false negative\")\n",
    "\n",
    "plt.subplot(2, 3, 5)\n",
    "hmm_too_soon = hmm_errors[hmm_errors[:, 0] == 5, 1]\n",
    "rnn_too_soon = rnn_errors[rnn_errors[:, 0] == 5, 1]\n",
    "bins = np.linspace(0, max(hmm_too_soon.max(), rnn_too_soon.max()), 20)\n",
    "\n",
    "plt.bar(bins[:-1], np.histogram(hmm_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.bar(bins[:-1], np.histogram(rnn_too_soon, bins=bins)[0], alpha=.5)\n",
    "plt.legend([\"hmm\", \"rnn\"])\n",
    "plt.title(\"false positive\")\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
