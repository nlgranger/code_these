{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shelve\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import seqtools\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from experiments.siamese_triplet.a_data import \\\n",
    "    cachedir, durations, labels, recordings, \\\n",
    "    train_subset, val_subset\n",
    "from experiments.siamese_triplet.b_preprocess import skel_feat_seqs\n",
    "from experiments.siamese_triplet.c_model import skel_rnn, build_predict_fn\n",
    "from experiments.siamese_triplet.common import sample_episode, \\\n",
    "    evaluate_knn, evaluate_matching\n",
    "\n",
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data ----------------------------------------------------------------------------------\n",
    "\n",
    "feat_seqs_train = [seqtools.gather(skel_feat_seqs, train_subset)]\n",
    "labels_train = labels[train_subset].astype(np.int32)\n",
    "recordings_train = recordings[train_subset]\n",
    "durations_train = durations[train_subset].astype(np.int32)\n",
    "\n",
    "feat_seqs_val = [\n",
    "    seqtools.gather(skel_feat_seqs, val_subset)\n",
    "]\n",
    "labels_val = labels[val_subset].astype(np.int32)\n",
    "recordings_val = recordings[val_subset]\n",
    "durations_val = durations[val_subset].astype(np.int32)\n",
    "\n",
    "del recordings, labels, durations, skel_feat_seqs\n",
    "\n",
    "report = shelve.open(os.path.join(cachedir, \"rnn_report\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model ---------------------------------------------------------------------------------\n",
    "\n",
    "modality = report['meta']['modality']\n",
    "max_time = report['meta']['max_time']\n",
    "batch_size = report['meta']['batch_size']\n",
    "encoder_kwargs = report['meta']['encoder_kwargs']\n",
    "\n",
    "model_dict = skel_rnn(\n",
    "    *tuple(f[0][0].shape for f in feat_seqs_train),\n",
    "    batch_size=batch_size, max_time=max_time,\n",
    "    encoder_kwargs=encoder_kwargs)\n",
    "\n",
    "l_linout = model_dict['l_linout']\n",
    "l_in = model_dict['l_in']\n",
    "l_duration = model_dict['l_duration']\n",
    "\n",
    "last_iteration = str(sorted(int(e) for e in report.keys() if re.match(r'[0-9]+', e))[-1])\n",
    "# last_iteration = '900'\n",
    "lasagne.layers.set_all_param_values(l_linout, report[last_iteration]['params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation routines -------------------------------------------------------------------\n",
    "\n",
    "predict_fn = build_predict_fn(model_dict, report['meta']['batch_size'],\n",
    "                              report['meta']['max_time'])\n",
    "embeddings_train = predict_fn(feat_seqs_train, durations_train)\n",
    "embeddings_val = predict_fn(feat_seqs_val, durations_val)\n",
    "\n",
    "def evaluate(embeddings_, labels_, recordings_,\n",
    "             shots_grid_, voca_size_grid_,\n",
    "             classifier_, n_episodes_):\n",
    "    vocabulary = np.unique(labels_)\n",
    "    results = np.empty((len(shots_grid_), len(voca_size_grid_)))\n",
    "\n",
    "    for i, shots in enumerate(shots_grid_):\n",
    "        for j, voca_size in enumerate(voca_size_grid_):\n",
    "            ranks = []\n",
    "            for _ in range(n_episodes_):\n",
    "                ep_train_subset, ep_test_subset, _ = sample_episode(\n",
    "                    labels_, recordings_, vocabulary, voca_size, shots)\n",
    "\n",
    "                if classifier_ == \"kernel\":\n",
    "                    ep_ranks = evaluate_matching(\n",
    "                        embeddings_[ep_train_subset],\n",
    "                        embeddings_[ep_test_subset],\n",
    "                        labels_[ep_train_subset],\n",
    "                        labels_[ep_test_subset],\n",
    "                        voca_size, shots)\n",
    "\n",
    "                elif classifier_ == \"knn\":\n",
    "                    ep_ranks = evaluate_knn(\n",
    "                        embeddings_[ep_train_subset],\n",
    "                        embeddings_[ep_test_subset],\n",
    "                        labels_[ep_train_subset],\n",
    "                        labels_[ep_test_subset],\n",
    "                        k=neighbourgs)\n",
    "                else:\n",
    "                    raise ValueError(\"unsupported classifier type\")\n",
    "\n",
    "                ranks.extend(ep_ranks)\n",
    "\n",
    "            results[i, j] = np.mean(np.array(ranks) == 0)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model ------------------------------------------------------------------------\n",
    "\n",
    "classifier = \"kernel\"\n",
    "neighbourgs = 1\n",
    "shots_grid = np.array([1, 2, 3, 4, 5])\n",
    "voca_size_grid = np.array([5, 10, 15, 20, 25, 30])\n",
    "n_episodes = 1000\n",
    "\n",
    "result_train = evaluate(embeddings_train, labels_train, recordings_train,\n",
    "                        shots_grid, voca_size_grid,\n",
    "                        classifier, n_episodes)\n",
    "result_val = evaluate(embeddings_val, labels_val, recordings_val,\n",
    "                      shots_grid, voca_size_grid,\n",
    "                      classifier, n_episodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display -------------------------------------------------------------------------------\n",
    "\n",
    "fig = plt.figure(figsize=(8, 7))\n",
    "\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for i, shots in enumerate(shots_grid):\n",
    "    for j, voca_size in enumerate(voca_size_grid):\n",
    "        ax.plot(\n",
    "            [shots, shots],\n",
    "            [voca_size, voca_size],\n",
    "            [result_train[i, j], result_val[i, j]],\n",
    "            alpha=.5, c='k', linestyle=':')\n",
    "ax.scatter(\n",
    "    np.tile(shots_grid[:, None], (1, len(voca_size_grid))),\n",
    "    np.tile(voca_size_grid[None, :], (len(shots_grid), 1)),\n",
    "    result_train,\n",
    "    c=np.ravel(result_train),\n",
    "    alpha=.5)\n",
    "for j in range(len(voca_size_grid)):\n",
    "    ax.plot(shots_grid, result_train[:, j], zs=0, zdir='y', c='black', alpha=0.1)\n",
    "\n",
    "ax.plot_wireframe(\n",
    "    np.tile(shots_grid[:, None], (1, len(voca_size_grid))),\n",
    "    np.tile(voca_size_grid[None, :], (len(shots_grid), 1)),\n",
    "    result_val,\n",
    "    alpha=1.)\n",
    "ax.scatter(\n",
    "    np.tile(shots_grid[:, None], (1, len(voca_size_grid))),\n",
    "    np.tile(voca_size_grid[None, :], (len(shots_grid), 1)),\n",
    "    result_val,\n",
    "    c=np.ravel(result_val),\n",
    "    alpha=1.)\n",
    "for j in range(len(voca_size_grid)):\n",
    "    ax.plot(shots_grid, result_val[:, j], zs=0, zdir='y', c='black', alpha=0.3)\n",
    "\n",
    "ax.set_xticks(shots_grid)\n",
    "ax.set_yticks(voca_size_grid)\n",
    "ax.set_xlabel(\"shots\")\n",
    "ax.set_ylabel(\"vocabulary\")\n",
    "ax.set_zlabel(\"accuracy\")\n",
    "\n",
    "# ax.view_init(15, 290)\n",
    "ax.view_init(20, 140)\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
