{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "os.environ['THEANO_FLAGS'] = \"device=cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import shelve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import display\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "pd.set_option(\"display.precision\", 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.hmmvsrnn_reco.a_data import cachedir, frame_seqs, dataset, vocabulary, \\\n",
    "    get_ref_pts, detect_invalid_pts, interpolate_positions\n",
    "from experiments.hmmvsrnn_reco.b_preprocess import skel_feat_seqs, bgr_feat_seqs\n",
    "from sltools.transform import Transformation, transform_pose2d, transform_pose3d, transform_frames\n",
    "\n",
    "cachedir = cachedir.split('.')[0]\n",
    "tgt_dist = 2\n",
    "joints = dataset.JointType\n",
    "\n",
    "flip_mapping = ([joints.ShoulderRight, joints.ElbowRight,\n",
    "                 joints.WristRight, joints.HandRight, joints.ShoulderLeft,\n",
    "                 joints.ElbowLeft, joints.WristLeft, joints.HandLeft,\n",
    "                 joints.HipRight, joints.KneeRight, joints.AnkleRight,\n",
    "                 joints.FootRight, joints.HipLeft, joints.KneeLeft,\n",
    "                 joints.AnkleLeft, joints.FootLeft],\n",
    "                [joints.ShoulderLeft, joints.ElbowLeft,\n",
    "                 joints.WristLeft, joints.HandLeft, joints.ShoulderRight,\n",
    "                 joints.ElbowRight, joints.WristRight, joints.HandRight,\n",
    "                 joints.HipLeft, joints.KneeLeft, joints.AnkleLeft,\n",
    "                 joints.FootLeft, joints.HipRight, joints.KneeRight,\n",
    "                 joints.AnkleRight, joints.FootRight])\n",
    "\n",
    "video = dataset.bgr_frames(0)\n",
    "poses_2d = dataset.positions(0)\n",
    "poses_3d = dataset.positions_3d(0)\n",
    "invalid_masks = detect_invalid_pts(poses_2d)\n",
    "poses_2d = interpolate_positions(poses_2d, invalid_masks)\n",
    "poses_3d = interpolate_positions(poses_3d, invalid_masks)\n",
    "ref2d = get_ref_pts(poses_2d)\n",
    "ref3d = get_ref_pts(poses_3d)\n",
    "\n",
    "zshifts = np.mean(tgt_dist - ref3d[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation = Transformation(\n",
    "#     ref2d=ref2d, ref3d=ref3d, flip_mapping=flip_mapping,\n",
    "#     frame_width=640,\n",
    "#     fliplr=False,\n",
    "#     tilt=5 * np.pi / 180,\n",
    "#     zshift=zshifts,\n",
    "#     xscale=1.15, yscale=0.85,\n",
    "#     zscale=1, tscale=1)\n",
    "\n",
    "# t = 10\n",
    "# plt.figure()\n",
    "# plt.imshow(video[t])\n",
    "# plt.scatter(poses_2d[t, :, 0], poses_2d[t, :, 1])\n",
    "# plt.figure()\n",
    "# plt.imshow(transform_frames(video, transformation)[t])\n",
    "# trans_pose2d = transform_pose2d(poses_2d, transformation)\n",
    "# plt.scatter(trans_pose2d[t, :, 0], trans_pose2d[t, :, 1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "\n",
    "# for run, directory in enumerate([cachedir + '.run1', cachedir + '.run2', cachedir + '.run3', cachedir + '.run4']):\n",
    "# for run, directory in enumerate([cachedir + '.run4', cachedir + '.run5', cachedir + '.run6']):\n",
    "for run, directory in enumerate([cachedir + '.run{}'.format(i) for i in range(1, 7)]):\n",
    "    for report_file in os.listdir(directory):\n",
    "        if not report_file.endswith(\".dat\"):\n",
    "            continue\n",
    "        \n",
    "        f = os.path.join(directory, report_file[:-4])\n",
    "        with shelve.open(f, flag='r') as report:\n",
    "            if 'analysis' not in report.keys():\n",
    "                continue\n",
    "            meta = report['meta']\n",
    "            name = meta['experiment_name']\n",
    "            args = report['args']['encoder_kwargs']\n",
    "            analysis = report['analysis']\n",
    "            experiments.append((name, run, meta, args, analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['model', 'modality', 'run', 'acc', 'ji', 'acc_filtered', 'ji_filtered']\n",
    "\n",
    "analyses = []\n",
    "\n",
    "for name, run, meta, args, analysis in experiments:\n",
    "    if meta['modality'] != 'skel':\n",
    "        continue\n",
    "    if meta['variant'] != 'tc15':\n",
    "        continue\n",
    "    if meta['model'] != 'rnn':\n",
    "        continue\n",
    "\n",
    "    model = meta['model']\n",
    "    modality = meta['modality']\n",
    "    acc = analysis['accuracy'][1]\n",
    "    acc_filtered = analysis['accuracy_filtered'][1]\n",
    "    ji = analysis['ji'][1]\n",
    "    ji_filtered = analysis['ji_filtered'][1]\n",
    "    analyses.append((model, modality, run, acc, ji, acc_filtered, ji_filtered))\n",
    "\n",
    "analyses = pd.DataFrame(analyses, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying TC size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = [('model', 'S3'), \n",
    "         ('win', 'i'),\n",
    "         ('nparms', 'i'),\n",
    "         ('ji', 'f'),\n",
    "         ('acc', 'f')]\n",
    "\n",
    "tc_analyses = np.sort([\n",
    "    np.array((\n",
    "        m['model'],\n",
    "        a['filter_dilation'] * (a['tconv_sz'] - 1) + 1,\n",
    "        a['tconv_sz'] * a['num_tc_filters'],\n",
    "        r['ji_filtered'][1], \n",
    "        r['accuracy_filtered'][1]), \n",
    "        dtype=dtype)\n",
    "    for _, _, m, a, r in experiments \n",
    "    if m['modality'] == \"skel\"])\n",
    "\n",
    "plt.figure(dpi=100) \n",
    "\n",
    "legend = []\n",
    "subset = (tc_analyses['model'] == b\"rnn\")\n",
    "p1 = plt.scatter(\n",
    "    tc_analyses[subset]['win'],\n",
    "    tc_analyses[subset]['ji'],\n",
    "    s=tc_analyses[subset]['nparms'] / 50,\n",
    "    marker=\"o\", alpha=0.5)\n",
    "    \n",
    "legend = []\n",
    "subset = (tc_analyses['model'] == b\"hmm\")\n",
    "p2 = plt.scatter(\n",
    "    tc_analyses[subset]['win'],\n",
    "    tc_analyses[subset]['ji'],\n",
    "    s=tc_analyses[subset]['nparms'] / 50,\n",
    "    marker=\"o\", alpha=0.5)\n",
    "\n",
    "plt.legend([p1, p2], ['rnn', 'hmm'], loc='best')\n",
    "\n",
    "plt.xlabel(\"window size\")\n",
    "plt.ylabel(\"Jaccard Index\")\n",
    "plt.xticks(np.arange(3, 32, 4))\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().grid(color='k', linestyle=':', alpha=.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_experiments = {\n",
    "    (name, run): (meta['modality'], analysis['accuracy_filtered'][2], analysis['ji_filtered'][2])\n",
    "    for name, run, meta, args, analysis in experiments \n",
    "    if meta['modality'] != \"transfer\"}\n",
    "\n",
    "columns = [\n",
    "    'model', 'modality', 'terminate_at', 'run', \n",
    "    'acc', 'delta_ref_acc', 'delta_other_acc', 'ji', 'delta_ref_ji', 'delta_other_ji']\n",
    "\n",
    "transfer_analyses = []\n",
    "\n",
    "for name, run, meta, args, analysis in experiments:\n",
    "    if meta['modality'] != 'transfer':\n",
    "        continue\n",
    "\n",
    "    model = meta['model']\n",
    "    terminate_at = args['terminate_at']\n",
    "    modality, acc_other, ji_other = source_experiments[(args['transfer_from'], run)]\n",
    "    _, acc_ref, ji_ref = source_experiments[(model + args['transfer_from'][3:], run)]\n",
    "    acc = analysis['accuracy_filtered'][2]\n",
    "    ji = analysis['ji_filtered'][2]\n",
    "    transfer_analyses.append(\n",
    "        (model, modality, terminate_at, run, \n",
    "                  acc, acc - acc_ref, acc - acc_other, \n",
    "                  ji, ji - ji_ref, ji - ji_other))\n",
    "\n",
    "transfer_analyses = pd.DataFrame(transfer_analyses, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_analyses.groupby(['model', 'modality', 'terminate_at']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare confusion on video frames\n",
    "\n",
    "hmm_conf = np.zeros((21, 21))\n",
    "rnn_conf = np.zeros((21, 21))\n",
    "\n",
    "for rundir in [cachedir + '.run1', cachedir + '.run2', cachedir + '.run3']:\n",
    "    with shelve.open(os.path.join(rundir, \"hmm_bgr_tc15\"), flag='r') as report:\n",
    "        hmm_analysis = report['analysis']\n",
    "        hmm_conf += hmm_analysis['confusion_filtered'][1]\n",
    "\n",
    "    with shelve.open(os.path.join(rundir, \"rnn_bgr_tc15\"), flag='r') as report:\n",
    "        rnn_analysis = report['analysis']\n",
    "        rnn_conf += rnn_analysis['confusion_filtered'][1]\n",
    "\n",
    "hmm_conf /= np.sum(hmm_conf, axis=1, keepdims=True)\n",
    "rnn_conf /= np.sum(rnn_conf, axis=1, keepdims=True)\n",
    "\n",
    "conf_diff = hmm_conf - rnn_conf\n",
    "\n",
    "# plot\n",
    "plt.figure(dpi=150, figsize=(6, 3))\n",
    "limits = np.max(abs(conf_diff))\n",
    "plt.imshow(\n",
    "    conf_diff, \n",
    "    clim=(-limits, limits), \n",
    "    cmap='RdBu')\n",
    "plt.yticks(np.arange(0, 21), [\n",
    "    '∅','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo'],\n",
    "    fontsize=8)\n",
    "plt.xticks(np.arange(0, 21), [''] * 21)\n",
    "plt.gca().annotate(\n",
    "    '', \n",
    "    xy=(1.5, 0.1), xycoords='axes fraction', xytext=(1.5, 0.9), \n",
    "    arrowprops=dict(arrowstyle=\"<->\", color='k'))\n",
    "plt.gca().annotate(\n",
    "    'rnn', xy=(1.47, 0.05), xycoords='axes fraction', xytext=(1.47, 0.05))\n",
    "plt.gca().annotate(\n",
    "    'hmm', xy=(1.44, 0.92), xycoords='axes fraction', xytext=(1.44, 0.92))\n",
    "plt.colorbar()\n",
    "\n",
    "# Compare misclassification\n",
    "a = np.sum(hmm_conf[1:, 1:]) - np.sum(np.diag(hmm_conf[1:, 1:]))\n",
    "b = np.sum(rnn_conf[1:, 1:]) - np.sum(np.diag(rnn_conf[1:, 1:]))\n",
    "print(a, b, (a - b) / b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare confusion on body poses\n",
    "\n",
    "hmm_conf = np.zeros((21, 21))\n",
    "rnn_conf = np.zeros((21, 21))\n",
    "\n",
    "for rundir in [cachedir + '.run1', cachedir + '.run2', cachedir + '.run3']:\n",
    "    with shelve.open(os.path.join(rundir, \"hmm_skel_tc15\"), flag='r') as report:\n",
    "        hmm_analysis = report['analysis']\n",
    "        hmm_conf += hmm_analysis['confusion_filtered'][1]\n",
    "\n",
    "    with shelve.open(os.path.join(rundir, \"rnn_skel_tc15\"), flag='r') as report:\n",
    "        rnn_analysis = report['analysis']\n",
    "        rnn_conf += rnn_analysis['confusion_filtered'][1]\n",
    "\n",
    "hmm_conf /= np.sum(hmm_conf, axis=1, keepdims=True)\n",
    "rnn_conf /= np.sum(rnn_conf, axis=1, keepdims=True)\n",
    "\n",
    "conf_diff = hmm_conf - rnn_conf\n",
    "\n",
    "# plot\n",
    "plt.figure(dpi=150, figsize=(6, 3))\n",
    "limits = np.max(abs(conf_diff))\n",
    "plt.imshow(\n",
    "    conf_diff, \n",
    "    clim=(-limits, limits), \n",
    "    cmap='RdBu')\n",
    "plt.yticks(np.arange(0, 21), [\n",
    "    '∅','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo'],\n",
    "    fontsize=8)\n",
    "plt.xticks(np.arange(0, 21), [''] * 21)\n",
    "plt.gca().annotate(\n",
    "    '', \n",
    "    xy=(1.5, 0.1), xycoords='axes fraction', xytext=(1.5, 0.9), \n",
    "    arrowprops=dict(arrowstyle=\"<->\", color='k'))\n",
    "plt.gca().annotate(\n",
    "    'rnn', xy=(1.47, 0.05), xycoords='axes fraction', xytext=(1.47, 0.05))\n",
    "plt.gca().annotate(\n",
    "    'hmm', xy=(1.44, 0.92), xycoords='axes fraction', xytext=(1.44, 0.92))\n",
    "plt.colorbar()\n",
    "\n",
    "# Compare misclassification\n",
    "a = np.sum(hmm_conf[1:, 1:]) - np.sum(np.diag(hmm_conf[1:, 1:]))\n",
    "b = np.sum(rnn_conf[1:, 1:]) - np.sum(np.diag(rnn_conf[1:, 1:]))\n",
    "print(a, b, (a - b) / b)\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0., 1.2, 1])\n",
    "# plt.savefig(\"/home/granger/exp1_confdiff_skel.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(hmm_conf[0, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(rnn_conf[0, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize mistaken classes\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "\n",
    "plt.imshow(\n",
    "    np.clip(rnn_conf, 0.0001, 1), \n",
    "    clim=(0.001, 1),\n",
    "    norm=colors.LogNorm(vmin=0.0001, vmax=1., clip=True))\n",
    "plt.yticks(np.arange(0, 21), [\n",
    "    '∅','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo'])\n",
    "plt.xticks(np.arange(0, 21), [''] * 21)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/home/granger/exp1_rnn_pose_confusion.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "c1 = 16\n",
    "c2 = 0\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5), dpi=150)\n",
    "all_glosses = np.array([[seq] + list(g) for seq in dataset.default_splits()[0] for g in dataset.glosses(seq)])\n",
    "\n",
    "\n",
    "p = (all_glosses[:, 1] == c1) / np.sum(all_glosses[:, 1] == c1)\n",
    "seq1, c1, start1, stop1 = all_glosses[np.random.choice(len(all_glosses), p=p)]\n",
    "vid1 = dataset.bgr_frames(seq1)\n",
    "\n",
    "for i, t in enumerate(np.linspace(start1 + 10, stop1 - 10, 5).astype(np.int)):\n",
    "    frame = vid1[t]\n",
    "    pose = dataset.positions(seq1)[t]\n",
    "    x1, x2, y1, y2 = np.min(pose[:, 0]) - 30, np.max(pose[:, 0]) + 30, np.min(pose[:, 1]) - 20, np.max(pose[:, 1]) - 130\n",
    "    ax = fig.add_subplot(2, 5, i + 1)\n",
    "    ax.imshow(frame[y1:y2, x1:x2, ::-1])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "p = (all_glosses[:, 1] == c2) / np.sum(all_glosses[:, 1] == c2)\n",
    "seq2, c2, start2, stop2 = all_glosses[np.random.choice(len(all_glosses), p=p)]\n",
    "vid2 = dataset.bgr_frames(seq2)\n",
    "\n",
    "for i, t in enumerate(np.linspace(start2 + 10, stop2 - 10, 5).astype(np.int)):\n",
    "    frame = vid2[t]\n",
    "    pose = dataset.positions(seq2)[t]\n",
    "    x1, x2, y1, y2 = np.min(pose[:, 0]) - 30, np.max(pose[:, 0]) + 30, np.min(pose[:, 1]) - 20, np.max(pose[:, 1]) - 130\n",
    "    ax = fig.add_subplot(2, 5, i + 6)\n",
    "    ax.imshow(frame[y1:y2, x1:x2, ::-1])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "fig.tight_layout(pad=0, h_pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.hmmvsrnn_reco.a_data import pose2d_seqs, frame_seqs\n",
    "from experiments.hmmvsrnn_reco.b_preprocess import bgr_feat_seqs, bgr_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = frame_seqs.sequences[1][0]\n",
    "frame_seq = frame_seqs.sequences[0][0]\n",
    "p = pose2d_seqs[0]\n",
    "plt.imshow(frame_seq[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_frame_seq = transform_frames(frame_seq, t)\n",
    "plt.imshow(transformed_frame_seq[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hands = bgr_feats(transformed_frame_seq, p)\n",
    "plt.imshow(np.concatenate(hands[10], axis=1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.concatenate(bgr_feat_seqs[0][10], axis=1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['model', 'modality', 'run', 'acc', 'ji', 'acc_filtered', 'ji_filtered']\n",
    "\n",
    "analyses = []\n",
    "\n",
    "for name, run, meta, args, analysis in experiments:\n",
    "    if meta['modality'] == 'transfer':\n",
    "        continue\n",
    "    if meta['variant'] != 'tc15':\n",
    "        continue\n",
    "\n",
    "    model = meta['model']\n",
    "    modality = meta['modality']\n",
    "    acc = analysis['accuracy'][1]\n",
    "    acc_filtered = analysis['accuracy_filtered'][1]\n",
    "    ji = analysis['ji'][1]\n",
    "    ji_filtered = analysis['ji_filtered'][1]\n",
    "    analyses.append((model, modality, run, acc, ji, acc_filtered, ji_filtered))\n",
    "\n",
    "analyses = pd.DataFrame(analyses, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyses.groupby(['model', 'modality']).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
