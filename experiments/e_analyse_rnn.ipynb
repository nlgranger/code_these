{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.getcwd()))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "import shelve\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm\n",
    "from lproc import subset, rmap\n",
    "from datasets import ch14dataset as dataset\n",
    "from datasets.utils import gloss2seq, seq2gloss\n",
    "from sltools.nn_utils import onehot, jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sltools.models.rnn import build_predict_fn\n",
    "\n",
    "# from experiments.ch14_skel.a_data import durations, gloss_seqs, tmpdir, train_subset, val_subset, test_subset\n",
    "# from experiments.ch14_skel.b_preprocess import feat_seqs\n",
    "# from experiments.ch14_skel.c_models import build_lstm\n",
    "# max_time = 128\n",
    "# batch_size = 32\n",
    "# multiple_inputs = False\n",
    "\n",
    "from experiments.ch14_bgr.a_data import durations, gloss_seqs, tmpdir, train_subset, val_subset, test_subset\n",
    "from experiments.ch14_bgr.b_preprocess import feat_seqs\n",
    "from experiments.ch14_bgr.c_models import build_lstm\n",
    "max_time = 128\n",
    "batch_size = 32\n",
    "multiple_inputs = False\n",
    "\n",
    "# from experiments.ch14_fusion.a_data import durations, gloss_seqs, tmpdir, train_subset, val_subset, test_subset\n",
    "# from experiments.ch14_fusion.b_preprocess import feat_seqs\n",
    "# from experiments.ch14_fusion.c_models import build_lstm\n",
    "# max_time = 128\n",
    "# batch_size = 12\n",
    "# multiple_inputs = True\n",
    "\n",
    "nlabels = 21\n",
    "# tmpdir = \"/home/granger/.cache/ch14_skel_rnn_17_1_hinge\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = shelve.open(os.path.join(tmpdir, 'rnn_report'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats_seqs_train = subset(feat_seqs, train_subset)\n",
    "gloss_seqs_train = subset(gloss_seqs, train_subset)\n",
    "durations_train = subset(durations, train_subset)\n",
    "\n",
    "feats_seqs_val = subset(feat_seqs, val_subset)\n",
    "gloss_seqs_val = subset(gloss_seqs, val_subset)\n",
    "durations_val = subset(durations, val_subset)\n",
    "\n",
    "feats_seqs_test = subset(feat_seqs, test_subset)\n",
    "gloss_seqs_test = subset(gloss_seqs, test_subset)\n",
    "durations_test = subset(durations, test_subset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batch_losses = []\n",
    "all_epoch_losses = []\n",
    "n_epochs = []\n",
    "for i in map(str, sorted(map(int, report.keys()))):\n",
    "    r = report[i]\n",
    "    all_batch_losses += r['batch_losses']\n",
    "    all_epoch_losses.append(r['epoch_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(np.arange(len(all_epoch_losses)), all_epoch_losses, c='red')\n",
    "n_batches = len(all_batch_losses) // len(all_epoch_losses)\n",
    "error = np.array([np.std(all_batch_losses[i:i+n_batches]) \n",
    "                  for i in range(0, len(all_batch_losses), n_batches)])\n",
    "plt.fill_between(np.arange(len(all_epoch_losses)), all_epoch_losses-error, all_epoch_losses+error)\n",
    "# plt.semilogy([10 ** (i - 5) for i in range(5)])\n",
    "# plt.yscale(\"log\", nonposy='clip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pprint(report['0']['fit_args'])\n",
    "best_epoch = sorted([(float(report[str(e)]['val_scores']['jaccard']), int(e))\n",
    "                     for e in report.keys() if 'val_scores' in report[str(e)].keys()])[-1][1]\n",
    "print(\"best epoch: {}\".format(best_epoch))\n",
    "r = report[str(best_epoch)]\n",
    "pprint(r['train_scores']['jaccard'])\n",
    "pprint(r['train_scores']['framewise'])\n",
    "pprint(r['val_scores']['jaccard'])\n",
    "pprint(r['train_scores']['framewise'] - r['val_scores']['framewise'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_report = report[str(best_epoch)]\n",
    "\n",
    "if multiple_inputs:\n",
    "    input_shape = tuple([x.shape[1:] for x in feats_seqs_train[0]])\n",
    "else:\n",
    "    input_shape = (feats_seqs_train[0].shape[1:],)\n",
    "\n",
    "model = build_lstm(*input_shape,\n",
    "                   batch_size=batch_size, max_time=max_time)\n",
    "\n",
    "all_layers = lasagne.layers.get_all_layers(model['l_linout'])\n",
    "with open(os.path.join(tmpdir, \"rnn_it{:04d}.pkl\".format(best_epoch)), 'rb') as f:\n",
    "    params = pkl.load(f)\n",
    "    lasagne.layers.set_all_param_values(all_layers, params)\n",
    "\n",
    "predict_fn = build_predict_fn(model, batch_size, max_time, nlabels, model['warmup'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "def analyse(*data):\n",
    "    fig, axs = plt.subplots(1, len(data), figsize=(15, 3))\n",
    "    cmap = matplotlib.cm.viridis\n",
    "    cmap.set_bad(cmap(0.001))\n",
    "    \n",
    "    for ax, (feat_seqs, gloss_seqs, durations) in zip(axs, data):\n",
    "        labels = [gloss2seq(g_, d_, 0)\n",
    "                  for g_, d_ in zip(gloss_seqs, durations)]\n",
    "        pred = [np.argmax(p, axis=1) for p in predict_fn(feat_seqs)]\n",
    "\n",
    "        score = np.mean([jaccard(onehot(l, np.arange(1, 20)), onehot(p, np.arange(1, 20)))\n",
    "                         for l, p in zip (labels, pred)])\n",
    "\n",
    "        pred = np.concatenate(pred)\n",
    "        labels = np.concatenate(labels)\n",
    "\n",
    "        confusion = confusion_matrix(labels, pred).astype(np.double)\n",
    "        confusion /= np.sum(confusion, axis=1)[:, None]\n",
    "\n",
    "        print(\"Jaccard index: {:0.3f}\".format(score))\n",
    "        print(\"Framewise: {:0.3f}\".format(np.mean(pred == labels)))\n",
    "\n",
    "        im = ax.matshow(confusion, interpolation='none', cmap=cmap, \n",
    "                        clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        \n",
    "        divider = make_axes_locatable(ax)\n",
    "        cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "        fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "        \n",
    "\n",
    "# 21 distinct colors\n",
    "cmap = np.array([[113,204,0], [209,73,251], [243,255,52], [223,119,255], \n",
    "         [139,255,150], [255,66,189], [1,222,201], [255,77,30], \n",
    "         [0,149,225], [137,106,0], [0,43,105], [255,230,180], \n",
    "         [111,0,66], [0,113,63], [251,177,255], [56,96,0], \n",
    "         [160,218,255], [74,0,6], [255,170,172], [0,62,95], \n",
    "         [93,43,0]]) / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyse((feats_seqs_train, gloss_seqs_train, durations_train),\n",
    "        (feats_seqs_val, gloss_seqs_val, durations_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preview_seq(proba):        \n",
    "#     plt.plot(np.arange(len(proba)), proba[:, 0], ls=':', c=cmap[0])\n",
    "#     for c in range(1, 21):\n",
    "#         plt.plot(np.arange(len(proba)), proba[:, c], c=cmap[c])\n",
    "def preview_seq(proba):\n",
    "    x = proba[:, 0] > 0.1\n",
    "    for g, start, stop in seq2gloss(x):\n",
    "        start = max(0, start - 1)\n",
    "        stop = min(len(x), stop + 1)\n",
    "        if g:\n",
    "            plt.plot(np.arange(start, stop), proba[start:stop, 0], ls=':', c=cmap[0])\n",
    "    for c in range(1, 21):\n",
    "        x = proba[:, c] > 0.1\n",
    "        for g, start, stop in seq2gloss(x):\n",
    "            if g:\n",
    "                start = max(0, start - 1)\n",
    "                stop = min(len(x), stop + 1)\n",
    "                plt.plot(np.arange(start, stop), proba[start:stop, c], c=cmap[c])\n",
    "    \n",
    "    plt.gca().set_ylim((0.1, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 2\n",
    "\n",
    "proba = predict_fn([feats_seqs_val[s]])[0]\n",
    "labels = onehot(gloss2seq(gloss_seqs_val[s], durations_val[s], 0), \n",
    "                np.arange(0, 21))\n",
    "\n",
    "plt.figure(figsize=(13, 4))\n",
    "plt.subplot(2, 1, 1)\n",
    "preview_seq(proba)\n",
    "plt.subplot(2, 1, 2)\n",
    "preview_seq(labels * 1.0)\n",
    "\n",
    "# print(transformations[val_subset_augmented[s]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [gloss2seq(g_, d_, 0)\n",
    "          for g_, d_ in zip(gloss_seqs_val, durations_val)]\n",
    "preds = [np.argmax(p, axis=1) for p in predict_fn(feats_seqs_val)]\n",
    "\n",
    "score = [jaccard(onehot(l, np.arange(1, 20)), onehot(p, np.arange(1, 20)))\n",
    "         for l, p in zip (labels, preds)]\n",
    "\n",
    "plt.hist(score, np.linspace(0.5, 1, 40))\n",
    "\n",
    "list(zip(range(len(score)), score))[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of false positives out of sequence vocabulary\n",
    "\n",
    "np.mean([len(set(p_) - set(l_)) for p_, l_ in zip(preds, labels)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion types\n",
    "preds_cat = np.concatenate(preds)\n",
    "labels_cat = np.concatenate(labels)\n",
    "\n",
    "confusion = confusion_matrix(labels_cat, preds_cat)\n",
    "\n",
    "cum_err = np.sum(confusion, axis=1) - np.diag(confusion)\n",
    "\n",
    "print(\"false pos: {}  false neg: {}, mis-class: {}\".format(\n",
    "    cum_err[0], np.sum(confusion[1:, 0]), np.sum(cum_err[1:]) - np.sum(confusion[1:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate error with predicted gloss duration\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "validity = [np.sum(l[start:stop] == g) \n",
    "            for p, l in zip(preds, labels)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "gloss_d = [stop - start\n",
    "           for p in preds \n",
    "           for (g, start, stop) in seq2gloss(p)\n",
    "           if g != 0]\n",
    "\n",
    "scores = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "total_d = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "for v, d in zip(validity, gloss_d):\n",
    "    idx = int(d / 5)\n",
    "    scores[idx] += v\n",
    "    total_d[idx] += d\n",
    "\n",
    "plt.gca().bar(np.arange(5, int(np.ceil(max(gloss_d) + 5.0001)), 5), scores / total_d)\n",
    "\n",
    "\n",
    "validity = [np.sum(l[start:stop] == 0)\n",
    "            for p, l in zip(preds, labels)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "gloss_d = [stop - start\n",
    "           for p in preds\n",
    "           for (g, start, stop) in seq2gloss(p)\n",
    "           if g != 0]\n",
    "\n",
    "scores = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "total_d = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "for v, d in zip(validity, gloss_d):\n",
    "    idx = int(d / 5)\n",
    "    scores[idx] += v\n",
    "    total_d[idx] += d\n",
    "\n",
    "plt.gca().bar(np.arange(7, int(np.ceil(max(gloss_d) + 7.0001)), 5), scores / total_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score with filtered short segments\n",
    "\n",
    "ji = np.mean([jaccard(onehot(l, np.arange(1, 20)), onehot(p, np.arange(1, 20)))\n",
    "              for l, p in zip (labels, preds)])\n",
    "preds_cat = np.concatenate(preds)\n",
    "labels_cat = np.concatenate(labels)\n",
    "\n",
    "print(\"Jaccard index: {:0.3f}\".format(ji))\n",
    "print(\"Framewise: {:0.3f}\".format(np.mean(preds_cat == labels_cat)))\n",
    "\n",
    "thresholds = np.arange(10, 30)\n",
    "jis = np.empty((len(thresholds),))\n",
    "for i, t in enumerate(thresholds):\n",
    "    preds2 = [gloss2seq([(g, start, stop)\n",
    "                         for (g, start, stop) in seq2gloss(p) \n",
    "                         if stop - start > t],\n",
    "                        len(p), 0)\n",
    "              for p in preds]\n",
    "    jis[i] = np.mean([jaccard(onehot(l, np.arange(1, 20)), onehot(p, np.arange(1, 20)))\n",
    "                      for l, p in zip (labels, preds2)])\n",
    "\n",
    "thres1 = thresholds[np.argmax(jis)]\n",
    "\n",
    "thresholds = np.arange(100, 150, 5)\n",
    "jis = np.empty((len(thresholds),))\n",
    "for i, t in enumerate(thresholds):\n",
    "    preds2 = [gloss2seq([(g, start, stop)\n",
    "                         for (g, start, stop) in seq2gloss(p) \n",
    "                         if thres1 < stop - start < t],\n",
    "                        len(p), 0)\n",
    "              for p in preds]\n",
    "    jis[i] = np.mean([jaccard(onehot(l, np.arange(1, 20)), onehot(p, np.arange(1, 20)))\n",
    "                      for l, p in zip (labels, preds2)])\n",
    "    \n",
    "thres2 = thresholds[np.argmax(jis)]\n",
    "    \n",
    "preds2 = [gloss2seq([(g, start, stop)\n",
    "                     for (g, start, stop) in seq2gloss(p) \n",
    "                     if thres2 > stop - start > thres1],\n",
    "                    len(p), 0)\n",
    "          for p in preds]\n",
    "ji = np.mean([jaccard(onehot(l, np.arange(1, 20)), onehot(p, np.arange(1, 20)))\n",
    "              for l, p in zip (labels, preds2)])\n",
    "preds_cat = np.concatenate(preds2)\n",
    "labels_cat = np.concatenate(labels)\n",
    "print(\"Optimal thresholds: {} - {}\".format(thres1, thres2))\n",
    "print(\"Jaccard index: {:0.3f}\".format(ji))\n",
    "print(\"Framewise: {:0.3f}\".format(np.mean(preds_cat == labels_cat)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# thres = <-set above\n",
    "\n",
    "labels = [gloss2seq(g_, d_, 0)\n",
    "          for g_, d_ in zip(gloss_seqs_test, durations_test)]\n",
    "\n",
    "# Complete model\n",
    "preds = [np.argmax(p, axis=1) for p in predict_fn(feats_seqs_test)]\n",
    "preds2 = [gloss2seq([(g, start, stop)\n",
    "                     for (g, start, stop) in seq2gloss(p) \n",
    "                     if thres1 < stop - start < thres2],\n",
    "                    len(p), 0)\n",
    "          for p in preds]\n",
    "\n",
    "score = np.mean([jaccard(onehot(l, np.arange(1, 20)), onehot(p, np.arange(1, 20)))\n",
    "                 for l, p in zip(labels, preds2)])\n",
    "\n",
    "print(\"testing score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sltools.tconv import TemporalConv\n",
    "\n",
    "tc_l = None\n",
    "layers = lasagne.layers.get_all_layers(model['l_linout'])\n",
    "\n",
    "for l in layers:\n",
    "    if isinstance(l, TemporalConv):\n",
    "        tc_l = l\n",
    "        break\n",
    "\n",
    "W = np.asarray(tc_l.W.eval())\n",
    "tsne = TSNE(n_components=1, n_iter=5000, n_iter_without_progress=100, verbose=True)\n",
    "filter_order = np.argsort(tsne.fit_transform(W)[:, 0])\n",
    "\n",
    "f = plt.figure(figsize=(15, 8))\n",
    "\n",
    "ax = None\n",
    "for i in range(4):\n",
    "    if i > 0:\n",
    "        ax = plt.subplot(1, 4, i+1, sharey=ax)\n",
    "    else:\n",
    "        ax = plt.subplot(1, 4, i+1)\n",
    "    ax.pcolor(W[filter_order[i * 200:(i + 1) * 200]], \n",
    "              clim=(-np.abs(W).max(), np.abs(W).max()), \n",
    "              cmap='RdBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show activated filters for a category\n",
    "\n",
    "act_l = layers[layers.index(tc_l) + 2]\n",
    "X = feats_seqs_val\n",
    "X = rmap(lambda x_: (x_,), X)\n",
    "y = [gloss2seq(g_, len(r_), 0)\n",
    "     for g_, r_ in zip(gloss_seqs_val, feats_seqs_val)]\n",
    "\n",
    "# Chunking\n",
    "step = recognizer.max_len - 2 * recognizer.warmup\n",
    "durations = [len(seq[0]) for seq in X]\n",
    "chunks = [(i, k, min(k + recognizer.max_len, d))\n",
    "          for i, d in enumerate(durations)\n",
    "          for k in range(0, d - recognizer.warmup, step)]\n",
    "grads = [np.zeros((d, tc_l.output_shape[2]), dtype=theano.config.floatX)\n",
    "         for d in durations]\n",
    "\n",
    "# Functions\n",
    "X_buffers = [np.zeros(shape=(recognizer.batch_size, recognizer.max_len) + shape,\n",
    "                      dtype=theano.config.floatX)\n",
    "             for shape in recognizer.input_shapes]\n",
    "y_buffer = np.zeros(shape=(recognizer.batch_size, recognizer.max_len), dtype=np.int32)\n",
    "d_buffer = np.zeros((recognizer.batch_size,), dtype=np.int32)\n",
    "c_buffer = np.zeros((recognizer.batch_size, 3), dtype=np.int32)\n",
    "tgt_var = T.imatrix()\n",
    "  \n",
    "activations, predictions = lasagne.layers.get_output(\n",
    "    [act_l, recognizer.l_raw], deterministic=True)\n",
    "g = theano.grad(predictions[T.arange(recognizer.batch_size)[:, None], :, tgt_var].sum(), \n",
    "                wrt=activations)\n",
    "g_fn = theano.function([recognizer.l_in[0].input_var, recognizer.durations_var, tgt_var], g)\n",
    "\n",
    "j = 0\n",
    "for i, (seq, start, stop) in enumerate(chunks):\n",
    "    for b, x in zip(X_buffers, X[seq]):\n",
    "        b[j][:stop - start] = x[start:stop]\n",
    "    y_buffer[j][:stop - start] = y[seq][start:stop]\n",
    "    d_buffer[j] = stop - start\n",
    "    c_buffer[j] = (seq, start, stop)\n",
    "\n",
    "    if j + 1 == recognizer.batch_size or i == len(chunks) - 1:\n",
    "        batch_predictions = g_fn(*X_buffers, d_buffer, y_buffer)[:j + 1]\n",
    "        for (seq_, start_, stop_), grad in zip(c_buffer, batch_predictions):\n",
    "            warmup = recognizer.warmup if start_ > 0 else 0\n",
    "            grads[seq_][start_ + warmup:stop_] = \\\n",
    "                grad[warmup:stop_ - start_]\n",
    "\n",
    "    j = (j + 1) % recognizer.batch_size\n",
    "    \n",
    "all_grads = np.concatenate(grads)\n",
    "all_labels = np.concatenate(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = .5 # max(-X.min(), X.max())\n",
    "\n",
    "ashes = []\n",
    "for l in range(recognizer.nlabels):\n",
    "    where = (all_labels == l)\n",
    "    h = np.stack([np.histogram(X[where, i], bins=np.linspace(-rng, rng, 16))[0] / where.sum()\n",
    "                  for i in range(X.shape[1])])\n",
    "    ashes.append(h)\n",
    "\n",
    "meanh = np.mean(ashes, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15, 50))\n",
    "\n",
    "ax = plt.subplot2grid((1, 6), (0, 0), colspan=2)\n",
    "ax.pcolormesh(W[filter_order, :], clim=(-np.abs(W).max(), np.abs(W).max()), cmap='bwr')\n",
    "ax.set_yticks(np.arange(0, W.shape[0], 5))\n",
    "# ax.set_yticks([])\n",
    "ax.set_yticklabels([])\n",
    "ax.grid(True)\n",
    "\n",
    "for p, i in enumerate([0, 1, 2, -1]):\n",
    "    h = ashes[i] - meanh\n",
    "#     h = meanh\n",
    "    ax = plt.subplot2grid((1, 6), (0, 2 + p), colspan=1)\n",
    "    ax.pcolormesh(h, clim=(-1, 1), cmap='bwr')\n",
    "    ax.set_yticks(np.arange(0, W.shape[0], 5))\n",
    "    ax.set_xticks(np.arange(0, 16, 3))\n",
    "    ax.set_xticklabels(np.linspace(-rng, rng, 6))\n",
    "    ax.grid(True)\n",
    "    ax.set_ylim((0, W.shape[0]))\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "fig.subplots_adjust(hspace=0, wspace=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
