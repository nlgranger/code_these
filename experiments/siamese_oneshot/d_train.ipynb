{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lproc import rmap, subset, chunk_load\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sltools.utils import pad_seq, dichotomy\n",
    "\n",
    "from experiments.siamese_oneshot.a_data import tmpdir, \\\n",
    "    durations, labels, transformations, \\\n",
    "    train_subset, val_subset\n",
    "from experiments.siamese_oneshot.b_preprocess import feat_seqs\n",
    "from experiments.siamese_oneshot.c_model import build_model\n",
    "\n",
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 128\n",
    "feat_seqs = rmap(lambda s: pad_seq(s, max_time), feat_seqs)\n",
    "\n",
    "feat_seqs_train = subset(feat_seqs, train_subset)\n",
    "transformations_train = subset(transformations, train_subset)\n",
    "labels_train = labels[train_subset].astype(np.int32)\n",
    "durations_train = durations[train_subset]\n",
    "\n",
    "feat_seqs_val = subset(feat_seqs, val_subset)\n",
    "transformations_val = subset(transformations, val_subset)\n",
    "labels_val = labels[val_subset].astype(np.int32)\n",
    "durations_val = durations[val_subset]\n",
    "\n",
    "input_shape = feat_seqs[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine(x1, x2):\n",
    "    return 1 - (x1 * x2).sum(axis=1) \\\n",
    "        / (x1.norm(2, axis=1) + 0.0001) / (x2.norm(2, axis=1) + 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "buffers = [\n",
    "    np.zeros((4 * batch_size, 2, max_time) + input_shape, dtype=np.float32),\n",
    "    np.zeros((4 * batch_size, 2), dtype=np.int32),\n",
    "    np.zeros((4 * batch_size,), dtype=np.bool)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(feat_seqs[0][0].shape, 2 * batch_size, max_time)\n",
    "l_linout = model['l_linout']\n",
    "l_in = model['l_in']\n",
    "l_durations = model['l_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linout = lasagne.layers.get_output(l_linout, deterministic=True)\n",
    "dists = (linout[0::2] - linout[1::2]).norm(2, axis=1)\n",
    "predict_fn = theano.function([l_in.input_var, l_durations.input_var], outputs=dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_var = T.vector('targets')\n",
    "l_rate_var = T.scalar('l_rate')\n",
    "\n",
    "linout = lasagne.layers.get_output(l_linout, deterministic=False)\n",
    "dists = cosine(linout[0::2], linout[1::2])\n",
    "loss = T.switch(targets_var > .1,\n",
    "                .5 * T.maximum(0, dists - .25) ** 2,\n",
    "                .5 * T.maximum(0, .75 - dists) ** 2).sum()\n",
    "params = lasagne.layers.get_all_params(l_linout, trainable=True)\n",
    "updates = lasagne.updates.adam(loss, params, learning_rate=l_rate_var)\n",
    "update_fn = theano.function(\n",
    "    [l_in.input_var, l_durations.input_var, targets_var, l_rate_var],\n",
    "    outputs=loss, updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_perfs(feat_seqs_, durations_, pairs_, tgts_, thres_=None):\n",
    "    data_pairs = rmap(lambda p: np.stack([feat_seqs_[p[0]], feat_seqs_[p[1]]]), pairs_)\n",
    "    duration_pairs = np.array([[durations_[p0], durations_[p1]] for p0, p1 in  pairs_])\n",
    "    all_preds = np.empty((len(tgts_) - len(tgts_) % batch_size,))\n",
    "    all_targets = np.empty((len(tgts_) - len(tgts_) % batch_size,))\n",
    "    loader = chunk_load([data_pairs, duration_pairs, targets], buffers, batch_size, drop_last=True)\n",
    "    \n",
    "    i = 0\n",
    "    for x, d, y in loader:\n",
    "        all_preds[i:i + batch_size] = predict_fn(\n",
    "            x.reshape((2 * batch_size, max_time) + input_shape), \n",
    "            d.reshape((2 * batch_size,)))\n",
    "        all_targets[i:i + batch_size] = y\n",
    "        i += batch_size\n",
    "    \n",
    "    if thres_ is None:\n",
    "        thres_ = dichotomy(\n",
    "            lambda t: 1 - np.mean(all_preds[all_targets > .5] > t)\n",
    "                      / np.mean(all_preds[all_targets < .5] < t),\n",
    "            0, 1, it=20)\n",
    "    \n",
    "    fnr = np.mean(all_preds[all_targets > .5] > thres_)\n",
    "    fpr = np.mean(all_preds[all_targets < .5] < thres_)\n",
    "    \n",
    "    return all_targets, all_preds, thres_, fpr, fnr\n",
    "\n",
    "\n",
    "def sample_pairs(vocabulary, labels, n, positive_ratio=0.6, test=None):\n",
    "    test = test or (lambda *_: True)\n",
    "    where_labels = {l: np.where(labels == l)[0] for l in vocabulary}\n",
    "    where_not_labels = {l: np.where(labels != l)[0] for l in vocabulary}\n",
    "\n",
    "    pairs = np.empty((n, 2), dtype=np.uint64)\n",
    "    positive = np.empty((n,), dtype=np.bool)\n",
    "\n",
    "    for k, i in enumerate(np.random.permutation(n) % len(labels)):\n",
    "        l = labels[i]\n",
    "        p = np.random.random() < positive_ratio\n",
    "        if p:\n",
    "            j = np.random.choice(where_labels[l])\n",
    "            while not test(i, j):\n",
    "                j = np.random.choice(where_labels[l])\n",
    "        else:\n",
    "            j = np.random.choice(where_not_labels[l])\n",
    "\n",
    "        pairs[k] = i, j\n",
    "        positive[k] = p\n",
    "\n",
    "    return pairs, positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate = 3e-4\n",
    "\n",
    "report = shelve.open(os.path.join(tmpdir, \"rnn_report\"))\n",
    "running_loss = 0\n",
    "\n",
    "for e in range(0, 30):\n",
    "    pairs, targets = sample_pairs(\n",
    "        np.unique(labels), labels_train, len(train_subset), .5,\n",
    "        lambda i, j: transformations_train[j][0] != transformations_train[i][0])\n",
    "    data_pairs = rmap(lambda p: np.stack([feat_seqs_train[p[0]], feat_seqs_train[p[1]]]), pairs)\n",
    "    durations_pairs = rmap(lambda p: np.array([durations_train[p[0]], durations_train[p[1]]]), pairs)\n",
    "    loader = chunk_load([data_pairs, durations_pairs, targets], buffers, batch_size, drop_last=True)\n",
    "    \n",
    "    batch_losses = []\n",
    "    for (x, d, y) in loader:\n",
    "        batch_loss = update_fn(\n",
    "            x.reshape((2 * batch_size, max_time) + input_shape), \n",
    "            d.reshape((2 * batch_size,)),\n",
    "            y, l_rate)\n",
    "        batch_losses.append(batch_loss)\n",
    "        running_loss = .98 * running_loss + .02 * batch_loss\n",
    "        if len(batch_losses) % 30 == 0:\n",
    "            print(\"\\rloss: {}\".format(running_loss), end=\"\", flush=True)\n",
    "\n",
    "    # Report\n",
    "    print(\"\\repoch {:3d} loss : {}\".format(e, running_loss))\n",
    "    \n",
    "    all_targets, all_preds, thres, fpr_train, fnr_train = compute_perfs(\n",
    "        feat_seqs_train, durations_train, pairs, targets, None)\n",
    "    print(\"         thres : \", thres)\n",
    "    print(\"   fpr/fnr (t) : {:.2f}/{:.2f}\".format(fpr_train, fnr_train))\n",
    "    \n",
    "    pairs, targets = sample_pairs(np.unique(labels), labels_val, len(val_subset), .5,\n",
    "                                  lambda i, j: transformations_val[j][0] != transformations_val[i][0])\n",
    "    all_targets, all_preds, thres, fpr_val, fnr_val = compute_perfs(\n",
    "        feat_seqs_val, durations_val, pairs, targets, thres)\n",
    "    fpr_val = np.mean(all_preds[all_targets < .5] < thres)\n",
    "    fnr_val = np.mean(all_preds[all_targets > .5] > thres)\n",
    "    print(\"   fpr/fnr (v) : {:.2f}/{:.2f}\".format(fpr_val, fnr_val))\n",
    "    \n",
    "    report[str(e)] = {\n",
    "        'batch_losses': batch_losses,\n",
    "        'epoch_loss': running_loss,\n",
    "        'score_train': (fpr_train, fnr_train),\n",
    "        'score_val': (fpr_val, fnr_val),\n",
    "        'params': lasagne.layers.get_all_param_values(l_linout)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(np.arange(30), [report[str(i)]['score_train'][0] for i in range(30)], linestyle=':', color='red', label='fpr_train')\n",
    "plt.plot(np.arange(30), [report[str(i)]['score_train'][1] for i in range(30)], linestyle=':', color='blue', label='fpr_train')\n",
    "plt.plot(np.arange(30), [report[str(i)]['score_val'][0] for i in range(30)], linestyle='-', color='red', label='fpr_val')\n",
    "plt.plot(np.arange(30), [report[str(i)]['score_val'][1] for i in range(30)], linestyle='-', color='blue', label='fnr_val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_perfs(all_targets, all_preds, thres_):\n",
    "    print(\"fpr = \", np.mean(all_preds[all_targets < .5] < thres_))\n",
    "    print(\"fnr = \", np.mean(all_preds[all_targets > .5] > thres_))\n",
    "    print(\"thres = \", thres_)\n",
    "\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    bins = np.linspace(0, 1, 40)\n",
    "    pos, _ = np.histogram(all_preds[all_targets == 1], bins=bins)\n",
    "    neg, _ = np.histogram(all_preds[all_targets == 0], bins=bins)\n",
    "    plt.bar(bins[:-1], pos / pos.sum(), width=.025, color='red', alpha=.5)\n",
    "    plt.bar(bins[:-1], neg / neg.sum(), width=.025, color='blue', alpha=.5)\n",
    "    plt.plot([thres_, thres_], [0, .2])\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    fpr, tpr, _ = roc_curve(all_targets > .5, all_preds)\n",
    "    plt.plot(tpr, fpr)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "pairs, targets = sample_pairs(\n",
    "    np.unique(labels), labels_train, len(train_subset) * 3, .5,\n",
    "    lambda i, j: transformations_train[j][0] != transformations_train[i][0])\n",
    "all_targets, all_preds, thres, fpr, fnr = compute_perfs(\n",
    "    feat_seqs_train, durations_train, pairs, targets, None)\n",
    "preview_perfs(all_targets, all_preds, thres)\n",
    "print(\"  fpr / fnr (t) : {:.2f}/{:.2f}\".format(fpr, fnr))\n",
    "\n",
    "pairs, targets = sample_pairs(\n",
    "    np.unique(labels), labels_val, len(val_subset) * 3, .5,\n",
    "    lambda i, j: transformations_val[j][0] != transformations_val[i][0])\n",
    "all_targets, all_preds, thres, fpr, fnr = compute_perfs(\n",
    "    feat_seqs_val, durations_val, pairs, targets, thres)\n",
    "preview_perfs(all_targets, all_preds, thres)\n",
    "print(\"  fpr / fnr (t) : {:.2f}/{:.2f}\".format(fpr, fnr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pairs, tgts = sample_pairs(\n",
    "    np.unique(labels), labels_train, len(train_subset) * 3, .5,\n",
    "    lambda i, j: transformations_train[j][0] != transformations_train[i][0])\n",
    "cnf = confusion_matrix(labels_train[pairs[:, 0]], labels_train[pairs[:, 1]])\n",
    "print(cnf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
