{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "from bisect import bisect\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lproc import rmap, subset, chunk_load\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.siamese_triplet.a_data import tmpdir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sltools.nn_utils import adjust_length\n",
    "\n",
    "from experiments.siamese_triplet.a_data import \\\n",
    "    durations, labels, transformations, \\\n",
    "    train_subset, val_subset\n",
    "from experiments.siamese_triplet.b_preprocess import skel_feat_seqs\n",
    "\n",
    "max_time = 128\n",
    "skel_feat_seqs = rmap(lambda s: adjust_length(s, max_time), skel_feat_seqs)\n",
    "\n",
    "feats_seqs_train = [\n",
    "    subset(skel_feat_seqs, train_subset)\n",
    "    ]\n",
    "transformations_train = subset(transformations, train_subset)\n",
    "labels_train = labels[train_subset].astype(np.int32)\n",
    "durations_train = durations[train_subset].astype(np.int32)\n",
    "\n",
    "feats_seqs_val = [\n",
    "    subset(skel_feat_seqs, val_subset)\n",
    "    ]\n",
    "transformations_val = subset(transformations, val_subset)\n",
    "labels_val = labels[val_subset].astype(np.int32)\n",
    "durations_val = durations[val_subset].astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.siamese_triplet.c_model import skel_rnn\n",
    "\n",
    "batch_size = 16\n",
    "\n",
    "buffers = [np.zeros((4 * batch_size, max_time) + s[0].shape[1:], dtype=np.float32)\n",
    "           for s in feats_seqs_train] \\\n",
    "          + [np.zeros((4 * batch_size), dtype=np.int32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = skel_rnn(skel_feat_seqs[0][0].shape, batch_size, max_time)\n",
    "l_linout = model['l_linout']\n",
    "l_in = model['l_in']\n",
    "l_duration = model['l_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = shelve.open(os.path.join(tmpdir, \"rnn_report\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sltools.models.siamese import triplet_loss\n",
    "\n",
    "l_rate_var = T.scalar('l_rate')\n",
    "\n",
    "linout = lasagne.layers.get_output(l_linout, deterministic=False)\n",
    "loss = triplet_loss(linout[0::3], linout[1::3], linout[2::3]).sum()\n",
    "params = lasagne.layers.get_all_params(l_linout, trainable=True)\n",
    "updates = lasagne.updates.adam(loss, params, learning_rate=l_rate_var)\n",
    "update_fn = theano.function(\n",
    "    [l.input_var for l in l_in] + [l_duration.input_var, l_rate_var],\n",
    "    outputs=loss, updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_triplets(vocabulary, labels, n, test=None):\n",
    "    test = test or (lambda *_: True)\n",
    "    where_labels = {l: np.where(labels == l)[0] for l in vocabulary}\n",
    "    where_not_labels = {l: np.where(labels != l)[0] for l in vocabulary}\n",
    "\n",
    "    triplets = np.empty((n, 3), dtype=np.uint64)\n",
    "\n",
    "    i = 0\n",
    "    while i < len(labels):\n",
    "        left = i % len(labels)\n",
    "        wl = where_labels[labels[left]]\n",
    "        wn = where_not_labels[labels[left]]\n",
    "        middle = np.random.choice(wl)\n",
    "        right = np.random.choice(wn)\n",
    "\n",
    "        while not test(left, middle, right):\n",
    "            middle = np.random.choice(wl)\n",
    "            right = np.random.choice(wn)\n",
    "\n",
    "        triplets[i] = [left, middle, right]\n",
    "        i += 1\n",
    "\n",
    "    return triplets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report.clear()\n",
    "\n",
    "l_rate = 1e-4\n",
    "running_loss = 0\n",
    "\n",
    "for e in range(10):\n",
    "    batch_losses = []\n",
    "    triplets = np.array(sample_triplets(\n",
    "        sorted(set(labels_train)), labels_train, len(labels_train),\n",
    "        test=lambda i, j, k: transformations_train[i][0] != transformations_train[j][0]))\n",
    "    inputs = [subset(f, np.concatenate(triplets)) for f in feats_seqs_train]\n",
    "    inputs.append(durations_train[np.concatenate(triplets)])\n",
    "    minibatches = chunk_load(inputs, buffers, bloc_size=batch_size, drop_last=True)\n",
    "    \n",
    "    for i, (x, d) in enumerate(minibatches):\n",
    "        batch_loss = float(update_fn(x, d, l_rate))\n",
    "        batch_losses.append(batch_loss)\n",
    "        running_loss = .98 * running_loss + .02 * batch_loss\n",
    "        if i % 30 == 0:\n",
    "            print(\"\\rloss: {}\".format(running_loss), end=\"\", flush=True)\n",
    "  \n",
    "    report[str(e)] = {\n",
    "        'batch_losses': batch_losses,\n",
    "        'epoch_loss': running_loss,\n",
    "        'params': lasagne.layers.get_all_param_values(l_linout)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_losses = np.concatenate([r['batch_losses'] for r in report.values()])\n",
    "plt.figure(figsize=(12, 3))\n",
    "x = np.arange(0, len(batch_losses), 20)\n",
    "y = np.array([np.mean(batch_losses[max(0, i-40):i+40]) for i in range(0, len(batch_losses), 20)])\n",
    "err = np.array([np.std(batch_losses[max(0, i-40):i+40]) for i in range(0, len(batch_losses), 20)])\n",
    "\n",
    "plt.plot(x, y)\n",
    "plt.fill_between(x, y - err, y + err, alpha=.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(report.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sltools.models.siamese import build_predict_fn\n",
    "\n",
    "iteration = 9\n",
    "lasagne.layers.set_all_param_values(l_linout, report[str(iteration)]['params'])\n",
    "predict_fn = build_predict_fn(model, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vects = predict_fn(feats_seqs_train + [durations_train])\n",
    "val_vects = predict_fn(feats_seqs_val + [durations_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "from scipy.spatial.distance import cdist, pdist, squareform\n",
    "\n",
    "\n",
    "def experiment(negvects, posvects):\n",
    "    \"\"\"Check 1-nearest neighbour rank using from 1 to all \n",
    "    of same-class examples vs the negative ones.\n",
    "    \"\"\"\n",
    "    negdists = cdist(posvects, negvects)\n",
    "    posdists = squareform(pdist(posvects))\n",
    "#     posdists *= np.tril(np.ones_like(np.random.rand(4, 4)) * np.inf, k=0) + 1\n",
    "    \n",
    "    results = []\n",
    "    for i in range(1, len(posvects)):\n",
    "        posd = np.min(posdists[i, :i])\n",
    "        rank = bisect_left(negdists[i], posd)\n",
    "        results.append((i, posd, rank))\n",
    "\n",
    "    return np.array(results)\n",
    "\n",
    "\n",
    "def compute_perfs(vects, labels, ntests, k, n):\n",
    "    vocabulary = np.sort(np.unique(labels))\n",
    "    idx_where = {l: np.where(labels == l)[0] for l in vocabulary}\n",
    "    \n",
    "    results = []\n",
    "    for _ in range(ntests):\n",
    "        voca_subset = np.random.permutation(vocabulary)[:k]\n",
    "        \n",
    "        neg_where = np.concatenate([\n",
    "            idx_where[l][np.random.permutation(len(idx_where[l]))[:n]]\n",
    "            for l in voca_subset[:-1]])\n",
    "        negvects = vects[neg_where]\n",
    "        \n",
    "        pos_where = idx_where[voca_subset[-1]][\n",
    "            np.random.permutation(len(idx_where[voca_subset[-1]]))[:n]]\n",
    "        posvects = vects[pos_where]\n",
    "        \n",
    "        results.extend(np.concatenate([\n",
    "            np.full((n - 1, 1), voca_subset[-1]),\n",
    "            experiment(negvects, posvects)], axis=1))\n",
    "\n",
    "    return np.array(results)\n",
    "\n",
    "results_train = compute_perfs(\n",
    "    train_vects[:len(labels_train) // 5], \n",
    "    labels_train[:len(labels_train) // 5],\n",
    "    1000, 5, 40)\n",
    "results_val = compute_perfs(\n",
    "    val_vects, \n",
    "    labels_val,\n",
    "    1000, 5, 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(results_train[results_train[:, 1] == i, 3])\n",
    " for i in range(1, 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.mean(results_val[results_val[:, 1] == i, 3])\n",
    " for i in range(1, 15)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 16\n",
    "fig, axs = plt.subplots(nrows=5, ncols=1, figsize=(5, 12))\n",
    "for i, ax in zip(range(1, 6), axs):\n",
    "    v = results_train[results_train[:, 1] == i, 3]\n",
    "    b = np.arange(-.5, max(v) + 2, 1)\n",
    "    h, _ = np.histogram(v, bins=b)\n",
    "    h[cutoff] = np.sum(h[cutoff:])\n",
    "    h = h[:cutoff + 1]\n",
    "    ax.bar(np.arange(cutoff + 1), h / h.sum())\n",
    "    ax.set_ylim((0, 1))\n",
    "    ax.set_title(\"{}-shot\".format(i))\n",
    "    ax.set_xlabel(\"rank\")\n",
    "    ax.set_xticks([i for i in range(0, cutoff, 2)] + [cutoff])\n",
    "    ax.set_xticklabels([i for i in range(0, cutoff, 2)] + [\">{}\".format(cutoff)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff = 12\n",
    "fig, axs = plt.subplots(nrows=5, ncols=1, figsize=(5, 12))\n",
    "for i, ax in zip(range(1, 6), axs):\n",
    "    v = results_val[results_val[:, 1] == i, 3]\n",
    "    b = np.arange(-.5, max(v) + 2, 1)\n",
    "    h, _ = np.histogram(v, bins=b)\n",
    "    h[cutoff] = np.sum(h[cutoff:])\n",
    "    h = h[:cutoff + 1]\n",
    "    ax.bar(np.arange(cutoff + 1), h / h.sum())\n",
    "    ax.set_ylim((0, 1))\n",
    "    ax.set_title(\"{}-shot\".format(i))\n",
    "    ax.set_xlabel(\"rank\")\n",
    "    ax.set_xticks([i for i in range(0, cutoff, 2)] + [cutoff])\n",
    "    ax.set_xticklabels([i for i in range(0, cutoff, 2)] + [\">={}\".format(cutoff)])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(results_val[:, 2], bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
