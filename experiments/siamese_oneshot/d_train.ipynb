{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lproc import rmap, subset, chunk_load\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "from sltools.utils import pad_seq, dichotomy\n",
    "\n",
    "from experiments.siamese_oneshot.a_data import durations, labels, transformations, \\\n",
    "    train_subset, val_subset\n",
    "from experiments.siamese_oneshot.b_preprocess import feat_seqs\n",
    "from experiments.siamese_oneshot.c_model import build_model\n",
    "\n",
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_time = 128\n",
    "feat_seqs = rmap(lambda s: pad_seq(s, max_time), feat_seqs)\n",
    "\n",
    "feat_seqs_train = subset(feat_seqs, train_subset)\n",
    "transformations_train = subset(transformations, train_subset)\n",
    "labels_train = labels[train_subset].astype(np.int32)\n",
    "durations_train = durations[train_subset]\n",
    "\n",
    "feat_seqs_val = subset(feat_seqs, val_subset)\n",
    "transformations_val = subset(transformations, val_subset)\n",
    "labels_val = labels[val_subset].astype(np.int32)\n",
    "durations_val = durations[val_subset]\n",
    "\n",
    "input_shape = feat_seqs[0][0].shape\n",
    "\n",
    "def generate_pairs(transformations, labels, vocabulary, n, positive_ratio=0.6):\n",
    "    # precompute where to look for positive pairs\n",
    "    where_labels = {l: np.where(labels == l)[0] for l in vocabulary}\n",
    "    where_not_labels = {l: np.where(labels != l)[0] for l in vocabulary}\n",
    "    \n",
    "    pairs = np.empty((n, 2), dtype=np.uint64)\n",
    "    positive = np.empty((n,), dtype=np.bool)\n",
    "    \n",
    "    for k in range(n):\n",
    "        i = k % len(labels)  # simply pick left items iteratively\n",
    "        l = labels[i]\n",
    "        p = np.random.random() < positive_ratio\n",
    "        if p:\n",
    "            j = np.random.choice(where_labels[l])\n",
    "            while transformations[j][0] == transformations[i][0]:\n",
    "                j = np.random.choice(where_labels[l])\n",
    "        else:\n",
    "            j = np.random.choice(where_not_labels[l])\n",
    "        \n",
    "        pairs[k] = i, j\n",
    "        positive[k] = p\n",
    "    \n",
    "    return pairs, positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "\n",
    "model = build_model(feat_seqs[0][0].shape, batch_size, max_time)\n",
    "l_linout = model['l_linout']\n",
    "l_in_left, l_in_right = model['l_in']\n",
    "l_duration_left, l_duration_right = model['l_duration']\n",
    "linout = lasagne.layers.get_output(l_linout)\n",
    "\n",
    "# Build training routines\n",
    "targets = T.vector('targets')\n",
    "l_rate_var = T.scalar('l_rate')\n",
    "loss = T.switch(targets > .1,\n",
    "                .5 * linout ** 2,\n",
    "                .5 * T.maximum(0, 1 - linout) ** 2).sum()\n",
    "params = lasagne.layers.get_all_params(l_linout, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=l_rate_var)\n",
    "update_fn = theano.function([l_in_left.input_var, l_duration_left.input_var,\n",
    "                             l_in_right.input_var, l_duration_right.input_var,\n",
    "                             targets, l_rate_var],\n",
    "                            outputs=loss, updates=updates)\n",
    "\n",
    "linout2 = lasagne.layers.get_output(l_linout, deterministic=True)\n",
    "loss2 = T.switch(targets > .1,\n",
    "                 .5 * linout2 ** 2,\n",
    "                 .5 * T.maximum(0, 1 - linout2) ** 2)\n",
    "predict_fn = theano.function([l_in_left.input_var, l_duration_left.input_var,\n",
    "                              l_in_right.input_var, l_duration_right.input_var,\n",
    "                              targets],\n",
    "                             outputs=[linout2, loss2])\n",
    "\n",
    "running_loss = 0\n",
    "\n",
    "buffers = [np.zeros((4 * batch_size, max_time) + input_shape, dtype=np.float32),\n",
    "           np.zeros((4 * batch_size,), dtype=np.int32),\n",
    "           np.zeros((4 * batch_size, max_time) + input_shape, dtype=np.float32),\n",
    "           np.zeros((4 * batch_size,), dtype=np.int32),\n",
    "           np.zeros((4 * batch_size,), dtype=np.bool)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate = 1e-3\n",
    "\n",
    "for e in range(20):\n",
    "    pairs, tgts = generate_pairs(transformations_train, labels_train, np.unique(labels), \n",
    "                                 len(train_subset) * 2, .6)\n",
    "    x1 = rmap(lambda pair: feat_seqs_train[pair[0]], pairs)\n",
    "    x2 = rmap(lambda pair: durations_train[pair[0]], pairs)\n",
    "    x3 = rmap(lambda pair: feat_seqs_train[pair[1]], pairs)\n",
    "    x4 = rmap(lambda pair: durations_train[pair[1]], pairs)\n",
    "    for i, (xl, dl, xr, dr, tgt) in enumerate(chunk_load([x1, x2, x3, x4, tgts], buffers, \n",
    "                                                          chunk_size=batch_size, pad_last=False)):\n",
    "        if len(tgt) != batch_size:\n",
    "            continue\n",
    "        batch_loss = update_fn(xl, dl, xr, dr, tgt, l_rate)\n",
    "        running_loss = .98 * running_loss + .02 * batch_loss\n",
    "        if i % 30 == 0:\n",
    "            print(\"\\rloss: {}\".format(running_loss), end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\repoch {:3d} loss: {}\".format(e, running_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_perfs(feat_seqs_, durations_, pairs_, tgts_, predict_fn_, buffers_, thres_=None):\n",
    "    x1 = rmap(lambda pair: feat_seqs_[pair[0]], pairs)\n",
    "    x2 = rmap(lambda pair: durations_[pair[0]], pairs)\n",
    "    x3 = rmap(lambda pair: feat_seqs_[pair[1]], pairs)\n",
    "    x4 = rmap(lambda pair: durations_[pair[1]], pairs)\n",
    "    all_preds = np.empty((len(tgts_) - len(tgts_) % batch_size,))\n",
    "    all_losses = np.empty((len(tgts_) - len(tgts_) % batch_size,))\n",
    "    all_targets = np.empty((len(tgts_) - len(tgts_) % batch_size,))\n",
    "    i = 0\n",
    "    for xl, dl, xr, dr, tgt in chunk_load([x1, x2, x3, x4, tgts], buffers_, \n",
    "                                           chunk_size=batch_size, drop_last=True):\n",
    "        all_preds[i:i + batch_size], all_losses[i:i + batch_size] = \\\n",
    "            predict_fn_(xl, dl, xr, dr, tgt)\n",
    "        all_targets[i:i + batch_size] = tgt\n",
    "        i += len(tgt)\n",
    "    \n",
    "    if thres_ is None:\n",
    "        thres_ = dichotomy(\n",
    "            lambda t: 1 - np.mean(all_preds[all_targets > .5] > t)\n",
    "                      / np.mean(all_preds[all_targets < .5] < t),\n",
    "            min(all_preds), max(all_preds), it=20)\n",
    "\n",
    "    print(\"fnr = \", np.mean(all_preds[all_targets < .5] < thres_))\n",
    "    print(\"fpr = \", np.mean(all_preds[all_targets > .5] > thres_))\n",
    "    print(\"thres = \", thres_)\n",
    "\n",
    "    # observe training results\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    bins = np.linspace(0, 1, 40)\n",
    "    pos, _ = np.histogram(all_preds[all_targets == 1], bins=bins)\n",
    "    neg, _ = np.histogram(all_preds[all_targets == 0], bins=bins)\n",
    "    plt.bar(bins[:-1], pos / pos.sum(), width=.025, color='red', alpha=.5)\n",
    "    plt.bar(bins[:-1], neg / neg.sum(), width=.025, color='blue', alpha=.5)\n",
    "    plt.plot([thres_, thres_], [0, 1])\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    fpr, tpr, _ = roc_curve(all_targets > .5, all_preds)\n",
    "    plt.plot(tpr, fpr)\n",
    "    plt.gca().set_aspect('equal')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return all_targets, all_preds, thres_\n",
    "\n",
    "\n",
    "pairs, tgts = generate_pairs(transformations_train, labels_train, np.unique(labels), \n",
    "                             len(train_subset) * 2, .6)\n",
    "all_targets, all_preds, thres = preview_perfs(\n",
    "    feat_seqs_train, durations_train, pairs, tgts, predict_fn, buffers, None)\n",
    "\n",
    "pairs, tgts = generate_pairs(transformations_val, labels_val, np.unique(labels), \n",
    "                             len(val_subset) * 2, .6)\n",
    "all_targets, all_preds, thres = preview_perfs(\n",
    "    feat_seqs_val, durations_val, pairs, tgts, predict_fn, buffers, thres)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "pairs, tgts = generate_pairs(transformations_train, labels_train, np.unique(labels),\n",
    "                             len(train_subset) * 2, positive_ratio)\n",
    "cnf = confusion_matrix(labels_train[pairs[:, 0]], labels_train[pairs[:, 1]])\n",
    "print(cnf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
