{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "from lproc import rmap, subset, chunk_load\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "from experiments.siamese_oneshot.a_data import durations, labels, transformations, \\\n",
    "    train_subset, val_subset\n",
    "from experiments.siamese_oneshot.b_preprocess import feat_seqs\n",
    "from experiments.siamese_oneshot.c_model import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "\n",
    "max_time = 128\n",
    "batch_size = 16\n",
    "\n",
    "model = build_model(feat_seqs[0][0].shape, batch_size, max_time)\n",
    "l_linout = model['l_linout']\n",
    "l_in_left, l_in_right = model['l_in']\n",
    "l_duration_left, l_duration_right = model['l_duration']\n",
    "linout = lasagne.layers.get_output(l_linout)\n",
    "\n",
    "# Build training routines\n",
    "targets = T.vector('targets')\n",
    "l_rate_var = T.scalar('l_rate')\n",
    "loss = T.switch(targets > .1,\n",
    "                .5 * linout ** 2,\n",
    "                .5 * T.maximum(0, 1 - linout) ** 2).sum()\n",
    "params = lasagne.layers.get_all_params(l_linout, trainable=True)\n",
    "updates = lasagne.updates.nesterov_momentum(loss, params, learning_rate=l_rate_var)\n",
    "update_fn = theano.function([l_in_left.input_var, l_duration_left.input_var,\n",
    "                             l_in_right.input_var, l_duration_right.input_var,\n",
    "                             targets, l_rate_var],\n",
    "                            outputs=loss, updates=updates)\n",
    "\n",
    "linout2 = lasagne.layers.get_output(l_linout, deterministic=True)\n",
    "loss2 = T.switch(targets > .1,\n",
    "                 .5 * linout2 ** 2,\n",
    "                 .5 * T.maximum(0, 1 - linout2) ** 2)\n",
    "predict_fn = theano.function([l_in_left.input_var, l_duration_left.input_var,\n",
    "                              l_in_right.input_var, l_duration_right.input_var,\n",
    "                              targets],\n",
    "                             outputs=[linout2, loss2])\n",
    "\n",
    "running_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "\n",
    "def pad_seq(seq):\n",
    "    return np.concatenate((seq[:max_time],\n",
    "                           np.zeros((max(0, max_time - len(seq)),) + seq.shape[1:],\n",
    "                                    dtype=seq.dtype)))\n",
    "\n",
    "feat_seqs_train = subset(feat_seqs, train_subset)\n",
    "feat_seqs_train = rmap(pad_seq, feat_seqs)\n",
    "transformations_train = subset(transformations, train_subset)\n",
    "labels_train = labels[train_subset].astype(np.int32)\n",
    "durations_train = durations[train_subset]\n",
    "\n",
    "feat_seqs_val = subset(feat_seqs, val_subset)\n",
    "feat_seqs_val = rmap(pad_seq, feat_seqs_val)\n",
    "transformations_val = subset(transformations, val_subset)\n",
    "labels_val = labels[val_subset].astype(np.int32)\n",
    "durations_val = durations[val_subset]\n",
    "\n",
    "input_shape = feat_seqs[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run training iterations\n",
    "def generate_pairs(transformations, labels, vocabulary, n, positive_ratio):\n",
    "    # precompute where to look for positive pairs\n",
    "    where_labels = {l: np.where(labels == l)[0] for l in vocabulary}\n",
    "    where_not_labels = {l: np.where(labels != l)[0] for l in vocabulary}\n",
    "    \n",
    "    pairs = np.empty((n, 2), dtype=np.uint64)\n",
    "    positive = np.empty((n,), dtype=np.bool)\n",
    "    \n",
    "    for k in range(n):\n",
    "        i = k % len(labels)  # simply pick left items iteratively\n",
    "        l = labels[i]\n",
    "        p = np.random.random() < positive_ratio\n",
    "        if p:\n",
    "            j = np.random.choice(where_labels[l])\n",
    "            while transformations[j][0] == transformations[i][0]:\n",
    "                j = np.random.choice(where_labels[l])\n",
    "        else:\n",
    "            j = np.random.choice(where_not_labels[l])\n",
    "        \n",
    "        pairs[k] = i, j\n",
    "        positive[k] = p\n",
    "    \n",
    "    return pairs, positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_rate = 1e-3\n",
    "positive_ratio = 0.6\n",
    "\n",
    "buffers = [np.zeros((4 * batch_size, max_time) + input_shape, dtype=np.float32),\n",
    "           np.zeros((4 * batch_size,), dtype=np.int32),\n",
    "           np.zeros((4 * batch_size, max_time) + input_shape, dtype=np.float32),\n",
    "           np.zeros((4 * batch_size,), dtype=np.int32),\n",
    "           np.zeros((4 * batch_size,), dtype=np.bool)]\n",
    "\n",
    "for e in range(10):\n",
    "    pairs, tgts = generate_pairs(transformations_train, labels_train, np.unique(labels), \n",
    "                                 len(train_subset) * 2, positive_ratio)\n",
    "    x1 = rmap(lambda pair: feat_seqs_train[pair[0]], pairs)\n",
    "    x2 = rmap(lambda pair: durations_train[pair[0]], pairs)\n",
    "    x3 = rmap(lambda pair: feat_seqs_train[pair[1]], pairs)\n",
    "    x4 = rmap(lambda pair: durations_train[pair[1]], pairs)\n",
    "    for i, (xl, dl, xr, dr, tgt) in enumerate(chunk_load([x1, x2, x3, x4, tgts], buffers, \n",
    "                                                          chunk_size=batch_size, pad_last=False)):\n",
    "        if len(tgt) != batch_size:\n",
    "            continue\n",
    "        batch_loss = update_fn(xl, dl, xr, dr, tgt, l_rate)\n",
    "        running_loss = .98 * running_loss + .02 * batch_loss\n",
    "        if i % 30 == 0:\n",
    "            print(\"\\rloss: {}\".format(running_loss), end=\"\", flush=True)\n",
    "\n",
    "    print(\"\\repoch {:3d} loss: {}\".format(e, running_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview results\n",
    "\n",
    "# search for eer threshold\n",
    "positive_ratio = 0.6\n",
    "pairs, tgts = generate_pairs(transformations_train, labels_train, np.unique(labels), \n",
    "                             len(train_subset) * 2, positive_ratio)\n",
    "x1 = rmap(lambda pair: feat_seqs_train[pair[0]], pairs)\n",
    "x2 = rmap(lambda pair: durations_train[pair[0]], pairs)\n",
    "x3 = rmap(lambda pair: feat_seqs_train[pair[1]], pairs)\n",
    "x4 = rmap(lambda pair: durations_train[pair[1]], pairs)\n",
    "all_preds = np.empty((len(tgts) - len(tgts) % batch_size,))\n",
    "all_losses = np.empty((len(tgts) - len(tgts) % batch_size,))\n",
    "all_targets = np.empty((len(tgts) - len(tgts) % batch_size,))\n",
    "i = 0\n",
    "for xl, dl, xr, dr, tgt in chunk_load([x1, x2, x3, x4, tgts], buffers, \n",
    "                                       chunk_size=batch_size, pad_last=False):\n",
    "    if len(tgt) != batch_size:\n",
    "        continue\n",
    "    all_preds[i:i + len(tgt)], all_losses[i:i + len(tgt)] = \\\n",
    "        predict_fn(xl, dl, xr, dr, tgt)\n",
    "    all_targets[i:i + len(tgt)] = tgt\n",
    "    i += len(tgt)\n",
    "\n",
    "eer_thres = 0\n",
    "erdiff = 1\n",
    "for t in np.linspace(0, max(all_preds), 100):\n",
    "    erdiff_ = np.abs(np.mean(all_preds[all_targets > .5] > t) \n",
    "                     - np.mean(all_preds[all_targets < .5] < t))\n",
    "    if erdiff_ < erdiff:\n",
    "        eer_thres = t\n",
    "        erdiff = erdiff_\n",
    "\n",
    "print(\"training fnr = \", np.mean(all_preds[all_targets < .5] < eer_thres))\n",
    "print(\"training fpr = \", np.mean(all_preds[all_targets > .5] > eer_thres))\n",
    "\n",
    "# observe training results\n",
    "plt.figure()\n",
    "bins = np.linspace(0, 2, 40)\n",
    "pos, _ = np.histogram(all_preds[all_targets == 1], bins=bins)\n",
    "neg, _ = np.histogram(all_preds[all_targets == 0], bins=bins)\n",
    "plt.bar(bins[:-1], pos, width=.025, color='red', alpha=.5)\n",
    "plt.bar(bins[:-1], neg, width=.025, color='blue', alpha=.5)\n",
    "\n",
    "# observe validation results\n",
    "positive_ratio = 0.4\n",
    "pairs, tgts = generate_pairs(transformations_val, labels_val, np.unique(labels),\n",
    "                             len(val_subset) * 2, positive_ratio)\n",
    "x1 = rmap(lambda pair: feat_seqs_val[pair[0]], pairs)\n",
    "x2 = rmap(lambda pair: durations_val[pair[0]], pairs)\n",
    "x3 = rmap(lambda pair: feat_seqs_val[pair[1]], pairs)\n",
    "x4 = rmap(lambda pair: durations_val[pair[1]], pairs)\n",
    "all_preds = np.empty((len(tgts) - len(tgts) % batch_size,))\n",
    "all_losses = np.empty((len(tgts) - len(tgts) % batch_size,))\n",
    "all_targets = np.empty((len(tgts) - len(tgts) % batch_size,))\n",
    "i = 0\n",
    "for xl, dl, xr, dr, tgt in chunk_load([x1, x2, x3, x4, tgts], buffers, \n",
    "                                       chunk_size=batch_size, pad_last=False):\n",
    "    if len(tgt) != batch_size:\n",
    "        continue\n",
    "    all_preds[i:i + len(tgt)], all_losses[i:i + len(tgt)] = \\\n",
    "        predict_fn(xl, dl, xr, dr, tgt)\n",
    "    all_targets[i:i + len(tgt)] = tgt\n",
    "    i += len(tgt)\n",
    "\n",
    "plt.figure()\n",
    "bins = np.linspace(0, 2, 40)\n",
    "pos, _ = np.histogram(all_preds[all_targets == 1], bins=bins)\n",
    "neg, _ = np.histogram(all_preds[all_targets == 0], bins=bins)\n",
    "plt.bar(bins[:-1], pos, width=.025, color='red', alpha=.5)\n",
    "plt.bar(bins[:-1], neg, width=.025, color='blue', alpha=.5)\n",
    "\n",
    "fpr, tpr, thres = roc_curve(all_targets > .5, all_preds)\n",
    "plt.figure()\n",
    "plt.plot(tpr, fpr)\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.show()\n",
    "\n",
    "print(\"eer thres = \", eer_thres)\n",
    "print(\"fnr at eer = \", np.mean(all_preds[all_targets > .5] > eer_thres))\n",
    "print(\"fpr at eer = \", np.mean(all_preds[all_targets < .5] < eer_thres))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
