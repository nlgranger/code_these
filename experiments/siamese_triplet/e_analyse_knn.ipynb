{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib notebook\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne\n",
    "import seqtools\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.spatial.distance import cdist\n",
    "\n",
    "from experiments.siamese_triplet.a_data import \\\n",
    "    cachedir, durations, labels, recordings, \\\n",
    "    train_subset, val_subset\n",
    "from experiments.siamese_triplet.b_preprocess import skel_feat_seqs\n",
    "from experiments.siamese_triplet.c_model import skel_rnn, build_predict_fn\n",
    "\n",
    "np.set_printoptions(linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "report = shelve.open(os.path.join(cachedir, \"rnn_report\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, unique_indices = np.unique(recordings[train_subset], return_index=True)\n",
    "feat_seqs_train = [\n",
    "    seqtools.gather(skel_feat_seqs, train_subset[unique_indices])\n",
    "]\n",
    "labels_train = labels[train_subset[unique_indices]].astype(np.int32)\n",
    "durations_train = durations[train_subset[unique_indices]].astype(np.int32)\n",
    "\n",
    "feat_seqs_val = [\n",
    "    seqtools.gather(skel_feat_seqs, val_subset)\n",
    "]\n",
    "labels_val = labels[val_subset].astype(np.int32)\n",
    "durations_val = durations[val_subset].astype(np.int32)\n",
    "\n",
    "del recordings, labels, durations, skel_feat_seqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dict = skel_rnn(\n",
    "    *tuple(f[0][0].shape for f in feat_seqs_train), \n",
    "    batch_size=report['meta']['batch_size'], max_time=report['meta']['max_time'], \n",
    "    encoder_kwargs=report['meta']['encoder_kwargs'])\n",
    "\n",
    "l_linout = model_dict['l_linout']\n",
    "l_in = model_dict['l_in']\n",
    "l_duration = model_dict['l_duration']\n",
    "\n",
    "lasagne.layers.set_all_param_values(l_linout, report['9']['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview learning progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "batch_losses = np.concatenate([r['train_losses'] for r in report.values() if 'train_losses' in r])\n",
    "\n",
    "x = np.arange(len(batch_losses))\n",
    "y = np.array([np.mean(batch_losses[max(0, i-100):i+100]) for i in range(0, len(batch_losses))])\n",
    "err = np.array([np.std(batch_losses[max(0, i-100):i+100]) for i in range(0, len(batch_losses))])\n",
    "plt.plot(x, y)\n",
    "plt.fill_between(x, y - err, y + err, alpha=.3)\n",
    "\n",
    "batch_losses = np.concatenate([r['val_losses'] for r in report.values() if 'val_losses' in r])\n",
    "\n",
    "x = np.arange(len(batch_losses))\n",
    "y = np.array([np.mean(batch_losses[max(0, i-100):i+100]) for i in range(0, len(batch_losses))])\n",
    "err = np.array([np.std(batch_losses[max(0, i-100):i+100]) for i in range(0, len(batch_losses))])\n",
    "plt.plot(x, y)\n",
    "plt.fill_between(x, y - err, y + err, alpha=.3)\n",
    "\n",
    "plt.xlabel(\"training iterations\")\n",
    "plt.ylabel(\"triplet loss\")\n",
    "plt.legend(['training', 'testing'])\n",
    "\n",
    "plt.gca().set_ylim((-0.2, 0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_episode(labels, voca_size, shots):\n",
    "    vocabulary = np.sort(np.unique(labels))\n",
    "\n",
    "    ep_vocabulary = np.random.choice(vocabulary, size=voca_size, replace=False)\n",
    "\n",
    "    ep_train_subset = []\n",
    "    ep_test_subset = []\n",
    "    for l in ep_vocabulary:\n",
    "        where_label = np.random.permutation(np.where(labels == l)[0])\n",
    "        ep_train_subset.extend(where_label[:shots])\n",
    "        ep_test_subset.extend(where_label[shots:])\n",
    "\n",
    "    return np.array(ep_train_subset), np.array(ep_test_subset)\n",
    "\n",
    "\n",
    "def evaluate_knn(x_train, x_test, labels_train, labels_test, k):\n",
    "    ep_vocabulary = np.unique(labels_train)\n",
    "\n",
    "    dists = cdist(x_test, x_train, metric='cosine')\n",
    "\n",
    "    neighbours = np.argsort(dists, axis=1)[:, :k]\n",
    "\n",
    "    neighbours_labels = labels_train[None, neighbours][0]\n",
    "    neighbours_dists = dists[np.arange(len(labels_test))[:, None], neighbours]\n",
    "\n",
    "    stats = np.empty((len(labels_test), len(ep_vocabulary)),\n",
    "                     dtype=[('freq', 'i4'), ('dist_score', 'f4'), ('class', 'i4')])\n",
    "    for i, l in enumerate(ep_vocabulary):\n",
    "        stats['freq'][:, i] = np.sum(neighbours_labels == l, axis=1)\n",
    "        stats['dist_score'][:, i] = -np.sum(neighbours_dists * (neighbours_labels == l),\n",
    "                                            axis=1)\n",
    "        stats['class'][:, i] = l\n",
    "\n",
    "    stats = np.sort(stats, axis=1)\n",
    "\n",
    "    ranks = len(ep_vocabulary) - 1 \\\n",
    "        - np.argmax(labels_test[:, None] == stats['class'], axis=1)\n",
    "\n",
    "    return ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iteration = 9\n",
    "# lasagne.layers.set_all_param_values(l_linout, report[str(iteration)]['params'])\n",
    "\n",
    "predict_fn = build_predict_fn(model_dict, report['meta']['batch_size'], report['meta']['max_time'])\n",
    "embeddings_train = predict_fn(feat_seqs_train, durations_train)\n",
    "embeddings_val = predict_fn(feat_seqs_val, durations_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shots_grid = np.array([1, 2, 3, 4, 5])\n",
    "voca_size_grid = np.array([5, 10, 15, 20, 25, 30])\n",
    "k = 1\n",
    "\n",
    "train_results = np.empty((len(shots_grid), len(voca_size_grid)))\n",
    "for i, shots in enumerate(shots_grid):\n",
    "    for j, voca_size in enumerate(voca_size_grid):\n",
    "        print(\"\\r{}/{}\".format(i, j), end='', flush=True)\n",
    "        ranks = []\n",
    "        for _ in range(200):\n",
    "            ep_train_subset, ep_test_subset = sample_episode(labels_train, voca_size, shots)\n",
    "            ep_ranks = evaluate_knn(\n",
    "                embeddings_train[ep_train_subset], embeddings_train[ep_test_subset], \n",
    "                labels_train[ep_train_subset], labels_train[ep_test_subset], \n",
    "                k)\n",
    "            ranks.extend(ep_ranks)\n",
    "        \n",
    "        train_results[i, j] = np.mean(np.array(ranks) == 0)\n",
    "\n",
    "print(\"\\rdone\")\n",
    "\n",
    "val_results = np.empty((len(shots_grid), len(voca_size_grid)))\n",
    "for i, shots in enumerate(shots_grid):\n",
    "    print(\"\\r{}/{}\".format(i, j), end='', flush=True)\n",
    "    for j, voca_size in enumerate(voca_size_grid):\n",
    "        ranks = []\n",
    "        for _ in range(200):\n",
    "            ep_train_subset, ep_test_subset = sample_episode(labels_val, voca_size, shots)\n",
    "            ep_ranks = evaluate_knn(\n",
    "                embeddings_val[ep_train_subset], embeddings_val[ep_test_subset],\n",
    "                labels_val[ep_train_subset], labels_val[ep_test_subset], \n",
    "                k)\n",
    "            ranks.extend(ep_ranks)\n",
    "        \n",
    "        val_results[i, j] = np.mean(np.array(ranks) == 0)\n",
    "\n",
    "print(\"\\rdone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(9, 4), dpi=(100))\n",
    "\n",
    "ax = fig.add_subplot(121, projection='3d')\n",
    "ax.plot_wireframe(\n",
    "    np.tile(shots_grid[:, None], (1, len(voca_size_grid))),\n",
    "    np.tile(voca_size_grid[None, :], (len(shots_grid), 1)),\n",
    "    train_results,\n",
    "    alpha=1.)\n",
    "ax.scatter(\n",
    "    np.tile(shots_grid[:, None], (1, len(voca_size_grid))),\n",
    "    np.tile(voca_size_grid[None, :], (len(shots_grid), 1)),\n",
    "    train_results,\n",
    "    c=np.ravel(train_results),\n",
    "    alpha=1.)\n",
    "for j in range(len(voca_size_grid)):\n",
    "    ax.plot(shots_grid, train_results[:, j], zs=0, zdir='y', c='black', alpha=0.3)\n",
    "\n",
    "ax.set_xticks(shots_grid)\n",
    "ax.set_yticks(voca_size_grid)\n",
    "ax.set_zlim(min(np.min(train_results), np.min(val_results)), 1)\n",
    "ax.set_xlabel(\"shots\")\n",
    "ax.set_ylabel(\"vocabulary\")\n",
    "ax.set_zlabel(\"accuracy\")\n",
    "ax.set_title(\"training\")\n",
    "\n",
    "# ax.view_init(15, 290)\n",
    "ax.view_init(20, 140)\n",
    "\n",
    "ax = fig.add_subplot(122, projection='3d')\n",
    "ax.plot_wireframe(\n",
    "    np.tile(shots_grid[:, None], (1, len(voca_size_grid))),\n",
    "    np.tile(voca_size_grid[None, :], (len(shots_grid), 1)),\n",
    "    val_results,\n",
    "    alpha=1.)\n",
    "ax.scatter(\n",
    "    np.tile(shots_grid[:, None], (1, len(voca_size_grid))),\n",
    "    np.tile(voca_size_grid[None, :], (len(shots_grid), 1)),\n",
    "    val_results,\n",
    "    c=np.ravel(val_results),\n",
    "    alpha=1.)\n",
    "for j in range(len(voca_size_grid)):\n",
    "    ax.plot(shots_grid, val_results[:, j], zs=0, zdir='y', c='black', alpha=0.3)\n",
    "\n",
    "ax.set_xticks(shots_grid)\n",
    "ax.set_yticks(voca_size_grid)\n",
    "ax.set_zlim(min(np.min(train_results), np.min(val_results)), 1)\n",
    "ax.set_xlabel(\"shots\")\n",
    "ax.set_ylabel(\"vocabulary\")\n",
    "ax.set_zlabel(\"accuracy\")\n",
    "ax.set_title(\"testing\")\n",
    "\n",
    "# ax.view_init(15, 290)\n",
    "ax.view_init(20, 140)\n",
    "\n",
    "fig.savefig('/home/granger/oneshot.png')\n",
    "\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
