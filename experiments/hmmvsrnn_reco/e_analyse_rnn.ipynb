{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import pprint\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from lproc import subset, rmap\n",
    "import seqtools\n",
    "from datasets import ch14dataset as dataset\n",
    "from sltools.utils import gloss2seq, seq2gloss\n",
    "from sltools.nn_utils import onehot, jaccard, compute_scores, make_nn_sequence_mapper\n",
    "from sltools.postproc import optimize_boundaries, filter_longshort\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.hmmvsrnn_reco.a_data import durations, gloss_seqs, tmpdir, \\\n",
    "   train_subset, val_subset, test_subset, vocabulary\n",
    "from experiments.hmmvsrnn_reco.utils import autoreload_feats, reload_best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = \"rnn_skel_tc3_180213\"\n",
    "report = shelve.open(os.path.join(tmpdir, experiment_name))\n",
    "# model = \"rnn\"\n",
    "# modality = \"skel\"\n",
    "# variant = \"tc3\"\n",
    "# date = \"180213\"\n",
    "model = report['meta']['model']\n",
    "modality = report['meta']['modality']\n",
    "variant = report['meta']['variant']\n",
    "date = report['meta']['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_seqs = autoreload_feats(modality)\n",
    "\n",
    "feat_seqs_train = [seqtools.gather(f, train_subset) for f in feat_seqs]\n",
    "gloss_seqs_train = seqtools.gather(gloss_seqs, train_subset)\n",
    "durations_train = subset(durations, train_subset)\n",
    "targets_train = seqtools.smap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                              gloss_seqs_train, durations_train)\n",
    "\n",
    "feat_seqs_val = [seqtools.gather(f, val_subset) for f in feat_seqs]\n",
    "gloss_seqs_val = seqtools.gather(gloss_seqs, val_subset)\n",
    "durations_val = seqtools.gather(durations, val_subset)\n",
    "targets_val = seqtools.smap(lambda g, d: gloss2seq(g, d, 0), \n",
    "                            gloss_seqs_val, durations_val)\n",
    "\n",
    "feat_seqs_test = [seqtools.gather(f, val_subset) for f in feat_seqs]\n",
    "gloss_seqs_test = seqtools.gather(gloss_seqs, test_subset)\n",
    "durations_test = seqtools.gather(durations, test_subset)\n",
    "targets_test = seqtools.smap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                             gloss_seqs_test, durations_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batch_losses = []\n",
    "all_epoch_losses = []\n",
    "for i in sorted([e for e in report.keys() if e.startswith(\"epoch\")]):\n",
    "    r = report[i]\n",
    "    all_batch_losses += r['batch_losses']\n",
    "    all_epoch_losses.append(r['epoch_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(np.arange(len(all_epoch_losses)), all_epoch_losses, c='red')\n",
    "n_batches = len(all_batch_losses) // len(all_epoch_losses)\n",
    "error = np.array([np.std(all_batch_losses[i:i+n_batches]) \n",
    "                  for i in range(0, len(all_batch_losses), n_batches)])\n",
    "# plt.fill_between(np.arange(len(all_epoch_losses)), \n",
    "#                  np.maximum(0.00001, all_epoch_losses - error), \n",
    "#                  all_epoch_losses + error)\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "# plt.semilogy([10 ** (i - 5) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch, model_dict, predict_fn = reload_best_model(report)\n",
    "\n",
    "print(\"best epoch: {}\".format(best_epoch))\n",
    "\n",
    "epoch_report = report[best_epoch]\n",
    "print(epoch_report['train_scores']['jaccard'])\n",
    "print(epoch_report['train_scores']['framewise'])\n",
    "print(epoch_report['val_scores']['jaccard'])\n",
    "print(epoch_report['train_scores']['framewise'] - epoch_report['val_scores']['framewise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = [np.argmax(p, axis=1) for p in predict_fn(feat_seqs_train)]\n",
    "ji_train, framewise_train, confusion_train = compute_scores(predictions_train, targets_train, vocabulary)\n",
    "\n",
    "# predictions_val = [np.argmax(p, axis=1) for p in predict_fn(feats_seqs_val)]\n",
    "# ji_val, framewise_val, confusion_val = compute_scores(predictions_val, targets_val, vocabulary)\n",
    "\n",
    "# print(\"JI: {:.4f} / {:.4f}\".format(ji_train, ji_val))\n",
    "# print(\"Accuracy: {:.4f} / {:.4f}\".format(framewise_train, framewise_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = [\n",
    "    'âˆ…','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo']\n",
    "\n",
    "cmap = matplotlib.cm.viridis\n",
    "cmap.set_bad(cmap(0.001))\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(6, 4))\n",
    "im = ax1.matshow(confusion_train / np.sum(confusion_train, axis=1, keepdims=True), \n",
    "                 interpolation='none', cmap=cmap,\n",
    "                 clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "ax1.set_yticks(np.arange(0, 22, 1))\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticklabels(cnames)\n",
    "\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "fig, ax2 = plt.subplots(1, 1, figsize=(6, 4))\n",
    "im = ax2.matshow(confusion_val / np.sum(confusion_val, axis=1, keepdims=True), \n",
    "                 interpolation='none', cmap='viridis',\n",
    "                 clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "ax2.set_yticks(np.arange(0, 22, 1))\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticklabels(cnames)\n",
    "\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_seq(proba, ax=None):\n",
    "    # 21 distinct colors\n",
    "    \n",
    "    cmap = np.array([[113,204,0], [209,73,251], [243,255,52], [223,119,255], \n",
    "         [139,255,150], [255,66,189], [1,222,201], [255,77,30], \n",
    "         [0,149,225], [137,106,0], [0,43,105], [255,230,180], \n",
    "         [111,0,66], [0,113,63], [251,177,255], [56,96,0], \n",
    "         [160,218,255], [74,0,6], [255,170,172], [0,62,95], \n",
    "         [93,43,0]]) / 255\n",
    "    \n",
    "    ax = ax or plt.gca()\n",
    "    l = np.argmax(proba, axis=1)\n",
    "    for g, start, stop in seq2gloss(l):\n",
    "        start = max(0, start - 1)\n",
    "        stop = min(len(proba), stop + 1)\n",
    "        if g == 0:\n",
    "            ax.plot(np.arange(start, stop), proba[start:stop, 0], ls=':', c=cmap[0])\n",
    "        else:\n",
    "            ax.plot(np.arange(start, stop), proba[start:stop, g], c=cmap[g])\n",
    "            ax.fill_between(np.arange(start, stop),\n",
    "                            0, proba[start:stop, g],\n",
    "                            facecolor=cmap[g],\n",
    "                            alpha=0.3)\n",
    "    ax.set_ylim((0.1, 1.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 62\n",
    "\n",
    "proba = predict_fn([[fseq[s]] for fseq in feats_seqs_val])[0]\n",
    "labels = onehot(gloss2seq(gloss_seqs_val[s], durations_val[s], 0), \n",
    "                np.arange(0, 21))\n",
    "\n",
    "f = plt.figure(figsize=(13, 2))\n",
    "ax = f.add_subplot(111)\n",
    "preview_seq(proba[:], ax)\n",
    "plt.title(\"model predictions\")\n",
    "plt.show()\n",
    "f = plt.figure(figsize=(13, .7))\n",
    "ax = f.add_subplot(111)\n",
    "preview_seq(labels[:] * 1.0,  ax)\n",
    "plt.title(\"targets\")\n",
    "plt.show()\n",
    "\n",
    "# print(transformations[val_subset_augmented[s]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of errors\n",
    "\n",
    "scores = [jaccard(onehot(l, vocabulary), onehot(p, vocabulary))\n",
    "         for l, p in zip(targets_val, predictions_val)]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(scores, np.linspace(0.0, 1, 40))\n",
    "plt.title(\"Histogram of sequence-wise JI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of false positives out of sequence vocabulary\n",
    "np.mean([len(set(p_) - set(l_)) for p_, l_ in zip(predictions_val, targets_val)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion types\n",
    "cum_err = np.sum(confusion_val, axis=1) - np.diag(confusion_val)\n",
    "print(\"false pos: {}  false neg: {}, mis-class: {}\".format(\n",
    "    cum_err[0], np.sum(confusion_val[1:, 0]), np.sum(cum_err[1:]) - np.sum(confusion_val[1:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate error with predicted gloss duration\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "prediction_accuracy = [np.sum(l[start:stop] == g) \n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "none_accuracy = [np.sum(l[start:stop] == 0)\n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "gloss_d = [stop - start\n",
    "           for p in predictions_val \n",
    "           for (g, start, stop) in seq2gloss(p)\n",
    "           if g != 0]\n",
    "\n",
    "scores_pred = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "scores_none = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "total_d = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "for vp, vn, d in zip(prediction_accuracy, none_accuracy, gloss_d):\n",
    "    idx = int(d / 5)\n",
    "    scores_pred[idx] += vp\n",
    "    scores_none[idx] += vn\n",
    "    total_d[idx] += d\n",
    "\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5), \n",
    "              scores_pred / total_d,\n",
    "              width=5,\n",
    "              alpha=.5)\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5), \n",
    "              scores_none / total_d,\n",
    "              width=5,\n",
    "              alpha=.5)\n",
    "\n",
    "plt.legend([\"predicted class\", \"non-gesture class\"])\n",
    "plt.xlabel(\"subsequence duration (based on model prediction)\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize duration filter\n",
    "\n",
    "boundaries = optimize_boundaries(targets_val, predictions_val, vocabulary, (30, 100, 301))\n",
    "print(\"Optimal range: \", boundaries)\n",
    "print(\"FYI the score without is: {:.4f}\".format(ji_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation score\n",
    "\n",
    "ji_filtered_val, accuracy_filtered_val, confusion_filtered_val = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_val], \n",
    "    targets_val, vocabulary)\n",
    "print(\"validation score: {:.4f}\".format(ji_filtered_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "\n",
    "predictions_test = [np.argmax(p, axis=1) for p in predict_fn(feats_seqs_test)]\n",
    "\n",
    "ji_filtered_test, accuracy_filtered_test, confusion_filtered_test = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_test], \n",
    "    targets_test, vocabulary)\n",
    "print(\"testing score: {:.4f}\".format(ji_filtered_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recap:\n",
    "\n",
    "print(\"JI: {:.4f} / {:.4f}\".format(ji_train, ji_val))\n",
    "print(\"Accuracy: {:.4f} / {:.4f}\".format(framewise_train, framewise_val))\n",
    "\n",
    "recap = {\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"accuracy\": (framewise_train, framewise_val, None),\n",
    "    \"ji\": (ji_train, ji_val, None),\n",
    "    \"confusion\": (confusion_train, confusion_val, None),\n",
    "    \"accuracy_filtered\": (None, accuracy_filtered_val, accuracy_filtered_test),\n",
    "    \"ji_filtered\": (None, ji_filtered_val, ji_filtered_test),\n",
    "    \"confusion_filtered\": (None, confusion_filtered_val, None),\n",
    "}\n",
    "report['analysis'] = recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# from sltools.tconv import TemporalConv\n",
    "\n",
    "# tc_l = None\n",
    "# layers = lasagne.layers.get_all_layers(model_dict['l_linout'])\n",
    "\n",
    "# for l in layers:\n",
    "#     if isinstance(l, TemporalConv):\n",
    "#         tc_l = l\n",
    "#         break\n",
    "\n",
    "# W = np.asarray(tc_l.W.eval())\n",
    "# tsne = TSNE(n_components=1, n_iter=5000, n_iter_without_progress=100, verbose=True)\n",
    "# filter_order = np.argsort(tsne.fit_transform(W)[:, 0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
