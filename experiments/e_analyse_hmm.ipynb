{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "t1 = time.time()\n",
    "# os.environ['THEANO_FLAGS'] = \"device=cuda0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import lasagne\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm\n",
    "from matplotlib import gridspec\n",
    "from lproc import subset, rmap\n",
    "from sltools.utils import gloss2seq, seq2gloss\n",
    "from sltools.nn_utils import onehot, jaccard, compute_scores\n",
    "from sltools.postproc import optimize_boundaries, filter_longshort\n",
    "\n",
    "from experiments.hmmvsrnn_reco.a_data import durations, gloss_seqs, tmpdir, \\\n",
    "   train_subset, val_subset, test_subset, vocabulary\n",
    "from experiments.hmmvsrnn_reco.utils import reload_best_hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'EXPERIMENT_NAME' in os.environ:\n",
    "    experiment_name = os.environ['EXPERIMENT_NAME']\n",
    "else:\n",
    "    experiment_name = \"hmm_skel_tc15\"\n",
    "\n",
    "report = shelve.open(os.path.join(tmpdir, experiment_name))\n",
    "\n",
    "model = report['meta']['model']\n",
    "modality = report['meta']['modality']\n",
    "variant = report['meta']['variant']\n",
    "date = report['meta']['date']\n",
    "notes = report['meta']['notes']\n",
    "experiment_name = report['meta']['experiment_name']\n",
    "args = report['args']\n",
    "encoder_kwargs = args['encoder_kwargs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality == \"skel\":\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import skel_feat_seqs\n",
    "    feat_seqs = [skel_feat_seqs]\n",
    "elif modality == \"bgr\":\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import bgr_feat_seqs\n",
    "    feat_seqs = [bgr_feat_seqs]\n",
    "elif modality == \"fusion\":\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import skel_feat_seqs\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import bgr_feat_seqs\n",
    "    feat_seqs = [skel_feat_seqs, bgr_feat_seqs]\n",
    "elif modality == \"transfer\":\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import transfer_feat_seqs\n",
    "    feat_seqs = transfer_feat_seqs(encoder_kwargs['transfer_from'],\n",
    "                                   encoder_kwargs['freeze_at'])\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "feat_seqs_train = [subset(f, train_subset) for f in feat_seqs]\n",
    "gloss_seqs_train = subset(gloss_seqs, train_subset)\n",
    "durations_train = subset(durations, train_subset)\n",
    "targets_train = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                     gloss_seqs_train, durations_train)\n",
    "feat_seqs_val = [subset(f, val_subset) for f in feat_seqs]\n",
    "gloss_seqs_val = subset(gloss_seqs, val_subset)\n",
    "durations_val = subset(durations, val_subset)\n",
    "targets_val = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                    gloss_seqs_val, durations_val)\n",
    "feat_seqs_test = [subset(f, test_subset) for f in feat_seqs]\n",
    "gloss_seqs_test = subset(gloss_seqs, test_subset)\n",
    "durations_test = subset(durations, test_subset)\n",
    "targets_test = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                    gloss_seqs_test, durations_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training report and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "i = 0\n",
    "for e in sorted([e for e in report.keys() if e.startswith('epoch')]):\n",
    "    r = report[e]    \n",
    "    plt.plot(np.arange(i, i + len(r['epoch_losses'])), r['epoch_losses'], c='blue')\n",
    "    plt.scatter([i + len(r['epoch_losses']) - 1], [r['epoch_losses'][-1]], \n",
    "                marker='x', c='red', alpha=.5)\n",
    "    \n",
    "    i += len(r['epoch_losses'])\n",
    "\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "best_epoch, recognizer, previous_recognizer = reload_best_hmm(report)\n",
    "print(\"best epoch:\", best_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perfs(perf_report, chains_lengths):\n",
    "    fig = plt.figure(figsize=(10, 5), dpi=150)\n",
    "    gs = gridspec.GridSpec(2, 3)\n",
    "    \n",
    "    ax = fig.add_subplot(gs[0, 0])\n",
    "    cmap = matplotlib.cm.viridis\n",
    "    cmap.set_bad(cmap(0.001))\n",
    "    plt.imshow(perf_report['confusion'] / perf_report['confusion'].sum(axis=1, keepdims=True), \n",
    "               interpolation='none', \n",
    "               cmap=cmap, clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(\"HMM Jaccard/Framewise:\\n{:5.4f}/{:5.4f}\".format(\n",
    "        perf_report['jaccard'], perf_report['framewise']))\n",
    "\n",
    "    ax = fig.add_subplot(gs[1, 0])\n",
    "    cmap = matplotlib.cm.viridis\n",
    "    cmap.set_bad(cmap(0.001))\n",
    "    ax.imshow(perf_report['posterior_confusion'] / perf_report['posterior_confusion'].sum(axis=1, keepdims=True), \n",
    "              interpolation='none', \n",
    "              cmap=cmap, clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_title(\"Posterior Jaccard/Framewise:\\n{:5.4f}/{:5.4f}\".format(\n",
    "        perf_report['posterior_jaccard'], perf_report['posterior_framewise']))\n",
    "\n",
    "    ax = fig.add_subplot(gs[0:, 1:])\n",
    "    cmap = matplotlib.cm.viridis\n",
    "    cmap.set_bad(cmap(0.001))\n",
    "    ax.imshow(perf_report['statewise_confusion'] / perf_report['statewise_confusion'].sum(axis=1, keepdims=True), \n",
    "              interpolation='none', \n",
    "              cmap=cmap, clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticks(np.cumsum(chains_lengths) - .5)\n",
    "    ax.set_yticks(np.cumsum(chains_lengths) - .5)\n",
    "    ax.grid(color='gray', linestyle='dotted')\n",
    "    ax.set_title(\"State-wise framewise: {:5.4f}\".format(perf_report['statewise_framewise']))\n",
    "    \n",
    "    plt.colorbar(ax=ax)\n",
    "    \n",
    "    fig.tight_layout(w_pad=-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_perfs(report[best_epoch]['train_scores'], recognizer.chains_lengths)\n",
    "plot_perfs(report[best_epoch]['val_scores'], recognizer.chains_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_report = report[best_epoch]['val_scores']\n",
    "chains_lengths = recognizer.chains_lengths\n",
    "\n",
    "fig = plt.figure(figsize=(7, 6), dpi=150)\n",
    "ax = fig.add_subplot(111)\n",
    "cmap = matplotlib.cm.viridis\n",
    "cmap.set_bad(cmap(0.001))\n",
    "im = ax.imshow(perf_report['statewise_confusion'] / perf_report['statewise_confusion'].sum(axis=1, keepdims=True), \n",
    "          interpolation='none', \n",
    "          cmap=cmap, clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "ax.set_xticklabels([])\n",
    "ax.set_yticklabels([])\n",
    "ax.set_xticks(np.cumsum(chains_lengths) - .5)\n",
    "ax.set_yticks(np.cumsum(chains_lengths) - .5)\n",
    "ax.spines['left'].set_position(('outward', 2))\n",
    "ax.spines['bottom'].set_position(('outward', 2))\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.grid(color='w', linestyle='--', linewidth=.5)\n",
    "ax.set_title(\"accuracy: {:4.3f}\".format(perf_report['statewise_framewise']))\n",
    "\n",
    "fig.colorbar(im)\n",
    "\n",
    "fig.savefig(\"/home/granger/exp1_state_confusion.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train = [gloss2seq(g_, d_, 0) for g_, d_ in zip(gloss_seqs_train, durations_train)]\n",
    "predictions_train = recognizer.predict(feat_seqs_train)\n",
    "ji_train, framewise_train, confusion_train = compute_scores(predictions_train, targets_train, vocabulary)\n",
    "\n",
    "targets_val = [gloss2seq(g_, d_, 0) for g_, d_ in zip(gloss_seqs_val, durations_val)]\n",
    "predictions_val = recognizer.predict(feat_seqs_val)\n",
    "ji_val, framewise_val, confusion_val = compute_scores(predictions_val, targets_val, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of errors\n",
    "\n",
    "scores = np.array([jaccard(onehot(l, vocabulary), onehot(p, vocabulary))\n",
    "                   for l, p in zip(targets_val, predictions_val)])\n",
    "\n",
    "plt.figure(figsize=(4, 2), dpi=150)\n",
    "h, bins = np.histogram(scores, np.linspace(0.0, 1, 41))\n",
    "h = h / np.sum(h) * 40\n",
    "plt.bar(bins[:-1], h, width=1/40, \n",
    "        align='center', color=\"lightslategray\", edgecolor=\"darkslategray\")\n",
    "plt.xlabel(\"Sequence Jaccard Index\")\n",
    "plt.ylabel(\"density\")\n",
    "\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.gca().yaxis.grid(True, linestyle='--', linewidth=.5)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig(\"/home/granger/exp1_ji_density.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of false positives out of sequence vocabulary\n",
    "np.mean([len(set(p_) - set(l_)) for p_, l_ in zip(predictions_val, targets_val)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion types\n",
    "cum_err = np.sum(confusion_val, axis=1) - np.diag(confusion_val)\n",
    "print(\"false pos: {}  false neg: {}, mis-class: {}\".format(\n",
    "    cum_err[0], np.sum(confusion_val[1:, 0]), np.sum(cum_err[1:]) - np.sum(confusion_val[1:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posteriors of the _correct_ states in color and other states in gray\n",
    "\n",
    "def preview_seq(proba, gloss):\n",
    "    plt.figure(figsize=(10, 1), dpi=150)\n",
    "    cmap = plt.cm.summer(np.linspace(0, 1, 5))\n",
    "    \n",
    "    pre_start = 0\n",
    "    for lbl, start, stop in gloss:\n",
    "        for i in range(proba.shape[1] - 1):\n",
    "            plt.plot(np.arange(pre_start, start), proba[pre_start:start, i], ls=':', c=\"gray\")\n",
    "        plt.plot(np.arange(pre_start, start), proba[pre_start:start, -1], c=\"purple\")\n",
    "        for a in range(0, (lbl - 1) * 5):\n",
    "            plt.plot(np.arange(start, stop), proba[start:stop, a], ls=\":\", c='gray')\n",
    "        for a in range(5):\n",
    "            plt.plot(np.arange(start, stop), proba[start:stop, (lbl - 1) * 5 + a], c=cmap[a])\n",
    "        for a in range(lbl * 5, proba.shape[1]):\n",
    "            plt.plot(np.arange(start, stop), proba[start:stop, a], ls=\":\", c='gray')\n",
    "        pre_start = stop\n",
    "    \n",
    "    for i in range(proba.shape[1] - 1):\n",
    "        plt.plot(np.arange(pre_start, len(proba)), proba[pre_start:len(proba), i], ls=':', c=\"gray\")\n",
    "    plt.plot(np.arange(pre_start, len(proba)), proba[pre_start:len(proba), -1], c=\"purple\")\n",
    "    \n",
    "    plt.gca().set_axisbelow(True)\n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "    \n",
    "seq = 15\n",
    "\n",
    "preview_seq(\n",
    "    recognizer.posterior.predict_proba(*[f[seq] for f in feat_seqs_val]),\n",
    "    gloss_seqs_val[seq])\n",
    "\n",
    "plt.gca().set_xlim((200, 900))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recognizer.hmm.__getstate__().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = recognizer.hmm.__getstate__()['edges']\n",
    "states = recognizer.hmm.__getstate__()['states']\n",
    "\n",
    "out_edges = {int(states[v1].name): [] for v1, *_ in edges}\n",
    "for v1, v2, w, _, _ in recognizer.hmm.__getstate__()['edges']:\n",
    "    # print(\"{:>3d} -> {:>3d}: {:.5f}\".format(v1, v2, w))\n",
    "    out_edges[int(states[v1].name)].append((int(states[v2].name), w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5), dpi=150)\n",
    "gs = gridspec.GridSpec(4, 7, width_ratios=[1, 1, 1, 1, 1, .0, .1])\n",
    "limit = 1e-5\n",
    "\n",
    "cnames = [\n",
    "    'vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo']\n",
    "\n",
    "for c in range(20):\n",
    "    ax = fig.add_subplot(gs[c // 5, c % 5])\n",
    "    state_transition_matrix = np.zeros((5, 6))\n",
    "    \n",
    "    for i, s1 in enumerate(range(c * 5, c * 5 + 5)):\n",
    "        for s2, w in out_edges[s1]:\n",
    "            if s2 == 100:\n",
    "                state_transition_matrix[i, -1] = w\n",
    "            else:\n",
    "                state_transition_matrix[i, s2 - c * 5] = w\n",
    "    \n",
    "    state_transition_matrix = np.clip(state_transition_matrix, limit, 1)\n",
    "    \n",
    "    im = ax.imshow(state_transition_matrix, clim=(limit, 1), norm=LogNorm(limit, vmax=1))\n",
    "    ax.axis('off')\n",
    "    ax.set_title(cnames[c])\n",
    "\n",
    "bar_ax = fig.add_subplot(gs[1:3, 6])\n",
    "fig.colorbar(im, ax=bar_ax, cax=bar_ax)\n",
    "fig.tight_layout(pad=0, h_pad=-10)\n",
    "\n",
    "fig.savefig(\"/home/granger/exp1_transition_matrices.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate error with predicted gloss duration\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "prediction_accuracy = [np.sum(l[start:stop] == g) \n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "none_accuracy = [np.sum(l[start:stop] == 0)\n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "gloss_d = [stop - start\n",
    "           for p in predictions_val \n",
    "           for (g, start, stop) in seq2gloss(p)\n",
    "           if g != 0]\n",
    "\n",
    "scores_pred = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "scores_none = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "total_d = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "for vp, vn, d in zip(prediction_accuracy, none_accuracy, gloss_d):\n",
    "    idx = int(d / 5)\n",
    "    scores_pred[idx] += vp\n",
    "    scores_none[idx] += vn\n",
    "    total_d[idx] += d\n",
    "\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5), \n",
    "              scores_pred / total_d,\n",
    "              width=5,\n",
    "              alpha=.5)\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5), \n",
    "              scores_none / total_d,\n",
    "              width=5,\n",
    "              alpha=.5)\n",
    "\n",
    "plt.legend([\"predicted class\", \"non-gesture class\"])\n",
    "plt.xlabel(\"subsequence duration (based on model prediction)\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize duration filter\n",
    "\n",
    "boundaries = optimize_boundaries(targets_val, predictions_val, vocabulary, (30, 100, 301))\n",
    "print(\"Optimal range: \", boundaries)\n",
    "print(\"FYI the score without is: {:.4f}\".format(ji_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation score\n",
    "\n",
    "ji_filtered_val, accuracy_filtered_val, confusion_filtered_val = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_val], \n",
    "    targets_val, vocabulary)\n",
    "print(\"validation score: {:.4f}\".format(ji_filtered_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "\n",
    "targets_test = [gloss2seq(g_, d_, 0) for g_, d_ in zip(gloss_seqs_test, durations_test)]\n",
    "predictions_test = recognizer.predict(feat_seqs_test)\n",
    "\n",
    "ji_filtered_test, accuracy_filtered_test, confusion_filtered_test = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_test], \n",
    "    targets_test, vocabulary)\n",
    "print(\"testing score: {:.4f}\".format(ji_filtered_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recap:\n",
    "\n",
    "print(\"Accuracy:   {:.4f} / {:.4f} / ?\".format(framewise_train, framewise_val))\n",
    "print(\"JI:         {:.4f} / {:.4f} / ?\".format(ji_train, ji_val))\n",
    "print(\"Acc. filt.:      ? / {:.4f} / {:.4f}\".format(accuracy_filtered_val, accuracy_filtered_test))\n",
    "print(\"JI filt.:        ? / {:.4f} / {:.4f}\".format(ji_filtered_val, ji_filtered_test))\n",
    "\n",
    "recap = {\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"accuracy\": (framewise_train, framewise_val, None),\n",
    "    \"ji\": (ji_train, ji_val, None),\n",
    "    \"confusion\": (confusion_train, confusion_val, None),\n",
    "    \"accuracy_filtered\": (None, accuracy_filtered_val, accuracy_filtered_test),\n",
    "    \"ji_filtered\": (None, ji_filtered_val, ji_filtered_test),\n",
    "    \"confusion_filtered\": (None, confusion_filtered_val, None),\n",
    "}\n",
    "report['analysis'] = recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report['args']['encoder_kwargs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.manifold import TSNE\n",
    "# from sltools.tconv import TemporalConv\n",
    "\n",
    "# l = None\n",
    "# for l_ in lasagne.layers.get_all_layers(recognizer.posterior.l_feats):\n",
    "#     if isinstance(l_, TemporalConv):\n",
    "#         l = l_\n",
    "\n",
    "# W1 = l.W.eval()\n",
    "# W1 = W1.transpose((0, 2, 1)).reshape((-1, W1.shape[1]))\n",
    "# Y = np.linalg.norm(W1, axis=1)\n",
    "# i = np.argsort(Y)\n",
    "# W1 = np.stack([W1[i_] for i_ in i])[-300:]\n",
    "# model = TSNE(n_components=1, metric='euclidean')\n",
    "# Y = model.fit_transform(W1)[:, 0]\n",
    "# i = np.argsort(Y)\n",
    "# W1 = W1[i]\n",
    "# Y = Y[i]\n",
    "\n",
    "# plt.figure(figsize=(5, 20))\n",
    "# x, y = np.meshgrid(np.arange(W1.shape[1]), Y)\n",
    "# plt.imshow(W1, clim=(-np.abs(W1).max(), np.abs(W1).max()), cmap='bwr')\n",
    "# plt.gca().set_aspect(\"auto\")\n",
    "# plt.axis([-1, W1.shape[1], -1, W1.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# t2 = time.time()\n",
    "# print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = lasagne.layers.get_all_layers(recognizer.posterior.l_feats)[2]\n",
    "# W = np.asarray(l.W.eval())\n",
    "\n",
    "# nrows, ncols = int(np.ceil(np.sqrt(W.shape[0] + 1))), int(np.floor(np.sqrt(W.shape[0] + 1)))\n",
    "# img = np.zeros((nrows * (W.shape[2] + 1), ncols * (W.shape[3] + 1)))\n",
    "# for k in range(W.shape[0]):\n",
    "#     i, j = k // ncols, k % ncols\n",
    "#     y, x = i * (W.shape[2] + 1), j * (W.shape[3] + 1)\n",
    "#     tmp = img[y:y + W.shape[2]]\n",
    "#     img[y:y + W.shape[2], x:x + W.shape[3]] = W[k, 0]\n",
    "\n",
    "# plt.imshow(img, clim=(-np.abs(W).max(), np.abs(W).max()), cmap='bwr')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbl, cnt = np.unique(\n",
    "#     np.concatenate([gloss2seq(g_, len(r_), 0) for g_, r_ in zip(gloss_seqs_val, feat_seqs_val)]),\n",
    "#     return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(x=lbl+.5, height=cnt, log=True)\n",
    "# plt.gca().set_ylim((1, 3e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(x=lbl+.5, height=cnt, log=False)\n",
    "# plt.gca().set_ylim((1, 2e5))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([len(gseq) for gseq in gloss_seqs_val])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
