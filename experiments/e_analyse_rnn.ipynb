{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "os.environ['THEANO_FLAGS'] = \"device=cuda1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "import pprint\n",
    "import numpy as np\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib.cm\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from lproc import subset, rmap\n",
    "import seqtools\n",
    "from datasets import ch14dataset as dataset\n",
    "from sltools.utils import gloss2seq, seq2gloss\n",
    "from sltools.nn_utils import onehot, jaccard, compute_scores\n",
    "from sltools.postproc import optimize_boundaries, filter_longshort\n",
    "from IPython.display import set_matplotlib_formats\n",
    "\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "plt.rcParams['axes.facecolor'] = 'white'\n",
    "plt.rcParams['figure.facecolor'] = 'white'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.hmmvsrnn_reco.a_data import durations, gloss_seqs, tmpdir, \\\n",
    "   train_subset, val_subset, test_subset, vocabulary\n",
    "from experiments.hmmvsrnn_reco.utils import reload_best_rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'EXPERIMENT_NAME' in os.environ:\n",
    "    experiment_name = os.environ['EXPERIMENT_NAME']\n",
    "else:\n",
    "    experiment_name = \"rnn_bgr_tc15\"\n",
    "\n",
    "report = shelve.open(os.path.join(tmpdir, experiment_name))\n",
    "\n",
    "model = report['meta']['model']\n",
    "modality = report['meta']['modality']\n",
    "variant = report['meta']['variant']\n",
    "date = report['meta']['date']\n",
    "notes = report['meta']['notes']\n",
    "experiment_name = report['meta']['experiment_name']\n",
    "args = report['args']\n",
    "encoder_kwargs = args['encoder_kwargs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if modality == \"skel\":\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import skel_feat_seqs\n",
    "    feat_seqs = [skel_feat_seqs]\n",
    "elif modality == \"bgr\":\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import bgr_feat_seqs\n",
    "    feat_seqs = [bgr_feat_seqs]\n",
    "elif modality == \"fusion\":\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import skel_feat_seqs\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import bgr_feat_seqs\n",
    "    feat_seqs = [skel_feat_seqs, bgr_feat_seqs]\n",
    "elif modality == \"transfer\":\n",
    "    from experiments.hmmvsrnn_reco.b_preprocess import transfer_feat_seqs\n",
    "    feat_seqs = transfer_feat_seqs(encoder_kwargs['transfer_from'],\n",
    "                                   encoder_kwargs['freeze_at'])\n",
    "else:\n",
    "    raise ValueError()\n",
    "\n",
    "feat_seqs_train = [subset(f, train_subset) for f in feat_seqs]\n",
    "gloss_seqs_train = subset(gloss_seqs, train_subset)\n",
    "durations_train = subset(durations, train_subset)\n",
    "targets_train = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                     gloss_seqs_train, durations_train)\n",
    "feat_seqs_val = [subset(f, val_subset) for f in feat_seqs]\n",
    "gloss_seqs_val = subset(gloss_seqs, val_subset)\n",
    "durations_val = subset(durations, val_subset)\n",
    "targets_val = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                    gloss_seqs_val, durations_val)\n",
    "feat_seqs_test = [subset(f, test_subset) for f in feat_seqs]\n",
    "gloss_seqs_test = subset(gloss_seqs, test_subset)\n",
    "durations_test = subset(durations, test_subset)\n",
    "targets_test = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                    gloss_seqs_test, durations_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batch_losses = []\n",
    "all_epoch_losses = []\n",
    "for i in sorted([e for e in report.keys() if e.startswith(\"epoch\")]):\n",
    "    r = report[i]\n",
    "    all_batch_losses += r['batch_losses']\n",
    "    all_epoch_losses.append(r['epoch_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 3))\n",
    "plt.plot(np.arange(len(all_epoch_losses)), all_epoch_losses, c='red')\n",
    "n_batches = len(all_batch_losses) // len(all_epoch_losses)\n",
    "error = np.array([np.std(all_batch_losses[i:i+n_batches]) \n",
    "                  for i in range(0, len(all_batch_losses), n_batches)])\n",
    "# plt.fill_between(np.arange(len(all_epoch_losses)), \n",
    "#                  np.maximum(0.00001, all_epoch_losses - error), \n",
    "#                  all_epoch_losses + error)\n",
    "plt.yscale(\"log\")\n",
    "# plt.semilogy([10 ** (i - 5) for i in range(5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_epoch, model_dict, predict_fn = reload_best_rnn(report)\n",
    "\n",
    "print(\"best epoch: {}\".format(best_epoch))\n",
    "\n",
    "epoch_report = report[best_epoch]\n",
    "print(epoch_report['train_scores']['jaccard'])\n",
    "print(epoch_report['train_scores']['framewise'])\n",
    "print(epoch_report['val_scores']['jaccard'])\n",
    "print(epoch_report['train_scores']['framewise'] - epoch_report['val_scores']['framewise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_train = [np.argmax(p, axis=1) for p in predict_fn(feat_seqs_train)]\n",
    "ji_train, framewise_train, confusion_train = compute_scores(predictions_train, targets_train, vocabulary)\n",
    "\n",
    "predictions_val = [np.argmax(p, axis=1) for p in predict_fn(feat_seqs_val)]\n",
    "ji_val, framewise_val, confusion_val = compute_scores(predictions_val, targets_val, vocabulary)\n",
    "\n",
    "print(\"JI: {:.4f} / {:.4f}\".format(ji_train, ji_val))\n",
    "print(\"Accuracy: {:.4f} / {:.4f}\".format(framewise_train, framewise_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnames = [\n",
    "    '∅','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo']\n",
    "\n",
    "cmap = matplotlib.cm.viridis\n",
    "cmap.set_bad(cmap(0.001))\n",
    "\n",
    "fig, ax1 = plt.subplots(1, 1, figsize=(6, 4))\n",
    "im = ax1.matshow(confusion_train / np.sum(confusion_train, axis=1, keepdims=True), \n",
    "                 interpolation='none', cmap=cmap,\n",
    "                 clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "ax1.set_yticks(np.arange(0, 22, 1))\n",
    "ax1.set_xticks([])\n",
    "ax1.set_yticklabels(cnames)\n",
    "\n",
    "divider = make_axes_locatable(ax1)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im, cax=cax, orientation='vertical')\n",
    "\n",
    "fig, ax2 = plt.subplots(1, 1, figsize=(6, 4))\n",
    "im = ax2.matshow(confusion_val / np.sum(confusion_val, axis=1, keepdims=True), \n",
    "                 interpolation='none', cmap='viridis',\n",
    "                 clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "ax2.set_yticks(np.arange(0, 22, 1))\n",
    "ax2.set_xticks([])\n",
    "ax2.set_yticklabels(cnames)\n",
    "\n",
    "divider = make_axes_locatable(ax2)\n",
    "cax = divider.append_axes('right', size='5%', pad=0.05)\n",
    "fig.colorbar(im, cax=cax, orientation='vertical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preview prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview_seq(proba, ax=None):\n",
    "    # 21 distinct colors\n",
    "    \n",
    "    cmap = np.array([[113,204,0], [209,73,251], [243,255,52], [223,119,255], \n",
    "         [139,255,150], [255,66,189], [1,222,201], [255,77,30], \n",
    "         [0,149,225], [137,106,0], [0,43,105], [255,230,180], \n",
    "         [111,0,66], [0,113,63], [251,177,255], [56,96,0], \n",
    "         [160,218,255], [74,0,6], [255,170,172], [0,62,95], \n",
    "         [93,43,0]]) / 255\n",
    "    \n",
    "    ax = ax or plt.gca()\n",
    "    l = np.argmax(proba, axis=1)\n",
    "    for g, start, stop in seq2gloss(l):\n",
    "        start = max(0, start - 1)\n",
    "        stop = min(len(proba), stop + 1)\n",
    "        if g == 0:\n",
    "            ax.plot(np.arange(start, stop), proba[start:stop, 0], ls=':', c=cmap[0])\n",
    "        else:\n",
    "            ax.plot(np.arange(start, stop), proba[start:stop, g], c=cmap[g])\n",
    "            ax.fill_between(np.arange(start, stop),\n",
    "                            0, proba[start:stop, g],\n",
    "                            facecolor=cmap[g],\n",
    "                            alpha=0.3)\n",
    "    ax.set_ylim((0, 1.1))\n",
    "    ax.set_xlim((0, len(proba)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 62\n",
    "s = 62\n",
    "\n",
    "proba = predict_fn([[fseq[s]] for fseq in feat_seqs_val])[0]\n",
    "labels = onehot(gloss2seq(gloss_seqs_val[s], durations_val[s], 0), \n",
    "                np.arange(0, 21))\n",
    "\n",
    "fig = plt.figure(figsize=(6, 3), dpi=150)\n",
    "gs = GridSpec(7, 1)\n",
    "ax = plt.subplot(gs[:4, 0])\n",
    "ax.set_xticks(np.arange(0, len(proba), 50), minor=True)\n",
    "preview_seq(np.exp(proba[:]), ax)\n",
    "ax.set_title(\"model predictions\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "ax = plt.subplot(gs[4:, 0])\n",
    "preview_seq(labels[:] * 1.0,  ax)\n",
    "ax.set_title(\"targets\")\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "fig.tight_layout()\n",
    "\n",
    "fig.savefig(\"/home/granger/exp1_preds_vs_tgt.pdf\", bbox_inches='tight')\n",
    "\n",
    "print(gloss_seqs_val[s][:, 0].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize duration filter\n",
    "\n",
    "boundaries = optimize_boundaries(targets_val, predictions_val, vocabulary, (30, 100, 301))\n",
    "print(\"Optimal range: \", boundaries)\n",
    "print(\"FYI the score without is: {:.4f}\".format(ji_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation score\n",
    "\n",
    "ji_filtered_val, accuracy_filtered_val, confusion_filtered_val = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_val], \n",
    "    targets_val, vocabulary)\n",
    "print(\"validation score: {:.4f}\".format(ji_filtered_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "\n",
    "predictions_test = [np.argmax(p, axis=1) for p in predict_fn(feat_seqs_test)]\n",
    "\n",
    "ji_filtered_test, accuracy_filtered_test, confusion_filtered_test = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_test], \n",
    "    targets_test, vocabulary)\n",
    "print(\"testing score: {:.4f}\".format(ji_filtered_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recap:\n",
    "\n",
    "print(\"Accuracy:   {:.4f} / {:.4f} / ?\".format(framewise_train, framewise_val))\n",
    "print(\"JI:         {:.4f} / {:.4f} / ?\".format(ji_train, ji_val))\n",
    "print(\"Acc. filt.:      ? / {:.4f} / {:.4f}\".format(accuracy_filtered_val, accuracy_filtered_test))\n",
    "print(\"JI filt.:        ? / {:.4f} / {:.4f}\".format(ji_filtered_val, ji_filtered_test))\n",
    "\n",
    "recap = {\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"accuracy\": (framewise_train, framewise_val, None),\n",
    "    \"ji\": (ji_train, ji_val, None),\n",
    "    \"confusion\": (confusion_train, confusion_val, None),\n",
    "    \"accuracy_filtered\": (None, accuracy_filtered_val, accuracy_filtered_test),\n",
    "    \"ji_filtered\": (None, ji_filtered_val, ji_filtered_test),\n",
    "    \"confusion_filtered\": (None, confusion_filtered_val, None),\n",
    "}\n",
    "report['analysis'] = recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of errors\n",
    "\n",
    "scores = np.array([jaccard(onehot(l, vocabulary), onehot(p, vocabulary))\n",
    "                   for l, p in zip(targets_val, predictions_val)])\n",
    "\n",
    "plt.figure(figsize=(4, 2), dpi=150)\n",
    "h, bins = np.histogram(scores, np.linspace(0.0, 1, 41))\n",
    "h = h / np.sum(h) * 40\n",
    "plt.bar(bins[:-1], h, width=1/40, \n",
    "        align='center', color=\"lightslategray\", edgecolor=\"darkslategray\")\n",
    "plt.xlabel(\"Sequence Jaccard Index\")\n",
    "plt.ylabel(\"density\")\n",
    "\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.gca().yaxis.grid(True, linestyle='--', linewidth=.5)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.savefig(\"/home/granger/exp1_ji_density.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe badly classified sequences\n",
    "\n",
    "worst_seqs = np.argsort(scores)[:15]\n",
    "print(\"worst sequences:              {}\".format(val_subset[worst_seqs]))\n",
    "print(\"worst sequences (validation): {}\".format(worst_seqs))\n",
    "print(\"worst sequences JI:           {}\".format(scores[worst_seqs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of false positives out of sequence vocabulary\n",
    "print(np.mean([len(set(p_) - set(l_)) \n",
    "               for p_, l_ in zip(predictions_val, targets_val)],\n",
    "              axis=0))\n",
    "print(np.mean([len(set(p_) - set(l_)) \n",
    "               for p_, l_ in zip([filter_longshort(p, boundaries, 0) for p in predictions_val], targets_val)],\n",
    "              axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion types\n",
    "cum_err = np.sum(confusion_val, axis=1) - np.diag(confusion_val)\n",
    "print(\"false pos: {}  false neg: {}, mis-class: {}\".format(\n",
    "    cum_err[0], np.sum(confusion_val[1:, 0]), np.sum(cum_err[1:]) - np.sum(confusion_val[1:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6867.0 / (11639.0 + 6083.0 + 6867.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate error with predicted gloss duration\n",
    "\n",
    "plt.figure(figsize=(7, 2), dpi=150)\n",
    "\n",
    "prediction_accuracy = [np.sum(l[start:stop] == g) \n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "none_accuracy = [np.sum(l[start:stop] == 0)\n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "gloss_d = [stop - start\n",
    "           for p in predictions_val \n",
    "           for (g, start, stop) in seq2gloss(p)\n",
    "           if g != 0]\n",
    "gloss_d = np.fmin(gloss_d, 200)\n",
    "\n",
    "scores_pred = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "scores_none = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "total_d = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "for vp, vn, d in zip(prediction_accuracy, none_accuracy, gloss_d):\n",
    "    idx = int(d / 5)\n",
    "    scores_pred[idx] += vp\n",
    "    scores_none[idx] += vn\n",
    "    total_d[idx] += d\n",
    "\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5) + .75, \n",
    "              scores_pred / total_d,\n",
    "              width=1.5,\n",
    "              color='darkorange')\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5) - .75, \n",
    "              scores_none / total_d,\n",
    "              width=1.5,\n",
    "              color='steelblue')\n",
    "plt.gca().set_xlim([-2.5, 202.5])\n",
    "plt.gca().set_xticks(np.arange(0, 201, 25))\n",
    "plt.gca().set_xticklabels([str(i) for i in range(0, 200, 25)] + [\"≥ 200\"])\n",
    "\n",
    "plt.gca().set_axisbelow(True)\n",
    "plt.gca().yaxis.grid(True, linestyle='--', linewidth=.5)\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.legend([\"predicted class\", \"non-gesture class\"], loc='upper right', bbox_to_anchor=(0.95, 0.95))\n",
    "plt.xlabel(\"subsequence duration (based on model prediction)\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(\"/home/granger/acc_vs_glossduration.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# observe alignment issues\n",
    "\n",
    "filtered_predictions_val = [filter_longshort(p, boundaries, 0) for p in predictions_val]\n",
    "gloss_predictions = [\n",
    "    [(g, start, stop) for (g, start, stop) in seq2gloss(p) if g != 0]\n",
    "    for p in filtered_predictions_val]\n",
    "\n",
    "start_offset = []\n",
    "stop_offset = []\n",
    "\n",
    "for i in range(len(val_subset)):\n",
    "    glosses_tgt = gloss_seqs_val[i]\n",
    "    glosses_pred = gloss_predictions[i]\n",
    "    for g, a, b in glosses_tgt:\n",
    "        for g_, a_, b_ in glosses_pred:\n",
    "            if g_ != g:\n",
    "                continue\n",
    "            if min(b, b_) - max(a, a_) < (b - a) / 2:\n",
    "                continue\n",
    "            start_offset.append(a_ - a)\n",
    "            stop_offset.append(b_ - b)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(5, 2), dpi=150)\n",
    "ax = plt.subplot(111)\n",
    "\n",
    "h, b = np.histogram(np.clip(start_offset, -8, 8), bins=np.arange(-8.5, 9, 1))\n",
    "h = h / np.sum(h)\n",
    "ax.bar(b[:-1] + .5 - .15, h, width=.3, color='steelblue')\n",
    "\n",
    "h, b = np.histogram(np.clip(stop_offset, -8, 8), bins=np.arange(-8.5, 9, 1))\n",
    "h = h / np.sum(h)\n",
    "ax.bar(b[:-1] + .5 + .15, h, width=.3, color='darkorange')\n",
    "\n",
    "ax.set_xlabel('detection offset with groundtruth')\n",
    "ax.set_ylabel('density')\n",
    "ax.legend(['beginning', 'end'])\n",
    "\n",
    "ax.set_xlim((-8.3, 8.3))\n",
    "ax.set_xticks(np.arange(-8, 9, 2))\n",
    "ax.set_xticklabels([\"≤-8\"] + [\"+\" + str(i) if i > 0 else str(i) for i in  range(-6, 7, 2)] + [\"≥+8\"])\n",
    "ax.set_xticks(np.arange(-8, 9), minor=True)\n",
    "\n",
    "ax.set_axisbelow(True)\n",
    "ax.yaxis.grid(True, linestyle='--', linewidth=.5)\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "\n",
    "fig.savefig(\"/home/granger/exp1_gloss_offset.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sltools.tconv import TemporalConv\n",
    "\n",
    "tc_l = None\n",
    "layers = lasagne.layers.get_all_layers(model_dict['l_linout'])\n",
    "\n",
    "for l in layers:\n",
    "    if isinstance(l, TemporalConv):\n",
    "        tc_l = l\n",
    "        break\n",
    "\n",
    "W = np.asarray(tc_l.W.eval())\n",
    "W = np.reshape(np.transpose(W, (0, 2, 1)), (-1, tc_l.filter_size))\n",
    "\n",
    "norms = np.linalg.norm(W, axis=1)\n",
    "biggest = np.argsort(norms)[-5000:]\n",
    "biggest = biggest[np.random.permutation(5000)[:320]]\n",
    "tsne = TSNE(n_components=1, n_iter=5000, n_iter_without_progress=100, verbose=True)\n",
    "tsne_order = np.argsort(tsne.fit_transform(W[biggest])[:, 0])\n",
    "biggest_sorted = biggest[tsne_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5, 6), dpi=150)\n",
    "clim = np.max(np.abs(W))\n",
    "for i in range(4):\n",
    "    plt.subplot(1, 4, i + 1)\n",
    "    img = W[biggest_sorted[i * 80:(i + 1) * 80]]\n",
    "    img = np.concatenate([img, np.zeros((80 - img.shape[0], img.shape[1]))], axis=0)\n",
    "    plt.imshow(img, cmap='RdBu', clim=(-clim, clim))\n",
    "    plt.gca().set_yticks([])\n",
    "    plt.xticks([0, 14], ['1', '15'])\n",
    "    plt.gca().set_xticks([4, 9], minor=True)\n",
    "    \n",
    "    plt.gca().spines['top'].set_visible(False)\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_visible(False)\n",
    "    plt.gca().set_aspect('equal')\n",
    "\n",
    "plt.suptitle('time (within window)', y=-0.02)\n",
    "plt.tight_layout(pad=0.5)\n",
    "\n",
    "plt.savefig(\"/home/granger/exp2_tc_weights.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = np.asarray(layers[2].W.eval())\n",
    "\n",
    "limits = np.max(abs(W))\n",
    "fig = plt.figure(figsize=(3, 3), dpi=150)\n",
    "for i in range(16):\n",
    "    ax = fig.add_subplot(4, 4, i + 1)\n",
    "    ax.imshow(W[i, 0], cmap='inferno')\n",
    "    ax.axis('off')\n",
    "\n",
    "fig.tight_layout(pad=-2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
