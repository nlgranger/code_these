{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "os.environ['THEANO_FLAGS'] = \"device=cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import shelve\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "from IPython.display import display\n",
    "\n",
    "plt.rcParams['savefig.dpi'] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiments.hmmvsrnn_reco.a_data import tmpdir, frame_seqs, dataset, vocabulary, get_ref_pts, detect_invalid_pts, interpolate_positions\n",
    "from sltools.transform import Transformation, transform_pose2d, transform_pose3d, transform_frames\n",
    "\n",
    "tmpdir = tmpdir.split('.')[0]\n",
    "tgt_dist = 2\n",
    "joints = dataset.JointType\n",
    "\n",
    "flip_mapping = ([joints.ShoulderRight, joints.ElbowRight,\n",
    "                 joints.WristRight, joints.HandRight, joints.ShoulderLeft,\n",
    "                 joints.ElbowLeft, joints.WristLeft, joints.HandLeft,\n",
    "                 joints.HipRight, joints.KneeRight, joints.AnkleRight,\n",
    "                 joints.FootRight, joints.HipLeft, joints.KneeLeft,\n",
    "                 joints.AnkleLeft, joints.FootLeft],\n",
    "                [joints.ShoulderLeft, joints.ElbowLeft,\n",
    "                 joints.WristLeft, joints.HandLeft, joints.ShoulderRight,\n",
    "                 joints.ElbowRight, joints.WristRight, joints.HandRight,\n",
    "                 joints.HipLeft, joints.KneeLeft, joints.AnkleLeft,\n",
    "                 joints.FootLeft, joints.HipRight, joints.KneeRight,\n",
    "                 joints.AnkleRight, joints.FootRight])\n",
    "\n",
    "video = dataset.bgr_frames(0)\n",
    "poses_2d = dataset.positions(0)\n",
    "poses_3d = dataset.positions_3d(0)\n",
    "invalid_masks = detect_invalid_pts(poses_2d)\n",
    "poses_2d = interpolate_positions(poses_2d, invalid_masks)\n",
    "poses_3d = interpolate_positions(poses_3d, invalid_masks)\n",
    "ref2d = get_ref_pts(poses_2d)\n",
    "ref3d = get_ref_pts(poses_3d)\n",
    "\n",
    "zshifts = np.mean(tgt_dist - ref3d[:, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation = Transformation(\n",
    "#     ref2d=ref2d, ref3d=ref3d, flip_mapping=flip_mapping,\n",
    "#     frame_width=640,\n",
    "#     fliplr=False,\n",
    "#     tilt=5 * np.pi / 180,\n",
    "#     zshift=zshifts,\n",
    "#     xscale=1.15, yscale=0.85,\n",
    "#     zscale=1, tscale=1)\n",
    "\n",
    "# t = 10\n",
    "# plt.figure()\n",
    "# plt.imshow(video[t])\n",
    "# plt.scatter(poses_2d[t, :, 0], poses_2d[t, :, 1])\n",
    "# plt.figure()\n",
    "# plt.imshow(transform_frames(video, transformation)[t])\n",
    "# trans_pose2d = transform_pose2d(poses_2d, transformation)\n",
    "# plt.scatter(trans_pose2d[t, :, 0], trans_pose2d[t, :, 1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tmpdir, tmpdir + '.run1', tmpdir + '.run2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(e[1], e[4]['ji_filtered']) for e in experiments if e[0] == \"hmm_skel_tc21\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = []\n",
    "\n",
    "for run, directory in enumerate([tmpdir + '.run1', tmpdir + '.run2', tmpdir + '.run3']):\n",
    "    for report_file in os.listdir(directory):\n",
    "        if not report_file.endswith(\".dat\"):\n",
    "            continue\n",
    "        \n",
    "        f = os.path.join(directory, report_file[:-4])\n",
    "        with shelve.open(f, flag='r') as report:\n",
    "            if 'analysis' not in report.keys():\n",
    "                continue\n",
    "            meta = report['meta']\n",
    "            name = meta['experiment_name']\n",
    "            args = report['args']['encoder_kwargs']\n",
    "            analysis = report['analysis']\n",
    "            experiments.append((name, run, meta, args, analysis))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted([(e[0], e[4]['ji_filtered'][2]) for e in experiments])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Varying TC size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype = [('model', 'S3'), \n",
    "         ('win', 'i'),\n",
    "         ('nparms', 'i'),\n",
    "         ('ji', 'f'),\n",
    "         ('acc', 'f')]\n",
    "\n",
    "tc_analyses = np.sort([\n",
    "    np.array((\n",
    "        m['model'],\n",
    "        a['filter_dilation'] * (a['tconv_sz'] - 1) + 1,\n",
    "        a['tconv_sz'] * a['num_tc_filters'],\n",
    "        r['ji_filtered'][1], \n",
    "        r['accuracy_filtered'][1]), \n",
    "        dtype=dtype)\n",
    "    for _, _, m, a, r in experiments \n",
    "    if m['modality'] == \"skel\"])\n",
    "\n",
    "plt.figure(dpi=100) \n",
    "\n",
    "legend = []\n",
    "subset = (tc_analyses['model'] == b\"rnn\")\n",
    "p1 = plt.scatter(\n",
    "    tc_analyses[subset]['win'],\n",
    "    tc_analyses[subset]['ji'],\n",
    "    s=tc_analyses[subset]['nparms'] / 50,\n",
    "    marker=\"o\", alpha=0.5)\n",
    "    \n",
    "legend = []\n",
    "subset = (tc_analyses['model'] == b\"hmm\")\n",
    "p2 = plt.scatter(\n",
    "    tc_analyses[subset]['win'],\n",
    "    tc_analyses[subset]['ji'],\n",
    "    s=tc_analyses[subset]['nparms'] / 50,\n",
    "    marker=\"o\", alpha=0.5)\n",
    "\n",
    "plt.legend([p1, p2], ['rnn', 'hmm'], loc='best')\n",
    "\n",
    "plt.xlabel(\"window size\")\n",
    "plt.ylabel(\"Jaccard Index\")\n",
    "plt.xticks(np.arange(3, 32, 4))\n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_experiments = {\n",
    "    (name, run): (meta['modality'], analysis['accuracy_filtered'][2], analysis['ji_filtered'][2])\n",
    "    for name, run, meta, args, analysis in experiments \n",
    "    if meta['modality'] != \"transfer\"}\n",
    "\n",
    "columns = [\n",
    "    'model', 'modality', 'terminate_at', 'run', \n",
    "    'acc', 'delta_ref_acc', 'delta_other_acc', 'ji', 'delta_ref_ji', 'delta_other_ji']\n",
    "\n",
    "transfer_analyses = []\n",
    "\n",
    "for name, run, meta, args, analysis in experiments:\n",
    "    if meta['modality'] != 'transfer':\n",
    "        continue\n",
    "\n",
    "    model = meta['model']\n",
    "    terminate_at = args['terminate_at']\n",
    "    modality, acc_other, ji_other = source_experiments[(args['transfer_from'], run)]\n",
    "    _, acc_ref, ji_ref = source_experiments[(model + args['transfer_from'][3:], run)]\n",
    "    acc = analysis['accuracy_filtered'][2]\n",
    "    ji = analysis['ji_filtered'][2]\n",
    "    transfer_analyses.append(\n",
    "        (model, modality, terminate_at, run, \n",
    "                  acc, acc - acc_ref, acc - acc_other, \n",
    "                  ji, ji - ji_ref, ji - ji_other))\n",
    "\n",
    "transfer_analyses = pd.DataFrame(transfer_analyses, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_analyses.groupby(['model', 'modality', 'terminate_at']).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare confusion on video frames\n",
    "\n",
    "hmm_conf = np.zeros((21, 21))\n",
    "rnn_conf = np.zeros((21, 21))\n",
    "\n",
    "for rundir in [tmpdir + '.run1', tmpdir + '.run2', tmpdir + '.run3']:\n",
    "    with shelve.open(os.path.join(rundir, \"hmm_bgr_tc15\"), flag='r') as report:\n",
    "        hmm_analysis = report['analysis']\n",
    "        hmm_conf += hmm_analysis['confusion_filtered'][1]\n",
    "\n",
    "    with shelve.open(os.path.join(rundir, \"rnn_bgr_tc15\"), flag='r') as report:\n",
    "        rnn_analysis = report['analysis']\n",
    "        rnn_conf += rnn_analysis['confusion_filtered'][1]\n",
    "\n",
    "hmm_conf /= np.sum(hmm_conf, axis=1, keepdims=True)\n",
    "rnn_conf /= np.sum(rnn_conf, axis=1, keepdims=True)\n",
    "\n",
    "conf_diff = hmm_conf - rnn_conf\n",
    "\n",
    "# plot\n",
    "plt.figure(dpi=150, figsize=(6, 3))\n",
    "limits = np.max(abs(conf_diff))\n",
    "plt.imshow(\n",
    "    conf_diff, \n",
    "    clim=(-limits, limits), \n",
    "    cmap='RdBu')\n",
    "plt.yticks(np.arange(0, 21), [\n",
    "    'âˆ…','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo'],\n",
    "    fontsize=8)\n",
    "plt.xticks(np.arange(0, 21), [''] * 21)\n",
    "plt.gca().annotate(\n",
    "    '', \n",
    "    xy=(1.5, 0.1), xycoords='axes fraction', xytext=(1.5, 0.9), \n",
    "    arrowprops=dict(arrowstyle=\"<->\", color='k'))\n",
    "plt.gca().annotate(\n",
    "    'rnn', xy=(1.47, 0.05), xycoords='axes fraction', xytext=(1.47, 0.05))\n",
    "plt.gca().annotate(\n",
    "    'hmm', xy=(1.44, 0.92), xycoords='axes fraction', xytext=(1.44, 0.92))\n",
    "plt.colorbar()\n",
    "\n",
    "# Compare misclassification\n",
    "a = np.sum(hmm_conf[1:, 1:]) - np.sum(np.diag(hmm_conf[1:, 1:]))\n",
    "b = np.sum(rnn_conf[1:, 1:]) - np.sum(np.diag(rnn_conf[1:, 1:]))\n",
    "print(a, b, (a - b) / b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare confusion on body poses\n",
    "\n",
    "hmm_conf = np.zeros((21, 21))\n",
    "rnn_conf = np.zeros((21, 21))\n",
    "\n",
    "for rundir in [tmpdir + '.run1', tmpdir + '.run2', tmpdir + '.run3']:\n",
    "    with shelve.open(os.path.join(rundir, \"hmm_skel_tc15\"), flag='r') as report:\n",
    "        hmm_analysis = report['analysis']\n",
    "        hmm_conf += hmm_analysis['confusion_filtered'][1]\n",
    "\n",
    "    with shelve.open(os.path.join(rundir, \"rnn_skel_tc15\"), flag='r') as report:\n",
    "        rnn_analysis = report['analysis']\n",
    "        rnn_conf += rnn_analysis['confusion_filtered'][1]\n",
    "\n",
    "hmm_conf /= np.sum(hmm_conf, axis=1, keepdims=True)\n",
    "rnn_conf /= np.sum(rnn_conf, axis=1, keepdims=True)\n",
    "\n",
    "conf_diff = hmm_conf - rnn_conf\n",
    "\n",
    "# plot\n",
    "plt.figure(dpi=150, figsize=(6, 3))\n",
    "limits = np.max(abs(conf_diff))\n",
    "plt.imshow(\n",
    "    conf_diff, \n",
    "    clim=(-limits, limits), \n",
    "    cmap='RdBu')\n",
    "plt.yticks(np.arange(0, 21), [\n",
    "    'âˆ…','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo'],\n",
    "    fontsize=8)\n",
    "plt.xticks(np.arange(0, 21), [''] * 21)\n",
    "plt.gca().annotate(\n",
    "    '', \n",
    "    xy=(1.5, 0.1), xycoords='axes fraction', xytext=(1.5, 0.9), \n",
    "    arrowprops=dict(arrowstyle=\"<->\", color='k'))\n",
    "plt.gca().annotate(\n",
    "    'rnn', xy=(1.47, 0.05), xycoords='axes fraction', xytext=(1.47, 0.05))\n",
    "plt.gca().annotate(\n",
    "    'hmm', xy=(1.44, 0.92), xycoords='axes fraction', xytext=(1.44, 0.92))\n",
    "plt.colorbar()\n",
    "\n",
    "# Compare misclassification\n",
    "a = np.sum(hmm_conf[1:, 1:]) - np.sum(np.diag(hmm_conf[1:, 1:]))\n",
    "b = np.sum(rnn_conf[1:, 1:]) - np.sum(np.diag(rnn_conf[1:, 1:]))\n",
    "print(a, b, (a - b) / b)\n",
    "\n",
    "# plt.tight_layout(rect=[0, 0., 1.2, 1])\n",
    "# plt.savefig(\"/home/granger/exp1_confdiff_skel.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize mistaken classes\n",
    "\n",
    "plt.figure(dpi=150)\n",
    "\n",
    "plt.imshow(\n",
    "    np.clip(rnn_conf, 0.0001, 1), \n",
    "    clim=(0.001, 1),\n",
    "    norm=colors.LogNorm(vmin=0.0001, vmax=1., clip=True))\n",
    "plt.yticks(np.arange(0, 21), [\n",
    "    'âˆ…','vattene','vieniqui','perfetto','furbo','cheduepalle','chevuoi','daccordo',\n",
    "    'seipazzo','combinato','freganiente','ok','cosatifarei','basta','prendere',\n",
    "    'noncenepiu','fame','tantotempo','buonissimo','messidaccordo','sonostufo'])\n",
    "plt.xticks(np.arange(0, 21), [''] * 21)\n",
    "plt.colorbar()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/home/granger/exp1_rnn_pose_confusion.pdf\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(42)\n",
    "\n",
    "c1 = 16\n",
    "c2 = 0\n",
    "\n",
    "fig = plt.figure(figsize=(8, 5), dpi=150)\n",
    "all_glosses = np.array([[seq] + list(g) for seq in dataset.default_splits()[0] for g in dataset.glosses(seq)])\n",
    "\n",
    "\n",
    "p = (all_glosses[:, 1] == c1) / np.sum(all_glosses[:, 1] == c1)\n",
    "seq1, c1, start1, stop1 = all_glosses[np.random.choice(len(all_glosses), p=p)]\n",
    "vid1 = dataset.bgr_frames(seq1)\n",
    "\n",
    "for i, t in enumerate(np.linspace(start1 + 10, stop1 - 10, 5).astype(np.int)):\n",
    "    frame = vid1[t]\n",
    "    pose = dataset.positions(seq1)[t]\n",
    "    x1, x2, y1, y2 = np.min(pose[:, 0]) - 30, np.max(pose[:, 0]) + 30, np.min(pose[:, 1]) - 20, np.max(pose[:, 1]) - 130\n",
    "    ax = fig.add_subplot(2, 5, i + 1)\n",
    "    ax.imshow(frame[y1:y2, x1:x2])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "p = (all_glosses[:, 1] == c2) / np.sum(all_glosses[:, 1] == c2)\n",
    "seq2, c2, start2, stop2 = all_glosses[np.random.choice(len(all_glosses), p=p)]\n",
    "vid2 = dataset.bgr_frames(seq2)\n",
    "\n",
    "for i, t in enumerate(np.linspace(start2 + 10, stop2 - 10, 5).astype(np.int)):\n",
    "    frame = vid2[t]\n",
    "    pose = dataset.positions(seq2)[t]\n",
    "    x1, x2, y1, y2 = np.min(pose[:, 0]) - 30, np.max(pose[:, 0]) + 30, np.min(pose[:, 1]) - 20, np.max(pose[:, 1]) - 130\n",
    "    ax = fig.add_subplot(2, 5, i + 6)\n",
    "    ax.imshow(frame[y1:y2, x1:x2])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_yticklabels([])\n",
    "\n",
    "fig.tight_layout(pad=0, h_pad=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file = \"/home/granger/dev/code_these/datasets/ch14dataset/data/Sample0001_color.mp4\"\n",
    "# \n",
    "# class Video(Sequence):\n",
    "#     def __init__(self, file):\n",
    "#         self.file = file\n",
    "#         self.container = av.open(file)\n",
    "#         self.stream = self.container.streams.get(video=0)[0]\n",
    "#         self.frame_base = self.stream.time_base * self.stream.average_rate\n",
    "#         self.packet_iter = self.container.demux(self.stream)\n",
    "#         self.last_packet = next(self.packet_iter).decode()\n",
    "# \n",
    "#         self.offset = 0\n",
    "#         self.duration = int(self.stream.duration * self.stream.time_base\n",
    "#                             * self.stream.average_rate)\n",
    "# \n",
    "#     def __len__(self):\n",
    "#         return self.duration\n",
    "# \n",
    "#     def __getitem__(self, t):\n",
    "#         # slicing support\n",
    "#         if isinstance(t, slice):\n",
    "#             start, stop, step = t.start, t.stop, t.step\n",
    "# \n",
    "#             # defaults\n",
    "#             start = start or 0\n",
    "#             stop = stop or -1\n",
    "#             step = step or 1\n",
    "# \n",
    "#             # range check\n",
    "#             if step != 1:\n",
    "#                 raise IndexError(\"Video slicing is limited to step 1\")\n",
    "#             if start < -len(self) or start >= len(self) \\\n",
    "#                     or stop < -len(self) - 1 or stop > len(self):\n",
    "#                 raise IndexError(\"Video slice index out of range.\")\n",
    "# \n",
    "#             # negative indexing\n",
    "#             start = start + len(self) if start < 0 else start\n",
    "#             stop = stop + len(self) if stop < 0 else stop\n",
    "#             stop = max(start, stop)\n",
    "# \n",
    "#             video = Video(self.file)\n",
    "#             video.offset = self.offset + start  # cumulate offsets\n",
    "#             video.duration = stop - start\n",
    "# \n",
    "#             return video\n",
    "# \n",
    "#         # range check\n",
    "#         if t < -len(self) or t >= len(self):\n",
    "#             raise IndexError(\"Video index out of range.\")\n",
    "# \n",
    "#         # negative indexing\n",
    "#         if t < 0:\n",
    "#             t += len(self)\n",
    "# \n",
    "#         t += self.offset\n",
    "# \n",
    "#         t_pts = t / self.stream.time_base / self.stream.average_rate\n",
    "# \n",
    "#         # Do seeking if needed\n",
    "#         if t > self.last_packet[-1].pts * self.frame_base + len(self.last_packet) \\\n",
    "#                 or t < self.last_packet[0].pts * self.frame_base:\n",
    "#             self.stream.seek(int(t / self.frame_base))\n",
    "#             self.packet_iter = self.container.demux(self.stream)\n",
    "# \n",
    "#         while True:\n",
    "#             for f in self.last_packet:\n",
    "#                 if f.pts == t_pts:\n",
    "#                     return f.to_rgb().to_nd_array()\n",
    "#             self.last_packet = next(self.packet_iter).decode()\n",
    "# \n",
    "# v = Video(file)\n",
    "# \n",
    "# assert np.all(np.stack(list(v[10:20])) == np.stack(list(v)[10:20]))\n",
    "# assert np.all(np.stack([v[i] for i in range(0, 40, 3)]) == np.stack(list(v)[0:40:3]))\n",
    "# \n",
    "# plt.imshow(v[100])\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
