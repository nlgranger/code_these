{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.dirname(os.path.dirname(os.getcwd())))\n",
    "\n",
    "t1 = time.time()\n",
    "# os.environ['THEANO_FLAGS'] = \"device=cuda1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shelve\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import lasagne\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "import matplotlib as mpl\n",
    "import matplotlib.cm\n",
    "from lproc import subset, rmap\n",
    "from sltools.utils import gloss2seq, seq2gloss\n",
    "from sltools.nn_utils import onehot, jaccard, compute_scores\n",
    "from sltools.postproc import optimize_boundaries, filter_longshort\n",
    "\n",
    "from experiments.hmmvsrnn_reco.a_data import durations, gloss_seqs, tmpdir, \\\n",
    "   train_subset, val_subset, test_subset, vocabulary\n",
    "from experiments.hmmvsrnn_reco.utils import autoreload_feats, reload_best_hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'EXPERIMENT_NAME' in os.environ:\n",
    "    experiment_name = os.environ['EXPERIMENT_NAME']\n",
    "else:\n",
    "    experiment_name = \"hmm_transfer_skelinp\"\n",
    "\n",
    "report = shelve.open(os.path.join(tmpdir, experiment_name))\n",
    "\n",
    "model = report['meta']['model']\n",
    "modality = report['meta']['modality']\n",
    "variant = report['meta']['variant']\n",
    "date = report['meta']['date']\n",
    "notes = report['meta']['notes']\n",
    "experiment_name = report['meta']['experiment_name']\n",
    "args = report['args']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_seqs = autoreload_feats(modality, **args['encoder_kwargs'])\n",
    "\n",
    "feat_seqs_train = [subset(f, train_subset) for f in feat_seqs]\n",
    "gloss_seqs_train = subset(gloss_seqs, train_subset)\n",
    "durations_train = subset(durations, train_subset)\n",
    "targets_train = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                     gloss_seqs_train, durations_train)\n",
    "feat_seqs_val = [subset(f, val_subset) for f in feat_seqs]\n",
    "gloss_seqs_val = subset(gloss_seqs, val_subset)\n",
    "durations_val = subset(durations, val_subset)\n",
    "targets_val = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                    gloss_seqs_val, durations_val)\n",
    "feat_seqs_test = [subset(f, test_subset) for f in feat_seqs]\n",
    "gloss_seqs_test = subset(gloss_seqs, test_subset)\n",
    "durations_test = subset(durations, test_subset)\n",
    "targets_test = rmap(lambda g, d: gloss2seq(g, d, 0),\n",
    "                    gloss_seqs_test, durations_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training report and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "\n",
    "i = 0\n",
    "for e in sorted([e for e in report.keys() if e.startswith('epoch')]):\n",
    "    r = report[e]    \n",
    "    plt.plot(np.arange(i, i + len(r['epoch_losses'])), r['epoch_losses'], c='blue')\n",
    "    plt.scatter([i + len(r['epoch_losses']) - 1], [r['epoch_losses'][-1]], \n",
    "                marker='x', c='red', alpha=.5)\n",
    "    \n",
    "    i += len(r['epoch_losses'])\n",
    "\n",
    "plt.gca().set_yscale(\"log\")\n",
    "plt.show()\n",
    "\n",
    "best_epoch, recognizer, previous_recognizer = reload_best_hmm(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_perfs(perf_report, chains_lengths):\n",
    "    plt.figure(figsize=(14, 7))\n",
    "\n",
    "    ax = plt.subplot2grid((2, 3), (0, 0))\n",
    "    cmap = matplotlib.cm.viridis\n",
    "    cmap.set_bad(cmap(0.001))\n",
    "    plt.imshow(perf_report['confusion'] / perf_report['confusion'].sum(axis=1, keepdims=True), \n",
    "               interpolation='none', \n",
    "               cmap=cmap, clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    ax.set_title(\"HMM Jaccard/Framewise : {:5.4f}/{:5.4f}\".format(\n",
    "        perf_report['jaccard'], perf_report['framewise']))\n",
    "\n",
    "    ax = plt.subplot2grid((2, 3), (1, 0))\n",
    "    cmap = matplotlib.cm.viridis\n",
    "    cmap.set_bad(cmap(0.001))\n",
    "    plt.imshow(perf_report['posterior_confusion'] / perf_report['posterior_confusion'].sum(axis=1, keepdims=True), \n",
    "               interpolation='none', \n",
    "               cmap=cmap, clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    ax.set_title(\"Posterior Jaccard/Framewise : {:5.4f}/{:5.4f}\".format(\n",
    "        perf_report['posterior_jaccard'], perf_report['posterior_framewise']))\n",
    "\n",
    "    ax = plt.subplot2grid((2, 3), (0, 1), colspan=2, rowspan=2)\n",
    "    cmap = matplotlib.cm.viridis\n",
    "    cmap.set_bad(cmap(0.001))\n",
    "    plt.imshow(perf_report['statewise_confusion'] / perf_report['statewise_confusion'].sum(axis=1, keepdims=True), \n",
    "               interpolation='none', \n",
    "               cmap=cmap, clim=(0.001, 1), norm=LogNorm(vmin=0.001, vmax=1))\n",
    "    plt.gca().set_xticklabels([])\n",
    "    plt.gca().set_yticklabels([])\n",
    "    plt.gca().set_xticks(np.cumsum(chains_lengths) - .5)\n",
    "    plt.gca().set_yticks(np.cumsum(chains_lengths) - .5)\n",
    "    plt.gca().grid(color='gray', linestyle='dotted')\n",
    "    ax.set_title(\"State-wise framewise: {:5.4f}\".format(perf_report['statewise_framewise']))\n",
    "    \n",
    "    plt.colorbar()\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_perfs(report[best_epoch]['train_scores'], recognizer.chains_lengths)\n",
    "plot_perfs(report[best_epoch]['val_scores'], recognizer.chains_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_train = [gloss2seq(g_, d_, 0) for g_, d_ in zip(gloss_seqs_train, durations_train)]\n",
    "predictions_train = recognizer.predict(feat_seqs_train)\n",
    "ji_train, framewise_train, confusion_train = compute_scores(predictions_train, targets_train, vocabulary)\n",
    "\n",
    "targets_val = [gloss2seq(g_, d_, 0) for g_, d_ in zip(gloss_seqs_val, durations_val)]\n",
    "predictions_val = recognizer.predict(feat_seqs_val)\n",
    "ji_val, framewise_val, confusion_val = compute_scores(predictions_val, targets_val, vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of errors\n",
    "\n",
    "scores = [jaccard(onehot(l, vocabulary), onehot(p, vocabulary))\n",
    "         for l, p in zip(targets_val, predictions_val)]\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(scores, np.linspace(0.5, 1, 40))\n",
    "plt.title(\"Histogram of sequence-wise JI\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of false positives out of sequence vocabulary\n",
    "np.mean([len(set(p_) - set(l_)) for p_, l_ in zip(predictions_val, targets_val)], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion types\n",
    "cum_err = np.sum(confusion_val, axis=1) - np.diag(confusion_val)\n",
    "print(\"false pos: {}  false neg: {}, mis-class: {}\".format(\n",
    "    cum_err[0], np.sum(confusion_val[1:, 0]), np.sum(cum_err[1:]) - np.sum(confusion_val[1:, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the posteriors of the _correct_ states in color and other states in gray\n",
    "\n",
    "def preview_seq(proba, gloss):\n",
    "    plt.figure(figsize=(15, 3))\n",
    "    cmap = plt.cm.summer(np.linspace(0, 1, 5))\n",
    "    \n",
    "    pre_start = 0\n",
    "    for lbl, start, stop in gloss:\n",
    "        for i in range(proba.shape[1] - 1):\n",
    "            plt.plot(np.arange(pre_start, start), proba[pre_start:start, i], ls=':', c=\"gray\")\n",
    "        plt.plot(np.arange(pre_start, start), proba[pre_start:start, -1], c=\"purple\")\n",
    "        for a in range(0, (lbl - 1) * 5):\n",
    "            plt.plot(np.arange(start, stop), proba[start:stop, a], ls=\":\", c='gray')\n",
    "        for a in range(5):\n",
    "            plt.plot(np.arange(start, stop), proba[start:stop, (lbl - 1) * 5 + a], c=cmap[a])\n",
    "        for a in range(lbl * 5, proba.shape[1]):\n",
    "            plt.plot(np.arange(start, stop), proba[start:stop, a], ls=\":\", c='gray')\n",
    "        pre_start = stop\n",
    "    \n",
    "    for i in range(proba.shape[1] - 1):\n",
    "        plt.plot(np.arange(pre_start, len(proba)), proba[pre_start:len(proba), i], ls=':', c=\"gray\")\n",
    "    plt.plot(np.arange(pre_start, len(proba)), proba[pre_start:len(proba), -1], c=\"purple\")\n",
    "\n",
    "    \n",
    "seq = 15\n",
    "\n",
    "preview_seq(\n",
    "    recognizer.posterior.predict_proba(*[f[seq] for f in feat_seqs_val]),\n",
    "    gloss_seqs_val[seq])\n",
    "\n",
    "plt.gca().set_xlim((200, 900))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlate error with predicted gloss duration\n",
    "\n",
    "plt.figure(figsize=(9, 4))\n",
    "\n",
    "prediction_accuracy = [np.sum(l[start:stop] == g) \n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "none_accuracy = [np.sum(l[start:stop] == 0)\n",
    "            for p, l in zip(predictions_val, targets_val)\n",
    "            for (g, start, stop) in seq2gloss(p)\n",
    "            if g != 0]\n",
    "gloss_d = [stop - start\n",
    "           for p in predictions_val \n",
    "           for (g, start, stop) in seq2gloss(p)\n",
    "           if g != 0]\n",
    "\n",
    "scores_pred = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "scores_none = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "total_d = np.zeros((int(np.ceil(max(gloss_d) / 5 + 0.0001)),))\n",
    "for vp, vn, d in zip(prediction_accuracy, none_accuracy, gloss_d):\n",
    "    idx = int(d / 5)\n",
    "    scores_pred[idx] += vp\n",
    "    scores_none[idx] += vn\n",
    "    total_d[idx] += d\n",
    "\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5), \n",
    "              scores_pred / total_d,\n",
    "              width=5,\n",
    "              alpha=.5)\n",
    "plt.gca().bar(np.arange(0, int(np.ceil(max(gloss_d) + 0.0001)), 5), \n",
    "              scores_none / total_d,\n",
    "              width=5,\n",
    "              alpha=.5)\n",
    "\n",
    "plt.legend([\"predicted class\", \"non-gesture class\"])\n",
    "plt.xlabel(\"subsequence duration (based on model prediction)\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimize duration filter\n",
    "\n",
    "boundaries = optimize_boundaries(targets_val, predictions_val, vocabulary, (30, 100, 301))\n",
    "print(\"Optimal range: \", boundaries)\n",
    "print(\"FYI the score without is: {:.4f}\".format(ji_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation score\n",
    "\n",
    "ji_filtered_val, accuracy_filtered_val, confusion_filtered_val = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_val], \n",
    "    targets_val, vocabulary)\n",
    "print(\"validation score: {:.4f}\".format(ji_filtered_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test score\n",
    "\n",
    "targets_test = [gloss2seq(g_, d_, 0) for g_, d_ in zip(gloss_seqs_test, durations_test)]\n",
    "predictions_test = recognizer.predict(feat_seqs_test)\n",
    "\n",
    "ji_filtered_test, accuracy_filtered_test, confusion_filtered_test = compute_scores(\n",
    "    [filter_longshort(p, boundaries, 0) for p in predictions_test], \n",
    "    targets_test, vocabulary)\n",
    "print(\"testing score: {:.4f}\".format(ji_filtered_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recap:\n",
    "\n",
    "print(\"Accuracy:   {:.4f} / {:.4f} / ?\".format(framewise_train, framewise_val))\n",
    "print(\"JI:         {:.4f} / {:.4f} / ?\".format(ji_train, ji_val))\n",
    "print(\"Acc. filt.:      ? / {:.4f} / {:.4f}\".format(accuracy_filtered_val, accuracy_filtered_test))\n",
    "print(\"JI filt.:        ? / {:.4f} / {:.4f}\".format(ji_filtered_val, ji_filtered_test))\n",
    "\n",
    "recap = {\n",
    "    \"experiment_name\": experiment_name,\n",
    "    \"best_epoch\": best_epoch,\n",
    "    \"accuracy\": (framewise_train, framewise_val, None),\n",
    "    \"ji\": (ji_train, ji_val, None),\n",
    "    \"confusion\": (confusion_train, confusion_val, None),\n",
    "    \"accuracy_filtered\": (None, accuracy_filtered_val, accuracy_filtered_test),\n",
    "    \"ji_filtered\": (None, ji_filtered_val, ji_filtered_test),\n",
    "    \"confusion_filtered\": (None, confusion_filtered_val, None),\n",
    "}\n",
    "report['analysis'] = recap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(report['args']['encoder_kwargs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sltools.tconv import TemporalConv\n",
    "\n",
    "l = None\n",
    "for l_ in lasagne.layers.get_all_layers(recognizer.posterior.l_feats):\n",
    "    if isinstance(l_, TemporalConv):\n",
    "        l = l_\n",
    "\n",
    "W1 = l.W.eval()\n",
    "W1 = W1.transpose((0, 2, 1)).reshape((-1, W1.shape[1]))\n",
    "Y = np.linalg.norm(W1, axis=1)\n",
    "i = np.argsort(Y)\n",
    "W1 = np.stack([W1[i_] for i_ in i])[-300:]\n",
    "model = TSNE(n_components=1, metric='euclidean')\n",
    "Y = model.fit_transform(W1)[:, 0]\n",
    "i = np.argsort(Y)\n",
    "W1 = W1[i]\n",
    "Y = Y[i]\n",
    "\n",
    "plt.figure(figsize=(5, 20))\n",
    "x, y = np.meshgrid(np.arange(W1.shape[1]), Y)\n",
    "plt.imshow(W1, clim=(-np.abs(W1).max(), np.abs(W1).max()), cmap='bwr')\n",
    "plt.gca().set_aspect(\"auto\")\n",
    "plt.axis([-1, W1.shape[1], -1, W1.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = time.time()\n",
    "print(t2 - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = lasagne.layers.get_all_layers(recognizer.posterior.l_feats)[2]\n",
    "# W = np.asarray(l.W.eval())\n",
    "\n",
    "# nrows, ncols = int(np.ceil(np.sqrt(W.shape[0] + 1))), int(np.floor(np.sqrt(W.shape[0] + 1)))\n",
    "# img = np.zeros((nrows * (W.shape[2] + 1), ncols * (W.shape[3] + 1)))\n",
    "# for k in range(W.shape[0]):\n",
    "#     i, j = k // ncols, k % ncols\n",
    "#     y, x = i * (W.shape[2] + 1), j * (W.shape[3] + 1)\n",
    "#     tmp = img[y:y + W.shape[2]]\n",
    "#     img[y:y + W.shape[2], x:x + W.shape[3]] = W[k, 0]\n",
    "\n",
    "# plt.imshow(img, clim=(-np.abs(W).max(), np.abs(W).max()), cmap='bwr')\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lbl, cnt = np.unique(\n",
    "#     np.concatenate([gloss2seq(g_, len(r_), 0) for g_, r_ in zip(gloss_seqs_val, feat_seqs_val)]),\n",
    "#     return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(x=lbl+.5, height=cnt, log=True)\n",
    "# plt.gca().set_ylim((1, 3e5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(x=lbl+.5, height=cnt, log=False)\n",
    "# plt.gca().set_ylim((1, 2e5))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum([len(gseq) for gseq in gloss_seqs_val])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
